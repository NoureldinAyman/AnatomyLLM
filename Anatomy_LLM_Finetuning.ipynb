{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "692b3cb7bc2349e08f2c9d80222858a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64286812472d46d8acd48f4264bdc11e",
              "IPY_MODEL_61bda8d0114b4decb4863850f64c258d",
              "IPY_MODEL_de2b63fbaf3a442186385211613f137f"
            ],
            "layout": "IPY_MODEL_e24560598a5244798c09726cb4e82284"
          }
        },
        "64286812472d46d8acd48f4264bdc11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc792eb8fa54ede8600565bb5d66246",
            "placeholder": "​",
            "style": "IPY_MODEL_856e72f5ad1545168af95145d6a34f83",
            "value": ""
          }
        },
        "61bda8d0114b4decb4863850f64c258d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735120592943432399066625b2f47377",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a0c18840a3e453e81778aaff1747405",
            "value": 1
          }
        },
        "de2b63fbaf3a442186385211613f137f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e839aef6367740b19da84a1824951e94",
            "placeholder": "​",
            "style": "IPY_MODEL_bd741dee74a64fd8988980312a83cec5",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.72s/it]\n"
          }
        },
        "e24560598a5244798c09726cb4e82284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc792eb8fa54ede8600565bb5d66246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856e72f5ad1545168af95145d6a34f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "735120592943432399066625b2f47377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0c18840a3e453e81778aaff1747405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e839aef6367740b19da84a1824951e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd741dee74a64fd8988980312a83cec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7593462323a44fa48ab5ae4cc74c6b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3655772b7404accaca1328d035a7892",
              "IPY_MODEL_049a3dbbc0664571bb984a7f3f337a50",
              "IPY_MODEL_151d345deeb8493788b1bee099755378"
            ],
            "layout": "IPY_MODEL_77d87c3aa6a145b092f0ab62784c66ce"
          }
        },
        "d3655772b7404accaca1328d035a7892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b381696a3e474e1a830f75b995927f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_28bbc97d808e496baed7a2247004d9a1",
            "value": ""
          }
        },
        "049a3dbbc0664571bb984a7f3f337a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2fc3bd7cb441d1929a663a61e73a25",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bfb46bbb9dc42cea4fe7fe7509dbf0e",
            "value": 1
          }
        },
        "151d345deeb8493788b1bee099755378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6430101260f841efbeec741840520667",
            "placeholder": "​",
            "style": "IPY_MODEL_00b7043be42d4d4aaa92306a534a1f17",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.81s/it]\n"
          }
        },
        "77d87c3aa6a145b092f0ab62784c66ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b381696a3e474e1a830f75b995927f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bbc97d808e496baed7a2247004d9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2fc3bd7cb441d1929a663a61e73a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfb46bbb9dc42cea4fe7fe7509dbf0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6430101260f841efbeec741840520667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b7043be42d4d4aaa92306a534a1f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b51ec55624a40edb7952acfe9ed7254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2fe911e4631445088fdaf14cb77c913",
              "IPY_MODEL_f9b0865fab2944a4bf466c7f48e91ad6",
              "IPY_MODEL_2f68ee61065f413597919af2277e1678"
            ],
            "layout": "IPY_MODEL_3555cee82a38472bae08d08aa8261795"
          }
        },
        "d2fe911e4631445088fdaf14cb77c913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27e0ebce71bc46b98d91bfb40758b47d",
            "placeholder": "​",
            "style": "IPY_MODEL_d4bd4cb2f9f547a58d792feb048c9281",
            "value": "Processed prompts: 100%"
          }
        },
        "f9b0865fab2944a4bf466c7f48e91ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7389460eb85491292103f4eb2955f85",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25565496f63444b286f89d3970df9105",
            "value": 1
          }
        },
        "2f68ee61065f413597919af2277e1678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3691956757794847a3e354a2eb07a77c",
            "placeholder": "​",
            "style": "IPY_MODEL_df0832ea0e464bf1a6360e876bc3c75d",
            "value": " 1/1 [00:03&lt;00:00,  3.00s/it, est. speed input: 115.15 toks/s, output: 74.88 toks/s]"
          }
        },
        "3555cee82a38472bae08d08aa8261795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "27e0ebce71bc46b98d91bfb40758b47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4bd4cb2f9f547a58d792feb048c9281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7389460eb85491292103f4eb2955f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25565496f63444b286f89d3970df9105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3691956757794847a3e354a2eb07a77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0832ea0e464bf1a6360e876bc3c75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce2681385e2e48ff93dadbb842908c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bf8beac1314101b251ea4a97b9b300",
              "IPY_MODEL_6b47292b6714443c931e77c81738f967",
              "IPY_MODEL_f5fea625d27a43578002a6b2a52016fe"
            ],
            "layout": "IPY_MODEL_1f64bafc2bf046caaea12a3e985be44f"
          }
        },
        "69bf8beac1314101b251ea4a97b9b300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70eb010fb65442fe937589a9c4bd26fb",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa6da3ecf044447894794e38aaa7ceb",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "6b47292b6714443c931e77c81738f967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b5742eb56c4165b6f542c13e7bdd54",
            "max": 3945426872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d7a1dc757c04b0d804a16ab8f41c389",
            "value": 3945426872
          }
        },
        "f5fea625d27a43578002a6b2a52016fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e37c96512dbb4bf9a93fbde1e3f511a4",
            "placeholder": "​",
            "style": "IPY_MODEL_7a4e19a815244b1d93038960534e8a98",
            "value": " 3.95G/3.95G [00:18&lt;00:00, 60.9MB/s]"
          }
        },
        "1f64bafc2bf046caaea12a3e985be44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70eb010fb65442fe937589a9c4bd26fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa6da3ecf044447894794e38aaa7ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0b5742eb56c4165b6f542c13e7bdd54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7a1dc757c04b0d804a16ab8f41c389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e37c96512dbb4bf9a93fbde1e3f511a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4e19a815244b1d93038960534e8a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea3fd8df8194facb3f3726e84d02031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7104cba797894ae5a6c01ed4aa3a045c",
              "IPY_MODEL_c612607de350484e9f29a0f4811ca3a0",
              "IPY_MODEL_afb191bbcf6a4c04b18d0c567e893dc8"
            ],
            "layout": "IPY_MODEL_b858bd327f174d48890ab8ed37c5c213"
          }
        },
        "7104cba797894ae5a6c01ed4aa3a045c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6341520993be4bf894fcddaf1765e913",
            "placeholder": "​",
            "style": "IPY_MODEL_d93e11d3dc0f4f018ae83e46858a81eb",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "c612607de350484e9f29a0f4811ca3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ddb7a646c740afb29d308896adf5e3",
            "max": 3864726352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd30cc8b92274a2ba28ff4fcfe95b53b",
            "value": 3864726352
          }
        },
        "afb191bbcf6a4c04b18d0c567e893dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3329005dc0d4ed9af7934b1bb3dfb7a",
            "placeholder": "​",
            "style": "IPY_MODEL_b21fd5ed2302467c8e960575397422da",
            "value": " 3.86G/3.86G [00:26&lt;00:00, 390MB/s]"
          }
        },
        "b858bd327f174d48890ab8ed37c5c213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6341520993be4bf894fcddaf1765e913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93e11d3dc0f4f018ae83e46858a81eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ddb7a646c740afb29d308896adf5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd30cc8b92274a2ba28ff4fcfe95b53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3329005dc0d4ed9af7934b1bb3dfb7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21fd5ed2302467c8e960575397422da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "163bac95c3b24c6a9f1e4d968e831124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a7cbf95f484173aed03feb558b4c92",
              "IPY_MODEL_b8bc5e64f1034acaaad80419ef47d5d5",
              "IPY_MODEL_e0a3422c675f40a0afac5d271acbfa44"
            ],
            "layout": "IPY_MODEL_c320ac3f7052487ba025399bbf597aa3"
          }
        },
        "b4a7cbf95f484173aed03feb558b4c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cdb2d7dfda44138a98eef73b0f25ddf",
            "placeholder": "​",
            "style": "IPY_MODEL_568ac04327df4809a3f9fed5a1bc2944",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        },
        "b8bc5e64f1034acaaad80419ef47d5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce4b0d0f79a4e19b86531eb473ebfe6",
            "max": 3864726408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c178a188b0b24cc6a64d12b468580aaa",
            "value": 3864726408
          }
        },
        "e0a3422c675f40a0afac5d271acbfa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d18dab913e14fa58b9aad5fd9e35e21",
            "placeholder": "​",
            "style": "IPY_MODEL_6570b95264e34a90b0a5f959a0411c48",
            "value": " 3.86G/3.86G [00:09&lt;00:00, 373MB/s]"
          }
        },
        "c320ac3f7052487ba025399bbf597aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cdb2d7dfda44138a98eef73b0f25ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568ac04327df4809a3f9fed5a1bc2944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce4b0d0f79a4e19b86531eb473ebfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c178a188b0b24cc6a64d12b468580aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d18dab913e14fa58b9aad5fd9e35e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6570b95264e34a90b0a5f959a0411c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe9327ac42464ff6a6c99a66c0af440e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa929e9711d04103aa42003fc65b22ef",
              "IPY_MODEL_88a52c19d13e4217b3d222b70b8bb196",
              "IPY_MODEL_10d5ebaf9aa149aa87d8a0a47eb9bd03"
            ],
            "layout": "IPY_MODEL_b4fc2ddf7203405f80bb7f8d70ebc026"
          }
        },
        "aa929e9711d04103aa42003fc65b22ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf9de6d19044944a1a91c808786014f",
            "placeholder": "​",
            "style": "IPY_MODEL_fb4107000a4648eca417298d78986766",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "88a52c19d13e4217b3d222b70b8bb196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1ec34de6a04b13ac8949463d0357f3",
            "max": 3556392240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45e27542adbf481f89533c9ee6e59e8f",
            "value": 3556392240
          }
        },
        "10d5ebaf9aa149aa87d8a0a47eb9bd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38fc480b71674c75a211d49f89fb00ee",
            "placeholder": "​",
            "style": "IPY_MODEL_74ea65af77e243dd95606b67752ebd3f",
            "value": " 3.56G/3.56G [00:09&lt;00:00, 398MB/s]"
          }
        },
        "b4fc2ddf7203405f80bb7f8d70ebc026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf9de6d19044944a1a91c808786014f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4107000a4648eca417298d78986766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1ec34de6a04b13ac8949463d0357f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e27542adbf481f89533c9ee6e59e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38fc480b71674c75a211d49f89fb00ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ea65af77e243dd95606b67752ebd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d1464395f74f88a3430c513bd33b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9eb689e7f3a4c65abcca86d0c3cfa8f",
              "IPY_MODEL_b8965da9fff74f30a740637109a27846",
              "IPY_MODEL_a3c79f7d62bc4a6cb20c72db720aae7d"
            ],
            "layout": "IPY_MODEL_7b59ab7963684e99a21bd3e2c906aac4"
          }
        },
        "f9eb689e7f3a4c65abcca86d0c3cfa8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f227afbebf664116be5256a8dd7630c8",
            "placeholder": "​",
            "style": "IPY_MODEL_bdaf8b06b31c487b92b58853736f811e",
            "value": "100%"
          }
        },
        "b8965da9fff74f30a740637109a27846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91438f652f05435aa5a3d33ac7a4f669",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_991a4753a68445b5bac27d22853dc8e9",
            "value": 1
          }
        },
        "a3c79f7d62bc4a6cb20c72db720aae7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d20cac9e4f499ca5b04639510de9a5",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf49bc981b742c79abdc7c6f3db58c8",
            "value": " 1/1 [00:00&lt;00:00,  1.95it/s]"
          }
        },
        "7b59ab7963684e99a21bd3e2c906aac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f227afbebf664116be5256a8dd7630c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdaf8b06b31c487b92b58853736f811e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91438f652f05435aa5a3d33ac7a4f669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991a4753a68445b5bac27d22853dc8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01d20cac9e4f499ca5b04639510de9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf49bc981b742c79abdc7c6f3db58c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37b0cf86c4c94a4d9f038703888657d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba90ac98dee04175959714a7ab3fd32d",
              "IPY_MODEL_9a66ac76fd3543fa988bbd603a2d92bf",
              "IPY_MODEL_3b6b4197e2a04d78b34d16c68dd0a175"
            ],
            "layout": "IPY_MODEL_0ea14708c7474e17bc1a7c5839234908"
          }
        },
        "ba90ac98dee04175959714a7ab3fd32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8572b44245441d5825f9123becdc766",
            "placeholder": "​",
            "style": "IPY_MODEL_89d34fc7ca244e46b140ca0dfb0deaa4",
            "value": "tokenizer.json: 100%"
          }
        },
        "9a66ac76fd3543fa988bbd603a2d92bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629946bf923445fa9ae35498efbbdf24",
            "max": 11418433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d73be752eb5412b8eb52084961bcafd",
            "value": 11418433
          }
        },
        "3b6b4197e2a04d78b34d16c68dd0a175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c1afc6cec84c959ff984bef18dbafa",
            "placeholder": "​",
            "style": "IPY_MODEL_575d2a7416e341a1bae13a18680c88c8",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 60.6MB/s]"
          }
        },
        "0ea14708c7474e17bc1a7c5839234908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8572b44245441d5825f9123becdc766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d34fc7ca244e46b140ca0dfb0deaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "629946bf923445fa9ae35498efbbdf24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d73be752eb5412b8eb52084961bcafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51c1afc6cec84c959ff984bef18dbafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575d2a7416e341a1bae13a18680c88c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c0093d6dd6e4887a1b511881e071847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a9fc955b290493181af2f19d7763d95",
              "IPY_MODEL_6170966f3b074623be7c2c33855a51a5",
              "IPY_MODEL_05cf2762af314b03a10d33bb8fa6fb0c"
            ],
            "layout": "IPY_MODEL_932385f7712c47328838397d303262a8"
          }
        },
        "4a9fc955b290493181af2f19d7763d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b628e48ea6549b2ba2123b470a47b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_4300e66d94e741808d6a772e81f843ef",
            "value": "model.safetensors.index.json: "
          }
        },
        "6170966f3b074623be7c2c33855a51a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b31ede9093a4cbfbb9a51d25d21661d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa2ece61f1e0454395a2bd3d67ddfc10",
            "value": 1
          }
        },
        "05cf2762af314b03a10d33bb8fa6fb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f6db425efc9421b8d029c65278c4e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_e10192fc7f0a40b69d7b5253fae139b4",
            "value": " 27.8k/? [00:00&lt;00:00, 3.00MB/s]"
          }
        },
        "932385f7712c47328838397d303262a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b628e48ea6549b2ba2123b470a47b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4300e66d94e741808d6a772e81f843ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b31ede9093a4cbfbb9a51d25d21661d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "aa2ece61f1e0454395a2bd3d67ddfc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f6db425efc9421b8d029c65278c4e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e10192fc7f0a40b69d7b5253fae139b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111a1af55d9b468b95c50c058a45ab14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_510c8ab0e7934619aa2fa01fd12cb64e",
              "IPY_MODEL_9a7a2a1aa9244dbead9cd109603bf988",
              "IPY_MODEL_44cc12fc3fb245d0af53a504023ce9c3"
            ],
            "layout": "IPY_MODEL_83048f60b69144e889a5e8fe44d1776a"
          }
        },
        "510c8ab0e7934619aa2fa01fd12cb64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7bb8b62a854177bfa9b6e9e5e3d447",
            "placeholder": "​",
            "style": "IPY_MODEL_add44c63990b4349943239e6a1eddc5b",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "9a7a2a1aa9244dbead9cd109603bf988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cba6f726c54ca19c7b4f1025ab34f7",
            "max": 3945426872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3b8f782d6fd407c9380e44d6124bdaa",
            "value": 3945426872
          }
        },
        "44cc12fc3fb245d0af53a504023ce9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb1563e8464f4b9e98baa8ae0216a485",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d8da6fe19a4c90ae1970fbf6495fda",
            "value": " 3.95G/3.95G [00:13&lt;00:00, 334MB/s]"
          }
        },
        "83048f60b69144e889a5e8fe44d1776a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7bb8b62a854177bfa9b6e9e5e3d447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add44c63990b4349943239e6a1eddc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cba6f726c54ca19c7b4f1025ab34f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b8f782d6fd407c9380e44d6124bdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb1563e8464f4b9e98baa8ae0216a485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d8da6fe19a4c90ae1970fbf6495fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d024192aff934df688d6410bb66cbfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa4548b27d3a44849a441105613106ca",
              "IPY_MODEL_cad54dd1bd444c2bbafd974fe31cb4cb",
              "IPY_MODEL_933f2297ccb74202852f72d3d71edb84"
            ],
            "layout": "IPY_MODEL_ed4f03a154c24782b6b5904bbfbb0e70"
          }
        },
        "aa4548b27d3a44849a441105613106ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567e605ca88645eaacb366fbd3857704",
            "placeholder": "​",
            "style": "IPY_MODEL_60a50327bc8f4cf08c09ec179c03b117",
            "value": "100%"
          }
        },
        "cad54dd1bd444c2bbafd974fe31cb4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d5941a81e34bcb92dc20f926328cfd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c23aaeb265bc4753a1ea935ddb3de91e",
            "value": 1
          }
        },
        "933f2297ccb74202852f72d3d71edb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a68e3e4937f84847850e5628a1655170",
            "placeholder": "​",
            "style": "IPY_MODEL_622a374deceb4b72b1c6cdac3a9e8c2f",
            "value": " 1/1 [00:34&lt;00:00, 34.14s/it]"
          }
        },
        "ed4f03a154c24782b6b5904bbfbb0e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567e605ca88645eaacb366fbd3857704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a50327bc8f4cf08c09ec179c03b117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d5941a81e34bcb92dc20f926328cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23aaeb265bc4753a1ea935ddb3de91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a68e3e4937f84847850e5628a1655170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622a374deceb4b72b1c6cdac3a9e8c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb45353d1e2d42bd9f524e39966a0bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac24e3fcb69c4ad896efc08a340a1610",
              "IPY_MODEL_a8dc1c294e484fcc9211c829fcb82a99",
              "IPY_MODEL_761f6dbb9ad0473eb6ff3e46b9d8c110"
            ],
            "layout": "IPY_MODEL_360e2e25d58141b9902d1e5b03b5ede7"
          }
        },
        "ac24e3fcb69c4ad896efc08a340a1610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1e9dbf34c14594a8a2bef6d3e1e3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_f6950a7498fe461e8390b87b653744ca",
            "value": "model-00001-of-00004.safetensors: "
          }
        },
        "a8dc1c294e484fcc9211c829fcb82a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc9bc3614f1482dbd663fc9d2a7d6b3",
            "max": 3945426872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a849613464164b509e63a0f14c137e17",
            "value": 3945426872
          }
        },
        "761f6dbb9ad0473eb6ff3e46b9d8c110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe1977633ec40aa9ca30e436ca1df51",
            "placeholder": "​",
            "style": "IPY_MODEL_10c06aa378b24c2fb298cc032ac1a1ce",
            "value": " 3.95G/? [00:33&lt;00:00, 519MB/s]"
          }
        },
        "360e2e25d58141b9902d1e5b03b5ede7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1e9dbf34c14594a8a2bef6d3e1e3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6950a7498fe461e8390b87b653744ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfc9bc3614f1482dbd663fc9d2a7d6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a849613464164b509e63a0f14c137e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffe1977633ec40aa9ca30e436ca1df51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10c06aa378b24c2fb298cc032ac1a1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f75910021514743a283223ba0e47093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d628b25ead10431b9d6a9a76b1aa048d",
              "IPY_MODEL_4a88c667a9b14793adbb55c85e21b3bc",
              "IPY_MODEL_09d1a4cc149f407a9d0dcf43004a3bac"
            ],
            "layout": "IPY_MODEL_7dc33af7427943c799d9a08685112f6c"
          }
        },
        "d628b25ead10431b9d6a9a76b1aa048d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7ae333b266846f7957eb9278648e680",
            "placeholder": "​",
            "style": "IPY_MODEL_a2f20d2ad3894448b14a6868169aaaa5",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "4a88c667a9b14793adbb55c85e21b3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35964f054bec4831b8e7bb46252c01d0",
            "max": 3864726352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_176be8890a1c4c5f815b28cc76308f1c",
            "value": 3864726352
          }
        },
        "09d1a4cc149f407a9d0dcf43004a3bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7274ead1ae9240ceb11a1ed5a3267420",
            "placeholder": "​",
            "style": "IPY_MODEL_5a98ad5f93564876b9d9ed64c6ce2238",
            "value": " 3.86G/3.86G [00:11&lt;00:00, 383MB/s]"
          }
        },
        "7dc33af7427943c799d9a08685112f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ae333b266846f7957eb9278648e680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f20d2ad3894448b14a6868169aaaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35964f054bec4831b8e7bb46252c01d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176be8890a1c4c5f815b28cc76308f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7274ead1ae9240ceb11a1ed5a3267420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a98ad5f93564876b9d9ed64c6ce2238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce085f33828492aab27ca3f18b14087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fee59561306407f95bf32d293db3fce",
              "IPY_MODEL_207c7589d3184c6a9dcb8bd956e22ad4",
              "IPY_MODEL_c56cf013b9ec4922b4b8b194abec42a0"
            ],
            "layout": "IPY_MODEL_37664cf9bc7042e98dd6a1a2a7858f4d"
          }
        },
        "8fee59561306407f95bf32d293db3fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d456168b7014e18a0b4bb87aeafea24",
            "placeholder": "​",
            "style": "IPY_MODEL_715f6d3787184c06b69712bea70cc8e1",
            "value": "100%"
          }
        },
        "207c7589d3184c6a9dcb8bd956e22ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fd4ef7c3fb44429aadbb3c5edac4566",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8817112969484228b5ae1e1465b365b8",
            "value": 1
          }
        },
        "c56cf013b9ec4922b4b8b194abec42a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f502e6361cb24fc081f0fbedc91d0a85",
            "placeholder": "​",
            "style": "IPY_MODEL_3e46dbe0f5f64e2d872491546a520928",
            "value": " 1/1 [00:34&lt;00:00, 34.00s/it]"
          }
        },
        "37664cf9bc7042e98dd6a1a2a7858f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d456168b7014e18a0b4bb87aeafea24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715f6d3787184c06b69712bea70cc8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fd4ef7c3fb44429aadbb3c5edac4566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8817112969484228b5ae1e1465b365b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f502e6361cb24fc081f0fbedc91d0a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e46dbe0f5f64e2d872491546a520928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77de0aff09b3476e93895238be2f5a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4570123bf5144e19aa02a77a0b4594c4",
              "IPY_MODEL_257ef2296d6743ccbc233e1c347a6944",
              "IPY_MODEL_9fcef8035fbb483e95aaab91d6f77921"
            ],
            "layout": "IPY_MODEL_1629b29ee1004dcbb747de286bb83e23"
          }
        },
        "4570123bf5144e19aa02a77a0b4594c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574f1444a578475ea2c5d256f5c1a93b",
            "placeholder": "​",
            "style": "IPY_MODEL_44440373e8f04bd195192b7e920071e8",
            "value": "model-00002-of-00004.safetensors: "
          }
        },
        "257ef2296d6743ccbc233e1c347a6944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4df87fcaa94b1aa3f42d39d97737cd",
            "max": 3864726352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dacb73e95bc4abaa562e53a54dc881e",
            "value": 3864726352
          }
        },
        "9fcef8035fbb483e95aaab91d6f77921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a975bd59dd94456ca34693075c6b1b5a",
            "placeholder": "​",
            "style": "IPY_MODEL_49a84fdb0478402d897babd92bbf388d",
            "value": " 3.87G/? [00:33&lt;00:00, 289MB/s]"
          }
        },
        "1629b29ee1004dcbb747de286bb83e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "574f1444a578475ea2c5d256f5c1a93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44440373e8f04bd195192b7e920071e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b4df87fcaa94b1aa3f42d39d97737cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dacb73e95bc4abaa562e53a54dc881e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a975bd59dd94456ca34693075c6b1b5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a84fdb0478402d897babd92bbf388d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ee9d2112fe45f9b112057892e33741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf1c7afb2d12464abbedc9815c356268",
              "IPY_MODEL_4426aaff304d47fba19dc573d1f627eb",
              "IPY_MODEL_d401f8f1026e48109026147f1481205c"
            ],
            "layout": "IPY_MODEL_21a45fa3707442c39c1ff620f40c6cc8"
          }
        },
        "cf1c7afb2d12464abbedc9815c356268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48001cf3129c45a6b3d6c44d8b70b553",
            "placeholder": "​",
            "style": "IPY_MODEL_8ddb2e55899d42beaa107e6c635b6c99",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        },
        "4426aaff304d47fba19dc573d1f627eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec621dba12b4febb035fb1f2f1dc2bc",
            "max": 3864726408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cca89d228fc4f63a21c412a8b207fb9",
            "value": 3864726408
          }
        },
        "d401f8f1026e48109026147f1481205c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39aa474e2e1947e6afd62396cc65fc4c",
            "placeholder": "​",
            "style": "IPY_MODEL_e3561402d92d40f395ac15aa58622f84",
            "value": " 3.86G/3.86G [00:11&lt;00:00, 388MB/s]"
          }
        },
        "21a45fa3707442c39c1ff620f40c6cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48001cf3129c45a6b3d6c44d8b70b553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ddb2e55899d42beaa107e6c635b6c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec621dba12b4febb035fb1f2f1dc2bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cca89d228fc4f63a21c412a8b207fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39aa474e2e1947e6afd62396cc65fc4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3561402d92d40f395ac15aa58622f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd5319d95a6e429aa910083ea113d54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32076a514d2c471893815e7195864a79",
              "IPY_MODEL_69e5a56b13bf415c8335efb22073c465",
              "IPY_MODEL_7a654bea9e2f4012be4bfb9d2686c7d0"
            ],
            "layout": "IPY_MODEL_746b4c2dd9084fc3b61d7ef934f2715a"
          }
        },
        "32076a514d2c471893815e7195864a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c2757ad484465fa66a3c07481c20dc",
            "placeholder": "​",
            "style": "IPY_MODEL_5f146ffa23934e2c88d8a965c12393f3",
            "value": "100%"
          }
        },
        "69e5a56b13bf415c8335efb22073c465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afcdce6b080d4e5aaccb376fee9b9fb5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4261ae1d636d419aa81759e934fc0833",
            "value": 1
          }
        },
        "7a654bea9e2f4012be4bfb9d2686c7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7574d31382e248a6bff2d3af0c00a731",
            "placeholder": "​",
            "style": "IPY_MODEL_befc5e043445459fbf95aeefdac517c7",
            "value": " 1/1 [00:34&lt;00:00, 34.18s/it]"
          }
        },
        "746b4c2dd9084fc3b61d7ef934f2715a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c2757ad484465fa66a3c07481c20dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f146ffa23934e2c88d8a965c12393f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afcdce6b080d4e5aaccb376fee9b9fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4261ae1d636d419aa81759e934fc0833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7574d31382e248a6bff2d3af0c00a731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befc5e043445459fbf95aeefdac517c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565cab7840e341eb92b926680b931213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a53b1ea5a08493e9d0ec8480ebbf59f",
              "IPY_MODEL_2ddefedfced04eae93c4b80c1435bc54",
              "IPY_MODEL_8b849755592e4c52b95123c55771c37f"
            ],
            "layout": "IPY_MODEL_047aebdbeb704477bb08552802114039"
          }
        },
        "1a53b1ea5a08493e9d0ec8480ebbf59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6c3ce6b71644ccb0d58317a93b9c4a",
            "placeholder": "​",
            "style": "IPY_MODEL_dda31399d0454b5797c19329c22561a7",
            "value": "model-00003-of-00004.safetensors: "
          }
        },
        "2ddefedfced04eae93c4b80c1435bc54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac4086aecac499ab5ea2fabe2f825b4",
            "max": 3864726408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b22086d9d73b44348f4500b4a7e18fa7",
            "value": 3864726408
          }
        },
        "8b849755592e4c52b95123c55771c37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cf32d64965940738b6e9e301e4a09e0",
            "placeholder": "​",
            "style": "IPY_MODEL_72c273b77a5f4966b108eccdb861916a",
            "value": " 3.87G/? [00:33&lt;00:00, 221MB/s]"
          }
        },
        "047aebdbeb704477bb08552802114039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb6c3ce6b71644ccb0d58317a93b9c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda31399d0454b5797c19329c22561a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac4086aecac499ab5ea2fabe2f825b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22086d9d73b44348f4500b4a7e18fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cf32d64965940738b6e9e301e4a09e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c273b77a5f4966b108eccdb861916a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d804f9aa2749470f8009a0776d0a24b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63429090a8db477cb87db69b638a40ad",
              "IPY_MODEL_547f795f81c944eca988bd5b5bde9334",
              "IPY_MODEL_c5a79c4a121c4dd7b058e2050a4f44f9"
            ],
            "layout": "IPY_MODEL_4cc60d13bfe945d3804b858a6ae536e2"
          }
        },
        "63429090a8db477cb87db69b638a40ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d910f7982b2f4f06bea68cd89b59a09e",
            "placeholder": "​",
            "style": "IPY_MODEL_078f39612148493cb198f281560fe33e",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "547f795f81c944eca988bd5b5bde9334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e81c79ea1b904c8aaa8f697e6bca98f2",
            "max": 3556392240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b88b97e28a249ce87067f034260f8c0",
            "value": 3556392240
          }
        },
        "c5a79c4a121c4dd7b058e2050a4f44f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cad68e6ac6c423d96627240c58b09ed",
            "placeholder": "​",
            "style": "IPY_MODEL_56e92d71c9db4ffdb1e6899901be565d",
            "value": " 3.56G/3.56G [00:08&lt;00:00, 385MB/s]"
          }
        },
        "4cc60d13bfe945d3804b858a6ae536e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d910f7982b2f4f06bea68cd89b59a09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078f39612148493cb198f281560fe33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e81c79ea1b904c8aaa8f697e6bca98f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b88b97e28a249ce87067f034260f8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cad68e6ac6c423d96627240c58b09ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e92d71c9db4ffdb1e6899901be565d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a89db533f79849aea49aba9bbf752098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb039c39c08e439e83ffb9402178d000",
              "IPY_MODEL_39de3b5729904e8e9c000d4c0c8948eb",
              "IPY_MODEL_67d0a54dee1749e0b5e58e695dc97e9d"
            ],
            "layout": "IPY_MODEL_ccf8f3e90c894c9f8530cf9eca7b89d8"
          }
        },
        "eb039c39c08e439e83ffb9402178d000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106d589a0fe047e3941d9b702b0d0aea",
            "placeholder": "​",
            "style": "IPY_MODEL_94f61634bf8f44a38cedf488a8dd9cba",
            "value": "100%"
          }
        },
        "39de3b5729904e8e9c000d4c0c8948eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c185c02786415d9c92399ba6b9820d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd2218dd8d8849af96252370e4afe1ee",
            "value": 1
          }
        },
        "67d0a54dee1749e0b5e58e695dc97e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93af3729512a4a4a8d34d67ac008f153",
            "placeholder": "​",
            "style": "IPY_MODEL_e3078312364840e8ba16b13313788acc",
            "value": " 1/1 [00:32&lt;00:00, 32.32s/it]"
          }
        },
        "ccf8f3e90c894c9f8530cf9eca7b89d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106d589a0fe047e3941d9b702b0d0aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f61634bf8f44a38cedf488a8dd9cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c185c02786415d9c92399ba6b9820d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2218dd8d8849af96252370e4afe1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93af3729512a4a4a8d34d67ac008f153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3078312364840e8ba16b13313788acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1f68c61dd648cd92b88d82cd36c7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69fe730e18f440b09885fce480049297",
              "IPY_MODEL_214c695c780049c5b2e652ff63bd5820",
              "IPY_MODEL_5be1bc33d88f4dfea768d1baf210affb"
            ],
            "layout": "IPY_MODEL_17db9c9b8b9a417e81d9fee28401cea9"
          }
        },
        "69fe730e18f440b09885fce480049297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e07d6478e4944fe9958b95ee95d1685",
            "placeholder": "​",
            "style": "IPY_MODEL_7660ed01d60b4428990d8ba96fde5abb",
            "value": "model-00004-of-00004.safetensors: "
          }
        },
        "214c695c780049c5b2e652ff63bd5820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30675ec135743fa9b5a49350a51e859",
            "max": 3556392240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01c412f2a6af4a62b3821c4ff724739d",
            "value": 3556392240
          }
        },
        "5be1bc33d88f4dfea768d1baf210affb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd17ed7179d4bfbaa529fe9d3301c49",
            "placeholder": "​",
            "style": "IPY_MODEL_852248290bd44bb3bb19d1b188a92800",
            "value": " 3.57G/? [00:32&lt;00:00, 256MB/s]"
          }
        },
        "17db9c9b8b9a417e81d9fee28401cea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e07d6478e4944fe9958b95ee95d1685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7660ed01d60b4428990d8ba96fde5abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30675ec135743fa9b5a49350a51e859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c412f2a6af4a62b3821c4ff724739d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fd17ed7179d4bfbaa529fe9d3301c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852248290bd44bb3bb19d1b188a92800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdb2dc48357942efb9e8f232880a6d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce8577ae8c464366a5c7d6aa9ab0fd84",
              "IPY_MODEL_d3365c906e1d4c379d8a1312518727bb",
              "IPY_MODEL_4c3033c5997745138885fefd9bd6e697"
            ],
            "layout": "IPY_MODEL_7c861757862841a1a662cd01c3b9e8d7"
          }
        },
        "ce8577ae8c464366a5c7d6aa9ab0fd84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fe4c9e23d454d1ab9596fb2e8dff63d",
            "placeholder": "​",
            "style": "IPY_MODEL_1159116e22b746fb98f98a1663734d7a",
            "value": "100%"
          }
        },
        "d3365c906e1d4c379d8a1312518727bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce4bb1e4b3a4b20bcaddf467af1e290",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4428fe4ea9048a0ac41fe0bb03f36df",
            "value": 1
          }
        },
        "4c3033c5997745138885fefd9bd6e697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079e221a1447412fbc7ca5b05dd2ff9c",
            "placeholder": "​",
            "style": "IPY_MODEL_6db44e8afcd146eeb898ab8b526e8f04",
            "value": " 1/1 [02:10&lt;00:00, 130.96s/it]"
          }
        },
        "7c861757862841a1a662cd01c3b9e8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe4c9e23d454d1ab9596fb2e8dff63d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1159116e22b746fb98f98a1663734d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce4bb1e4b3a4b20bcaddf467af1e290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4428fe4ea9048a0ac41fe0bb03f36df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "079e221a1447412fbc7ca5b05dd2ff9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db44e8afcd146eeb898ab8b526e8f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1cdde4e1f246f8828cd860979785a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abbf08203158425e950ab937064efd04",
              "IPY_MODEL_834ec320909e4461aa749eb90dac047a",
              "IPY_MODEL_290dbd8e730b4e5d8c43e9759602f04d"
            ],
            "layout": "IPY_MODEL_42f3f541baaf4dca81c49983b68db2b0"
          }
        },
        "abbf08203158425e950ab937064efd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd44085f8dd1497792b20e18c9e3af6b",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4b4004d0254dfa84acf5fe4e3f7782",
            "value": "unsloth.F16.gguf: "
          }
        },
        "834ec320909e4461aa749eb90dac047a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da24c4a950f34808a81b0df6e254615b",
            "max": 15237850848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3174b8e369e24812be48bedbb82bd8f4",
            "value": 15237850848
          }
        },
        "290dbd8e730b4e5d8c43e9759602f04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4282d7edbb14fae9a9e760a44707af1",
            "placeholder": "​",
            "style": "IPY_MODEL_b8c569fb4b594cb5a4727679b64acf8c",
            "value": " 15.2G/? [02:10&lt;00:00, 449MB/s]"
          }
        },
        "42f3f541baaf4dca81c49983b68db2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd44085f8dd1497792b20e18c9e3af6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4b4004d0254dfa84acf5fe4e3f7782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da24c4a950f34808a81b0df6e254615b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3174b8e369e24812be48bedbb82bd8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4282d7edbb14fae9a9e760a44707af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c569fb4b594cb5a4727679b64acf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db2be62e264146e8a71fbb2010aaafa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd792f7c049845848475e0e64ca4d9b3",
              "IPY_MODEL_79ad595c73764d158cf4dcab03c7aa4e",
              "IPY_MODEL_a6299769590543f28aafeb4bd7190227"
            ],
            "layout": "IPY_MODEL_ec8466c48b834d9a834970a64e855ee5"
          }
        },
        "fd792f7c049845848475e0e64ca4d9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4f3776591c4b6399fa09d7d7a24040",
            "placeholder": "​",
            "style": "IPY_MODEL_18385cee8a9d4115a3e820973162e6b6",
            "value": ""
          }
        },
        "79ad595c73764d158cf4dcab03c7aa4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14d8bf326994f34aa0a4809ef2de0d5",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c536be78db845dd8bf6406c6294d7c4",
            "value": 4
          }
        },
        "a6299769590543f28aafeb4bd7190227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9de86f98e0f4b3eb74a225fd5c59e00",
            "placeholder": "​",
            "style": "IPY_MODEL_c93953fca6aa4072998b37e9f1e9de88",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04&lt;00:00,  1.15s/it]\n"
          }
        },
        "ec8466c48b834d9a834970a64e855ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4f3776591c4b6399fa09d7d7a24040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18385cee8a9d4115a3e820973162e6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c14d8bf326994f34aa0a4809ef2de0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c536be78db845dd8bf6406c6294d7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9de86f98e0f4b3eb74a225fd5c59e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93953fca6aa4072998b37e9f1e9de88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d579453fbd1042f09621130ba45729d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a4ee2a2ab2745959811d98072c763ee",
              "IPY_MODEL_55c333aeda4e49828ccd0d8ced4dbfb0",
              "IPY_MODEL_e2a371a45ffe4bed93f7a62ee81c5909"
            ],
            "layout": "IPY_MODEL_19724ec0e9fc4e1f951da61b06ac0ecd"
          }
        },
        "6a4ee2a2ab2745959811d98072c763ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe64d344dc7e41f6baf276bb91e6af9e",
            "placeholder": "​",
            "style": "IPY_MODEL_f506023d6c65434385ca8bd0d6086d07",
            "value": "Evaluating MediLearn-Qwen2-7B-GRPO-500Steps: 100%"
          }
        },
        "55c333aeda4e49828ccd0d8ced4dbfb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2870057d82214798b6856aa15e6c9226",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bfc4419728a455d8ee34595b23085fe",
            "value": 35
          }
        },
        "e2a371a45ffe4bed93f7a62ee81c5909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0025ebe3fb94a07b795285c56843e54",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0ab2ccebcf434abf31129b5e8a917b",
            "value": " 35/35 [19:40&lt;00:00, 32.20s/it]"
          }
        },
        "19724ec0e9fc4e1f951da61b06ac0ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe64d344dc7e41f6baf276bb91e6af9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f506023d6c65434385ca8bd0d6086d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2870057d82214798b6856aa15e6c9226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bfc4419728a455d8ee34595b23085fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0025ebe3fb94a07b795285c56843e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0ab2ccebcf434abf31129b5e8a917b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning\n",
        "\n",
        "I'm going to be fintuning Qwen2-7B using Unsloth GRPO\n",
        "\n",
        "Open in [Colab](https://colab.research.google.com/drive/1x9rrEn2_c-I-V4ThzdYqL2dwBSJJ8USA?usp=sharing)"
      ],
      "metadata": {
        "id": "jN6vzrgih7Qw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpM41lmPGgn0"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue_fDDMCGgn0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm==0.8.5.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSdM-RzgGgn1"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm==0.8.5.post1\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiH0Z3BiezAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6c0b9b36-eff6-49c9-abae-2833dd137613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.53.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.33.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.6.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ],
      "source": [
        "#@title Libraries Extra Install { display-mode: \"form\" }\n",
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Qwen"
      ],
      "metadata": {
        "id": "ZZIkPAg-jOQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from huggingface_hub import hf_hub_download\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import numpy as np\n",
        "import warnings\n",
        "import bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4mv956cjAnh",
        "outputId": "d75099ce-e131-4805-fc91-eba8556288fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 07-05 09:22:29 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 07-05 09:22:29 [__init__.py:239] Automatically detected platform cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 1500 # Can increase for longer reasoning traces\n",
        "lora_rank = 64 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen2-7B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.8, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank,\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709,
          "referenced_widgets": [
            "692b3cb7bc2349e08f2c9d80222858a9",
            "64286812472d46d8acd48f4264bdc11e",
            "61bda8d0114b4decb4863850f64c258d",
            "de2b63fbaf3a442186385211613f137f",
            "e24560598a5244798c09726cb4e82284",
            "edc792eb8fa54ede8600565bb5d66246",
            "856e72f5ad1545168af95145d6a34f83",
            "735120592943432399066625b2f47377",
            "1a0c18840a3e453e81778aaff1747405",
            "e839aef6367740b19da84a1824951e94",
            "bd741dee74a64fd8988980312a83cec5",
            "7593462323a44fa48ab5ae4cc74c6b95",
            "d3655772b7404accaca1328d035a7892",
            "049a3dbbc0664571bb984a7f3f337a50",
            "151d345deeb8493788b1bee099755378",
            "77d87c3aa6a145b092f0ab62784c66ce",
            "b381696a3e474e1a830f75b995927f5c",
            "28bbc97d808e496baed7a2247004d9a1",
            "5d2fc3bd7cb441d1929a663a61e73a25",
            "5bfb46bbb9dc42cea4fe7fe7509dbf0e",
            "6430101260f841efbeec741840520667",
            "00b7043be42d4d4aaa92306a534a1f17"
          ]
        },
        "id": "-MTU_ZWmjQkn",
        "outputId": "fee75de7-c0ce-40ee-959a-5b2150cda956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.6.12: Fast Qwen2 patching. Transformers: 4.53.0. vLLM: 0.8.5.post1.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2-7b-instruct-bnb-4bit with actual GPU utilization = 79.08%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1500. Num Sequences = 320.\n",
            "Unsloth: vLLM's KV Cache can use up to 25.15 GB. Also swap space = 6 GB.\n",
            "INFO 07-05 04:46:57 [config.py:717] This model supports multiple tasks: {'classify', 'generate', 'score', 'reward', 'embed'}. Defaulting to 'generate'.\n",
            "INFO 07-05 04:46:57 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=1500.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': [], 'llm_int8_threshold': 6.0}\n",
            "INFO 07-05 04:46:58 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/qwen2-7b-instruct-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2-7b-instruct-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1500, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2-7b-instruct-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"backend\":\"inductor\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"debug\":false,\"dce\":true,\"coordinate_descent_tuning\":true,\"trace.enabled\":false,\"trace.graph_diagram\":false,\"triton.cudagraphs\":true,\"compile_threads\":48,\"max_autotune\":false,\"disable_progress\":false,\"verbose_progress\":true,\"enable_auto_functionalized_v2\":false},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
            "WARNING 07-05 04:46:58 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7c62c0528750>\n",
            "INFO 07-05 04:46:58 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
            "INFO 07-05 04:46:58 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
            "WARNING 07-05 04:46:58 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "INFO 07-05 04:46:58 [gpu_model_runner.py:1329] Starting to load model unsloth/qwen2-7b-instruct-bnb-4bit...\n",
            "INFO 07-05 04:46:59 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 07-05 04:46:59 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
            "INFO 07-05 04:46:59 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "692b3cb7bc2349e08f2c9d80222858a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7593462323a44fa48ab5ae4cc74c6b95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 07-05 04:47:03 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 07-05 04:47:03 [gpu_model_runner.py:1347] Model loading took 5.5142 GiB and 4.292228 seconds\n",
            "INFO 07-05 04:47:20 [backends.py:420] Using cache directory: /root/.cache/vllm/torch_compile_cache/e581ad8dfd/rank_0_0 for vLLM's torch.compile\n",
            "INFO 07-05 04:47:20 [backends.py:430] Dynamo bytecode transform time: 16.26 s\n",
            "INFO 07-05 04:47:30 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 7.210 s\n",
            "INFO 07-05 04:47:33 [monitor.py:33] torch.compile takes 16.26 s in total\n",
            "INFO 07-05 04:47:34 [kv_cache_utils.py:634] GPU KV cache size: 439,360 tokens\n",
            "INFO 07-05 04:47:34 [kv_cache_utils.py:637] Maximum concurrency for 1,500 tokens per request: 292.91x\n",
            "INFO 07-05 04:48:43 [gpu_model_runner.py:1686] Graph capturing finished in 69 secs, took 1.33 GiB\n",
            "INFO 07-05 04:48:43 [core.py:159] init engine (profile, create kv cache, warmup model) took 99.44 seconds\n",
            "Unsloth: Just some info: will skip parsing ['q_norm', 'post_feedforward_layernorm', 'k_norm', 'pre_feedforward_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['q_norm', 'post_feedforward_layernorm', 'k_norm', 'pre_feedforward_layernorm']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.6.12 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ],
      "metadata": {
        "id": "2HucqZ56kBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_REPO_ID = \"Anatomy-Tutor/Anatomy-and-Medical-Dataset\"\n",
        "DATASET_FILENAME = \"processed_medical_and_anatomy.json\""
      ],
      "metadata": {
        "id": "-Jw8oGEWkAlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "print(\"Loading dataset from Hugging Face Hub...\")\n",
        "try:\n",
        "    hf_data_path = hf_hub_download(\n",
        "        repo_id=DATASET_REPO_ID,\n",
        "        filename=DATASET_FILENAME,\n",
        "        repo_type=\"dataset\"\n",
        "    )\n",
        "    with open(hf_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        splits = json.load(f)\n",
        "    ds = DatasetDict({\n",
        "        \"train\": Dataset.from_list(splits[\"train\"]),\n",
        "        \"validation\": Dataset.from_list(splits[\"validation\"]),\n",
        "        \"test\": Dataset.from_list(splits[\"test\"]),\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load or process dataset. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLLB6RYBkXCC",
        "outputId": "d708c4c7-9675-4148-afff-90c6806f5937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from Hugging Face Hub...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "specific_refusal_phrase = \"I am sorry, but I can only answer questions related to human anatomy and medicine.\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are \"Medilearn,\" an expert AI anatomy tutor for a VR application. Your goal is to provide clear, accurate, and educational explanations.\n",
        "\n",
        "**Rules:**\n",
        "1.  **Stay On Topic:** Politely refuse any question not related to human anatomy or medicine. When you refuse a question, you MUST begin your response with the exact phrase: \"{specific_refusal_phrase}\"\n",
        "2.  **Be Direct and Unambiguous:** Provide answers that are clear and to the point. Avoid hedging or overly conversational filler.\n",
        "3.  **MCQ Answering:** For multiple-choice questions, start your response by stating the correct letter or number, followed by a colon and then your brief explanation. For example: \"A: This is the explanation.\"\n",
        "4.  **End Your Turn:** After providing the complete answer and the mandatory safety warning, you MUST output the special token `<|end_of_turn|>`.\n",
        "5.  **Safety First:** Your final sentence before the end-of-turn token must be: \"Always consult a qualified healthcare professional for medical advice.\"\n",
        "\n",
        "**Formatting Requirement:**\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "... your explanation goes here ...\n",
        "</reasoning>\n",
        "<answer>\n",
        "... final answer here ...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()"
      ],
      "metadata": {
        "id": "I2ZBPxb-kYJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common refusal templates\n",
        "refusal_responses = [\n",
        "    f\"{specific_refusal_phrase} My focus is strictly on human health and body systems.\",\n",
        "    f\"{specific_refusal_phrase} Therefore, I cannot provide information on this topic.\",\n",
        "    f\"{specific_refusal_phrase} My knowledge base is specialized in the medical field.\",\n",
        "    f\"{specific_refusal_phrase} I'm designed to assist with anatomical and medical inquiries only.\",\n",
        "    f\"{specific_refusal_phrase} This question falls outside my area of expertise.\",\n",
        "    f\"{specific_refusal_phrase} I recommend seeking information from a source specialized in that subject.\",\n",
        "    f\"{specific_refusal_phrase} My purpose is to educate on human anatomy and medicine.\",\n",
        "    f\"{specific_refusal_phrase} I'm unable to discuss non-health related matters.\",\n",
        "    f\"{specific_refusal_phrase} Please ensure your questions pertain to the human body or medical science.\",\n",
        "    f\"{specific_refusal_phrase} I can only engage with topics within the scope of human anatomy and medicine.\"\n",
        "]\n",
        "\n",
        "# Sample non-medical questions\n",
        "refusal_questions = [\n",
        "    \"What's the capital of France?\",\n",
        "    \"Tell me a joke.\",\n",
        "    \"Who won the World Cup in 2018?\",\n",
        "    \"How do I fix my car's engine?\",\n",
        "    \"What's the weather like today?\",\n",
        "    \"How do I start a business?\",\n",
        "    \"Who painted the Mona Lisa?\",\n",
        "    \"What year did the Titanic sink?\",\n",
        "    \"Which Roman emperor made Christianity the state religion?\",\n",
        "    \"What is the highest mountain in Africa?\",\n",
        "    \"What is the currency of Japan?\",\n",
        "    \"When was the Declaration of Independence signed?\",\n",
        "    \"Who was the first person to walk on the moon?\",\n",
        "    \"What is the longest river in the world?\",\n",
        "    \"Which country is famous for the Eiffel Tower?\",\n",
        "    \"What is the smallest continent by land area?\",\n",
        "    \"How does Wi-Fi work?\",\n",
        "    \"What is an algorithm?\",\n",
        "    \"Explain the concept of cloud computing.\",\n",
        "    \"What does CPU stand for?\",\n",
        "    \"How do I clear my computer's cache?\",\n",
        "    \"What's the difference between RAM and ROM?\",\n",
        "    \"How can I improve my phone's battery life?\",\n",
        "    \"What is cybersecurity?\",\n",
        "    \"What programming language is used for web development?\",\n",
        "    \"How do search engines rank websites?\",\n",
        "    \"Who wrote 'Romeo and Juliet'?\",\n",
        "    \"What is a sonnet?\",\n",
        "    \"Name a famous opera composer.\",\n",
        "    \"What is the primary art form of ballet?\",\n",
        "    \"Who composed the 'Moonlight Sonata'?\",\n",
        "    \"What is the meaning of 'carpe diem'?\",\n",
        "    \"Name a dystopian novel.\",\n",
        "    \"What is the difference between prose and poetry?\",\n",
        "    \"Who is considered the father of English literature?\",\n",
        "    \"What is impressionism in art?\",\n",
        "    \"How do I bake a chocolate cake?\",\n",
        "    \"What are the rules of chess?\",\n",
        "    \"How to change a car tire?\",\n",
        "    \"What's the best way to grow tomatoes?\",\n",
        "    \"How do I knit a scarf?\",\n",
        "    \"What are some good tips for budgeting money?\",\n",
        "    \"How to train a puppy?\",\n",
        "    \"What are common misconceptions about sleep?\",\n",
        "    \"How do you compost kitchen waste?\",\n",
        "    \"What are the basic steps to learning a new language?\",\n",
        "    \"What is the meaning of life?\",\n",
        "    \"Define 'justice.'\",\n",
        "    \"What is free will?\",\n",
        "    \"Explain the concept of infinity.\",\n",
        "    \"What is the purpose of art?\",\n",
        "    \"How do we know what is real?\",\n",
        "    \"What is happiness?\",\n",
        "    \"Discuss the ethics of artificial intelligence.\",\n",
        "    \"What is the nature of time?\",\n",
        "    \"What is the role of government in society?\"\n",
        "]"
      ],
      "metadata": {
        "id": "Y8KybHFfk2V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_refusal_example(question):\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "            {\"role\": \"assistant\", \"content\": random.choice(refusal_responses)},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Generate examples\n",
        "new_refusal_examples = [make_refusal_example(q) for q in refusal_questions]"
      ],
      "metadata": {
        "id": "y0wjiR3Ok41a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add to the existing train dataset\n",
        "original_train_data = ds[\"train\"].to_list()\n",
        "combined_data = original_train_data + new_refusal_examples\n",
        "\n",
        "# Convert back to HF Dataset\n",
        "ds[\"train\"] = Dataset.from_list(combined_data)\n"
      ],
      "metadata": {
        "id": "Uh9YDrDNk7F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(initial_dataset: Dataset) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Reformats an already loaded dataset with a 'messages' structure for GRPO training,\n",
        "    returning a list of dictionaries. Each dictionary will contain a 'prompt'\n",
        "    (in chatML format) and a 'reference_answer'.\n",
        "\n",
        "    Args:\n",
        "        initial_dataset (Dataset): The already loaded dataset (e.g., a specific split like train or validation).\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: A list of dictionaries, where each dictionary represents a reformatted data sample.\n",
        "    \"\"\"\n",
        "    formatted_data = []\n",
        "    # Iterate through the dataset to create a list of dictionaries\n",
        "    for item in initial_dataset:\n",
        "        user_prompt_content = None\n",
        "        assistant_answer_content = None\n",
        "\n",
        "        # Extract user prompt and assistant answer from the 'messages' list\n",
        "        # This assumes 'messages' is a list of dictionaries within each item.\n",
        "        for message in item.get(\"messages\", []):\n",
        "            if message.get(\"role\") == \"user\":\n",
        "                user_prompt_content = message.get(\"content\")\n",
        "            elif message.get(\"role\") == \"assistant\":\n",
        "                assistant_answer_content = message.get(\"content\")\n",
        "\n",
        "        # Ensure both user prompt and assistant answer are found\n",
        "        if user_prompt_content is not None and assistant_answer_content is not None:\n",
        "            # Create the prompt in chatML format, including the general SYSTEM_PROMPT\n",
        "            prompt_messages = [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": user_prompt_content},\n",
        "            ]\n",
        "\n",
        "            # Create a dictionary for the current item\n",
        "            formatted_item = {\n",
        "                \"prompt\": prompt_messages,\n",
        "                \"answer\": assistant_answer_content,\n",
        "            }\n",
        "            formatted_data.append(formatted_item)\n",
        "        else:\n",
        "            print(f\"Skipping item due to missing user prompt or assistant answer in messages: {item}\")\n",
        "\n",
        "    return formatted_data"
      ],
      "metadata": {
        "id": "GbOJf1DrlYOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_prepared_dataset = prepare_dataset(initial_dataset=ds[\"train\"])\n",
        "print(my_prepared_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VvVtdYflZXu",
        "outputId": "a183a6d5-cae5-4ef2-8448-529a8c4b0121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': [{'role': 'system', 'content': '\\nYou are \"Medilearn,\" an expert AI anatomy tutor for a VR application. Your goal is to provide clear, accurate, and educational explanations.\\n\\n**Rules:**\\n1.  **Stay On Topic:** Politely refuse any question not related to human anatomy or medicine. When you refuse a question, you MUST begin your response with the exact phrase: \"{specific_refusal_phrase}\"\\n2.  **Be Direct and Unambiguous:** Provide answers that are clear and to the point. Avoid hedging or overly conversational filler.\\n3.  **MCQ Answering:** For multiple-choice questions, start your response by stating the correct letter or number, followed by a colon and then your brief explanation. For example: \"A: This is the explanation.\"\\n4.  **End Your Turn:** After providing the complete answer and the mandatory safety warning, you MUST output the special token `<|end_of_turn|>`.\\n5.  **Safety First:** Your final sentence before the end-of-turn token must be: \"Always consult a qualified healthcare professional for medical advice.\"\\n\\n**Formatting Requirement:**\\nRespond in the following format:\\n<reasoning>\\n... your explanation goes here ...\\n</reasoning>\\n<answer>\\n... final answer here ...\\n</answer>\\n'}, {'role': 'user', 'content': 'A 34-year -old man presented to the Emergency Department with a 2-day history of abdominal pain, fever, malaise a. On examination he was pyrexial with no other abdominal signs. CT Abdomen :lesion in the liver with a fluid level. The most likely diagnosis is?\\na-Hydatid liver disease\\nb-Haemangioma of liver\\nC-Amoebic liver abscess\\nD-Pyogenic liver abscess.'}], 'answer': 'D'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reward Functions\n"
      ],
      "metadata": {
        "id": "-f_dTFpElawP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reasoning_start = \"<reasoning>\"\n",
        "reasoning_end   = \"</reasoning>\"\n",
        "solution_start  = \"<answer>\"\n",
        "solution_end    = \"</answer>\""
      ],
      "metadata": {
        "id": "BHNweDPRmBxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_format = re.compile(\n",
        "    rf\"^[\\s]{{0,}}\"\\\n",
        "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\\\n",
        "    rf\"{solution_start}(.+?){solution_end}\"\\\n",
        "    rf\"[\\s]{{0,}}$\",\n",
        "    flags = re.MULTILINE | re.DOTALL\n",
        ")"
      ],
      "metadata": {
        "id": "crQxOb4Kl1Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_xml_answer(text: str) -> str:\n",
        "    match = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "def extract_xml_section(text: str, section: str) -> str:\n",
        "    m = re.search(f\"<{section}>(.*?)</{section}>\", text, re.DOTALL)\n",
        "    return m.group(1).strip() if m else \"\"\n",
        "\n",
        "\n",
        "def answer_semantic_similarity(completions, prompts, answer, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards based on the semantic similarity (BERTScore F1) between\n",
        "    the model's generated answer and the reference answer.\n",
        "    Top priority: scale BERTScore F1 (0–1) up to [0, +10].\n",
        "    \"\"\"\n",
        "    import inspect\n",
        "\n",
        "    # Try to extract current step\n",
        "    step = kwargs.get(\"step\", None)\n",
        "    if step is None:\n",
        "        for frame_info in inspect.stack():\n",
        "            frame = frame_info.frame\n",
        "            if \"self\" in frame.f_locals and hasattr(frame.f_locals[\"self\"], \"state\"):\n",
        "                step = getattr(frame.f_locals[\"self\"].state, \"global_step\", None)\n",
        "                break\n",
        "\n",
        "    # 1) Extract model‐generated answers\n",
        "    responses = [c[0][\"content\"] for c in completions]\n",
        "    preds = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # 2) Debug print ONLY if step was found and is a multiple of 10\n",
        "    if step is not None and step % 100 == 0:\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "        print(f\"[Step {step}] Semantic Similarity Debug\")\n",
        "        for i, (prompt, r, p) in enumerate(zip(prompts, responses, preds)):\n",
        "            print(f\"Prompt:\\n{prompt[-1]['content']}\")\n",
        "            print(f\"Model Output:\\n{r}\")\n",
        "            print(f\"Extracted Answer:\\n{p}\")\n",
        "            print(\"-\" * 30)\n",
        "        print(\"=\" * 40 + \"\\n\")\n",
        "\n",
        "    # 3) Align with references\n",
        "    refs = answer[:len(preds)]\n",
        "\n",
        "    # 4) Compute BERTScore\n",
        "    P, R, F1 = bert_score.score(\n",
        "        preds,\n",
        "        refs,\n",
        "        lang=\"en\",\n",
        "        rescale_with_baseline=True\n",
        "    )\n",
        "\n",
        "    # 5) Scale each F1 value by 10\n",
        "    return [f1 * 10.0 for f1 in F1.tolist()]\n",
        "\n",
        "\n",
        "\n",
        "def match_format_exactly(completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards for exact adherence to the specified XML output format.\n",
        "    High priority: exact format match → +8, otherwise 0.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for comp in completions:\n",
        "        scores.append(8.0 if match_format.search(comp[0][\"content\"]) else 0.0)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def match_format_approximately(completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards for approximate adherence to the XML output format by counting tags.\n",
        "    Medium priority: each correct tag +1, each missing/extra –1.\n",
        "    Total range: 4 tags → [–4, +4]\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for comp in completions:\n",
        "        r = comp[0][\"content\"]\n",
        "        score = 0\n",
        "        score += 1.0 if r.count(reasoning_start) == 1 else -1.0\n",
        "        score += 1.0 if r.count(reasoning_end) == 1 else -1.0\n",
        "        score += 1.0 if r.count(solution_start) == 1 else -1.0\n",
        "        score += 1.0 if r.count(solution_end) == 1 else -1.0\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def on_topic_refusal(completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards for staying on topic and penalizes for out-of-bounds refusals\n",
        "    (i.e., if the model incorrectly refuses a relevant question).\n",
        "    Conversely, for *out-of-scope* questions, it effectively rewards a proper refusal (by not penalizing).\n",
        "    Medium-low priority: good answer +2, penalty (refusal) 0.\n",
        "    \"\"\"\n",
        "    bad_kw = [\n",
        "        \"i don't know\", \"dont know\", \"not sure\", \"no idea\", \"beyond my knowledge\",\n",
        "        \"outside my knowledge\", \"off-topic\", \"irrelevant\", \"i have no information\",\n",
        "        \"i'm sorry\", \"i am sorry\", \"apologies\", \"i apologize\", \"my apologies\",\n",
        "        \"cannot answer\", \"can’t answer\", \"unable to answer\", \"cannot provide\",\n",
        "        \"outside my scope\", \"knowledge cutoff\", \"cutoff date\",\n",
        "    ]\n",
        "    scores = []\n",
        "    for comp in completions:\n",
        "        ans = extract_xml_section(comp[0][\"content\"], \"answer\").lower()\n",
        "        scores.append(0.0 if any(k in ans for k in bad_kw) else 2.0)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def response_pacing_and_length(completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards for the length and pacing of the reasoning and answer sections.\n",
        "    Low priority: raw pacing score [0,1], scale to [0, 1.5].\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for comp in completions:\n",
        "        txt = comp[0][\"content\"]\n",
        "        r = extract_xml_section(txt, \"reasoning\").split()\n",
        "        a = extract_xml_section(txt, \"answer\").split()\n",
        "        mid_r, mid_a = (20 + 300) / 2, (5 + 200) / 2\n",
        "        sc_r = max(0, 1 - abs(len(r) - mid_r) / (300 - 20))\n",
        "        sc_a = max(0, 1 - abs(len(a) - mid_a) / (200 - 5))\n",
        "        # average [0,1], then *1.5\n",
        "        scores.append(((sc_r + sc_a) / 2) * 1.5)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def disclaimer_presence(completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards for including the mandatory safety disclaimer as the final sentence\n",
        "    within the <answer> tag. Penalizes if missing.\n",
        "    Medium priority: +3 for exact final placement, +2 for presence, -1 for missing.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    mandatory_disclaimer = \"Always consult a qualified healthcare professional for medical advice.\"\n",
        "\n",
        "    for comp in completions:\n",
        "        assistant_content = comp[0][\"content\"]\n",
        "        extracted_answer = extract_xml_answer(assistant_content)\n",
        "        cleaned_answer = extracted_answer.replace(\"<|end_of_turn|>\", \"\").strip()\n",
        "\n",
        "        sentences = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', cleaned_answer) if s.strip()]\n",
        "\n",
        "        if sentences and sentences[-1] == mandatory_disclaimer:\n",
        "            scores.append(3.0)\n",
        "        elif mandatory_disclaimer in cleaned_answer:\n",
        "            scores.append(2.0)\n",
        "        else:\n",
        "            scores.append(-1)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "6c6B9J-8l2wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_funcs = [\n",
        "    answer_semantic_similarity, # [0,10]\n",
        "    match_format_exactly, # [0,8]\n",
        "    match_format_approximately, # [–4,+4]\n",
        "    on_topic_refusal, # [0,2]\n",
        "    response_pacing_and_length, # [0,1.5]\n",
        "    disclaimer_presence # [-1, 3]\n",
        "]\n"
      ],
      "metadata": {
        "id": "86RJEXsbnN4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BTP277k8U4_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_prompt_length = 500\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 5,\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 4, # Decrease if out of memory\n",
        "    max_prompt_length = max_prompt_length,\n",
        "    max_completion_length = max_seq_length - max_prompt_length,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 500,\n",
        "    save_steps = 10,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        "\n",
        "    loss_type = \"dr_grpo\",\n",
        "    epsilon = 0.2,\n",
        "    epsilon_high = 0.28,\n",
        "    delta = 1.5,\n",
        "    mask_truncated_completions = True,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOnkCfVcnQaj",
        "outputId": "d6caa8fd-2809-4bcd-bd25-a8d1c9e659e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: The Dr GRPO paper recommends setting `scale_rewards` to False! Will override. Set it to `None` to force False.\n",
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize trainer\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = reward_funcs,\n",
        "    args = training_args,\n",
        "    train_dataset = my_prepared_dataset,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yj-7lr5aoezV",
        "outputId": "88f1942c-3a41-44e0-d0e4-b39cafedace8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 21,724 | Num Epochs = 1 | Total steps = 500\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 161,480,704 of 7,000,000,000 (2.31% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "[Step 0] Semantic Similarity Debug\n",
            "Prompt:\n",
            "A substance that is freely filtered, completely reabsorbed and not secreted has a renal plasma clearance:/na) Equal to GFR./nb) Equal to effective renal plasma flow./nc) Higher than GFR./nd) Equal to zero.\n",
            "Model Output:\n",
            "<reasoning>When a substance is freely filtered, completely reabsorbed, and not secreted by the kidneys, it indicates that the substance does not undergo any net loss once filtered from the glomerular filtrate. The substance exits the nephrons unchanged, suggesting no net alteration in plasma substance concentration before it's filtered compared to reabsorbed. This scenario directly correlates with a renal plasma clearance of zero, as there's no net loss of the substance to gauge the clearance rate.</reasoning>\n",
            "<answer>nd) Equal to zero.</answer>\n",
            "<end_of_turn> Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "nd) Equal to zero.\n",
            "------------------------------\n",
            "Prompt:\n",
            "A substance that is freely filtered, completely reabsorbed and not secreted has a renal plasma clearance:/na) Equal to GFR./nb) Equal to effective renal plasma flow./nc) Higher than GFR./nd) Equal to zero.\n",
            "Model Output:\n",
            "<reasoning>\n",
            "A substance that undergoes no filtration, complete reabsorption, and no secretion follows a round trip through the renal tubules without any waste product accumulation. This means the substance is not present in the urine. Therefore, its renal plasma clearance is measured as zero, as it doesn't add to the glomerular filtration rate.\n",
            "</reasoning>\n",
            "<answer>\n",
            "nd) Equal to zero.\n",
            "Extracted Answer:\n",
            "\n",
            "------------------------------\n",
            "Prompt:\n",
            "A substance that is freely filtered, completely reabsorbed and not secreted has a renal plasma clearance:/na) Equal to GFR./nb) Equal to effective renal plasma flow./nc) Higher than GFR./nd) Equal to zero.\n",
            "Model Output:\n",
            "nd: This means the substance is completely reabsorbed, resulting in its renal plasma clearance being equal to zero, as it does not appear in the urine.\n",
            "<|end_of_turn|> Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "\n",
            "------------------------------\n",
            "Prompt:\n",
            "A substance that is freely filtered, completely reabsorbed and not secreted has a renal plasma clearance:/na) Equal to GFR./nb) Equal to effective renal plasma flow./nc) Higher than GFR./nd) Equal to zero.\n",
            "Model Output:\n",
            "<reasoning>The renal plasma clearance of a substance is the volume of plasma that is effectively cleared from the kidney per minute, considering filtration, reabsorption, and secretion. If a substance is completely reabsorbed and not secreted, it means that no plasma is removed from the filtration segment reaching the renal tubule. Therefore, the final volume that is cleared is equivalent to the volume of plasma filtered by the glomerulus, which is the glomerular filtration rate (GFR).</reasoning>\n",
            "<answer>\n",
            "Hence, the renal plasma clearance of such a substance is equal to GFR.\n",
            "</answer>\n",
            "<end_of_turn> Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "Hence, the renal plasma clearance of such a substance is equal to GFR.\n",
            "------------------------------\n",
            "========================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:48:13, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / answer_semantic_similarity / mean</th>\n",
              "      <th>rewards / answer_semantic_similarity / std</th>\n",
              "      <th>rewards / match_format_exactly / mean</th>\n",
              "      <th>rewards / match_format_exactly / std</th>\n",
              "      <th>rewards / match_format_approximately / mean</th>\n",
              "      <th>rewards / match_format_approximately / std</th>\n",
              "      <th>rewards / on_topic_refusal / mean</th>\n",
              "      <th>rewards / on_topic_refusal / std</th>\n",
              "      <th>rewards / response_pacing_and_length / mean</th>\n",
              "      <th>rewards / response_pacing_and_length / std</th>\n",
              "      <th>rewards / disclaimer_presence / mean</th>\n",
              "      <th>rewards / disclaimer_presence / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>-0.829700</td>\n",
              "      <td>-27.136355</td>\n",
              "      <td>29.232609</td>\n",
              "      <td>148.500000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>219.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>148.500000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>219.800000</td>\n",
              "      <td>0.000619</td>\n",
              "      <td>-30.950413</td>\n",
              "      <td>23.549010</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>3.447521</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>3.089560</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.814059</td>\n",
              "      <td>0.122864</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>-0.208000</td>\n",
              "      <td>-42.028995</td>\n",
              "      <td>12.470500</td>\n",
              "      <td>75.950000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>127.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.950000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>127.200000</td>\n",
              "      <td>0.001458</td>\n",
              "      <td>-41.431081</td>\n",
              "      <td>11.177933</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.300000</td>\n",
              "      <td>1.858506</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.702088</td>\n",
              "      <td>0.041827</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>-0.573100</td>\n",
              "      <td>-32.782944</td>\n",
              "      <td>27.581190</td>\n",
              "      <td>179.250000</td>\n",
              "      <td>125.200000</td>\n",
              "      <td>244.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>179.250000</td>\n",
              "      <td>125.200000</td>\n",
              "      <td>244.400000</td>\n",
              "      <td>0.000962</td>\n",
              "      <td>-34.346278</td>\n",
              "      <td>21.688522</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.523760</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>3.058762</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.763334</td>\n",
              "      <td>0.143301</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>-0.379300</td>\n",
              "      <td>-41.772778</td>\n",
              "      <td>18.809571</td>\n",
              "      <td>95.400000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>167.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>95.400000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>167.600000</td>\n",
              "      <td>0.001491</td>\n",
              "      <td>-41.378151</td>\n",
              "      <td>15.745195</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>2.424621</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.705374</td>\n",
              "      <td>0.044788</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.321300</td>\n",
              "      <td>-35.128761</td>\n",
              "      <td>19.197273</td>\n",
              "      <td>170.700000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>254.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>170.700000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>254.400000</td>\n",
              "      <td>0.001181</td>\n",
              "      <td>-36.891934</td>\n",
              "      <td>15.216666</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>2.850008</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.763173</td>\n",
              "      <td>0.066522</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.461880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>-0.307700</td>\n",
              "      <td>-31.664046</td>\n",
              "      <td>28.692642</td>\n",
              "      <td>96.350000</td>\n",
              "      <td>55.800000</td>\n",
              "      <td>152.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.350000</td>\n",
              "      <td>55.800000</td>\n",
              "      <td>152.200000</td>\n",
              "      <td>0.001112</td>\n",
              "      <td>-33.374114</td>\n",
              "      <td>23.088895</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.523760</td>\n",
              "      <td>-1.800000</td>\n",
              "      <td>3.148382</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.710069</td>\n",
              "      <td>0.045857</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>-0.559500</td>\n",
              "      <td>-26.055703</td>\n",
              "      <td>27.024432</td>\n",
              "      <td>111.550000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>185.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.550000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>185.600000</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>-28.294968</td>\n",
              "      <td>22.521996</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>-1.100000</td>\n",
              "      <td>3.190563</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.739265</td>\n",
              "      <td>0.070930</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>-0.125700</td>\n",
              "      <td>-28.904487</td>\n",
              "      <td>25.887299</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>251.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>251.800000</td>\n",
              "      <td>0.002159</td>\n",
              "      <td>-31.466403</td>\n",
              "      <td>20.787637</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.523760</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2.860510</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.761916</td>\n",
              "      <td>0.120953</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>-0.275500</td>\n",
              "      <td>-30.653377</td>\n",
              "      <td>20.535104</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>84.400000</td>\n",
              "      <td>205.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>84.400000</td>\n",
              "      <td>205.800000</td>\n",
              "      <td>0.027291</td>\n",
              "      <td>-34.077600</td>\n",
              "      <td>15.990381</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.647521</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>2.421503</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.824224</td>\n",
              "      <td>0.089053</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>-0.423400</td>\n",
              "      <td>-18.695454</td>\n",
              "      <td>32.491791</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>71.400000</td>\n",
              "      <td>237.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>71.400000</td>\n",
              "      <td>237.800000</td>\n",
              "      <td>0.004860</td>\n",
              "      <td>-22.867050</td>\n",
              "      <td>26.883811</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.400571</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.771597</td>\n",
              "      <td>0.114168</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>-0.295700</td>\n",
              "      <td>-12.956203</td>\n",
              "      <td>26.094051</td>\n",
              "      <td>133.950000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>185.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.950000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>185.400000</td>\n",
              "      <td>0.441368</td>\n",
              "      <td>-18.965468</td>\n",
              "      <td>20.865020</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.809265</td>\n",
              "      <td>0.104596</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>-0.663900</td>\n",
              "      <td>-3.501267</td>\n",
              "      <td>27.543852</td>\n",
              "      <td>119.350000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>163.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>119.350000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>163.600000</td>\n",
              "      <td>0.155161</td>\n",
              "      <td>-11.627411</td>\n",
              "      <td>22.867348</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>3.323760</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>2.148382</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.826144</td>\n",
              "      <td>0.094503</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>-0.703500</td>\n",
              "      <td>-1.818406</td>\n",
              "      <td>13.977199</td>\n",
              "      <td>139.500000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>202.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>139.500000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>202.600000</td>\n",
              "      <td>0.050100</td>\n",
              "      <td>-10.771462</td>\n",
              "      <td>11.402712</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>1.723760</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>1.230940</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.853056</td>\n",
              "      <td>0.091541</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>-0.288300</td>\n",
              "      <td>-0.142535</td>\n",
              "      <td>27.047186</td>\n",
              "      <td>181.300000</td>\n",
              "      <td>110.200000</td>\n",
              "      <td>255.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>181.300000</td>\n",
              "      <td>110.200000</td>\n",
              "      <td>255.800000</td>\n",
              "      <td>0.068146</td>\n",
              "      <td>-9.330508</td>\n",
              "      <td>21.803862</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.887974</td>\n",
              "      <td>0.171875</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>-0.015300</td>\n",
              "      <td>18.818952</td>\n",
              "      <td>2.240997</td>\n",
              "      <td>222.250000</td>\n",
              "      <td>166.600000</td>\n",
              "      <td>277.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>222.250000</td>\n",
              "      <td>166.600000</td>\n",
              "      <td>277.200000</td>\n",
              "      <td>0.121830</td>\n",
              "      <td>4.820206</td>\n",
              "      <td>2.244275</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.998747</td>\n",
              "      <td>0.086953</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>-0.159500</td>\n",
              "      <td>12.898662</td>\n",
              "      <td>9.117713</td>\n",
              "      <td>176.100000</td>\n",
              "      <td>117.600000</td>\n",
              "      <td>246.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>176.100000</td>\n",
              "      <td>117.600000</td>\n",
              "      <td>246.800000</td>\n",
              "      <td>0.022698</td>\n",
              "      <td>0.477454</td>\n",
              "      <td>7.268695</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.782971</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.921209</td>\n",
              "      <td>0.093132</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>-0.055800</td>\n",
              "      <td>12.706045</td>\n",
              "      <td>8.440972</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>216.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>216.600000</td>\n",
              "      <td>0.033652</td>\n",
              "      <td>-0.327603</td>\n",
              "      <td>6.141421</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.933647</td>\n",
              "      <td>0.088281</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>15.657555</td>\n",
              "      <td>7.789111</td>\n",
              "      <td>198.600000</td>\n",
              "      <td>104.800000</td>\n",
              "      <td>306.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>198.600000</td>\n",
              "      <td>104.800000</td>\n",
              "      <td>306.600000</td>\n",
              "      <td>0.038229</td>\n",
              "      <td>2.450631</td>\n",
              "      <td>6.400422</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906923</td>\n",
              "      <td>0.138495</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.118300</td>\n",
              "      <td>10.704346</td>\n",
              "      <td>14.452601</td>\n",
              "      <td>195.800000</td>\n",
              "      <td>139.600000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.800000</td>\n",
              "      <td>139.600000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>1.096983</td>\n",
              "      <td>-1.226159</td>\n",
              "      <td>11.666339</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>1.723760</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>1.357188</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.930505</td>\n",
              "      <td>0.101067</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>-0.014500</td>\n",
              "      <td>11.536143</td>\n",
              "      <td>10.155818</td>\n",
              "      <td>205.600000</td>\n",
              "      <td>130.400000</td>\n",
              "      <td>278.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>205.600000</td>\n",
              "      <td>130.400000</td>\n",
              "      <td>278.600000</td>\n",
              "      <td>0.036629</td>\n",
              "      <td>-0.170749</td>\n",
              "      <td>7.038663</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>1.723760</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.323760</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906892</td>\n",
              "      <td>0.123112</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>14.637914</td>\n",
              "      <td>7.325677</td>\n",
              "      <td>212.900000</td>\n",
              "      <td>150.600000</td>\n",
              "      <td>301.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212.900000</td>\n",
              "      <td>150.600000</td>\n",
              "      <td>301.800000</td>\n",
              "      <td>0.044007</td>\n",
              "      <td>1.678645</td>\n",
              "      <td>5.452676</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.959269</td>\n",
              "      <td>0.091115</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>-0.001100</td>\n",
              "      <td>17.700205</td>\n",
              "      <td>1.487869</td>\n",
              "      <td>161.100000</td>\n",
              "      <td>99.200000</td>\n",
              "      <td>236.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>161.100000</td>\n",
              "      <td>99.200000</td>\n",
              "      <td>236.200000</td>\n",
              "      <td>0.037776</td>\n",
              "      <td>3.803866</td>\n",
              "      <td>1.468735</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.070256</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.327300</td>\n",
              "      <td>5.999846</td>\n",
              "      <td>17.272595</td>\n",
              "      <td>199.650000</td>\n",
              "      <td>132.800000</td>\n",
              "      <td>278.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>199.650000</td>\n",
              "      <td>132.800000</td>\n",
              "      <td>278.200000</td>\n",
              "      <td>0.052405</td>\n",
              "      <td>-5.353217</td>\n",
              "      <td>12.753616</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.323760</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>1.430940</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.953063</td>\n",
              "      <td>0.126928</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>-0.000800</td>\n",
              "      <td>17.836309</td>\n",
              "      <td>2.290389</td>\n",
              "      <td>200.450000</td>\n",
              "      <td>105.800000</td>\n",
              "      <td>325.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.450000</td>\n",
              "      <td>105.800000</td>\n",
              "      <td>325.800000</td>\n",
              "      <td>0.040347</td>\n",
              "      <td>3.866811</td>\n",
              "      <td>2.297816</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.969499</td>\n",
              "      <td>0.122384</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.285400</td>\n",
              "      <td>14.058205</td>\n",
              "      <td>7.555011</td>\n",
              "      <td>184.150000</td>\n",
              "      <td>97.200000</td>\n",
              "      <td>265.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>184.150000</td>\n",
              "      <td>97.200000</td>\n",
              "      <td>265.000000</td>\n",
              "      <td>0.045627</td>\n",
              "      <td>0.736413</td>\n",
              "      <td>6.315067</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.921793</td>\n",
              "      <td>0.118699</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>-0.028900</td>\n",
              "      <td>14.704310</td>\n",
              "      <td>7.436276</td>\n",
              "      <td>177.250000</td>\n",
              "      <td>104.400000</td>\n",
              "      <td>231.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>177.250000</td>\n",
              "      <td>104.400000</td>\n",
              "      <td>231.800000</td>\n",
              "      <td>0.039341</td>\n",
              "      <td>1.173276</td>\n",
              "      <td>6.673806</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.077538</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>-0.017100</td>\n",
              "      <td>16.916330</td>\n",
              "      <td>1.145036</td>\n",
              "      <td>158.550000</td>\n",
              "      <td>102.600000</td>\n",
              "      <td>218.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>158.550000</td>\n",
              "      <td>102.600000</td>\n",
              "      <td>218.600000</td>\n",
              "      <td>0.051904</td>\n",
              "      <td>3.105980</td>\n",
              "      <td>0.880706</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.910350</td>\n",
              "      <td>0.101781</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.156400</td>\n",
              "      <td>17.435637</td>\n",
              "      <td>7.480157</td>\n",
              "      <td>181.550000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>266.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>181.550000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>266.600000</td>\n",
              "      <td>0.058279</td>\n",
              "      <td>3.971863</td>\n",
              "      <td>6.419573</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.963774</td>\n",
              "      <td>0.086151</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.219700</td>\n",
              "      <td>14.394741</td>\n",
              "      <td>7.078499</td>\n",
              "      <td>233.350000</td>\n",
              "      <td>180.400000</td>\n",
              "      <td>291.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>233.350000</td>\n",
              "      <td>180.400000</td>\n",
              "      <td>291.600000</td>\n",
              "      <td>0.045010</td>\n",
              "      <td>0.938858</td>\n",
              "      <td>6.028017</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.955883</td>\n",
              "      <td>0.077848</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>-0.002700</td>\n",
              "      <td>15.460613</td>\n",
              "      <td>1.678251</td>\n",
              "      <td>216.600000</td>\n",
              "      <td>153.200000</td>\n",
              "      <td>289.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>216.600000</td>\n",
              "      <td>153.200000</td>\n",
              "      <td>289.600000</td>\n",
              "      <td>0.046693</td>\n",
              "      <td>1.443473</td>\n",
              "      <td>1.686544</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.017139</td>\n",
              "      <td>0.068906</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>18.804437</td>\n",
              "      <td>0.797561</td>\n",
              "      <td>146.500000</td>\n",
              "      <td>105.800000</td>\n",
              "      <td>195.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.500000</td>\n",
              "      <td>105.800000</td>\n",
              "      <td>195.200000</td>\n",
              "      <td>0.062310</td>\n",
              "      <td>4.867555</td>\n",
              "      <td>0.772552</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.936882</td>\n",
              "      <td>0.091014</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>-0.013600</td>\n",
              "      <td>15.763035</td>\n",
              "      <td>0.928001</td>\n",
              "      <td>207.550000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>207.550000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>1.769408</td>\n",
              "      <td>0.904305</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.993626</td>\n",
              "      <td>0.105147</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.049500</td>\n",
              "      <td>18.909990</td>\n",
              "      <td>1.305200</td>\n",
              "      <td>203.500000</td>\n",
              "      <td>106.400000</td>\n",
              "      <td>303.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>203.500000</td>\n",
              "      <td>106.400000</td>\n",
              "      <td>303.800000</td>\n",
              "      <td>0.047194</td>\n",
              "      <td>4.963774</td>\n",
              "      <td>1.321333</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.946216</td>\n",
              "      <td>0.096957</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>-0.026400</td>\n",
              "      <td>15.974041</td>\n",
              "      <td>1.372986</td>\n",
              "      <td>192.650000</td>\n",
              "      <td>159.200000</td>\n",
              "      <td>242.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>192.650000</td>\n",
              "      <td>159.200000</td>\n",
              "      <td>242.800000</td>\n",
              "      <td>0.630121</td>\n",
              "      <td>1.988196</td>\n",
              "      <td>1.360502</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.985845</td>\n",
              "      <td>0.061590</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>16.906900</td>\n",
              "      <td>2.178039</td>\n",
              "      <td>264.000000</td>\n",
              "      <td>195.400000</td>\n",
              "      <td>343.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>264.000000</td>\n",
              "      <td>195.400000</td>\n",
              "      <td>343.800000</td>\n",
              "      <td>0.163362</td>\n",
              "      <td>2.511395</td>\n",
              "      <td>1.980565</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.995505</td>\n",
              "      <td>0.111067</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>15.835276</td>\n",
              "      <td>0.964939</td>\n",
              "      <td>188.150000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>259.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.150000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>259.000000</td>\n",
              "      <td>0.053576</td>\n",
              "      <td>1.841615</td>\n",
              "      <td>0.971814</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.993661</td>\n",
              "      <td>0.088794</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>-0.048400</td>\n",
              "      <td>18.279152</td>\n",
              "      <td>2.855272</td>\n",
              "      <td>162.600000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>238.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>162.600000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>238.800000</td>\n",
              "      <td>0.065364</td>\n",
              "      <td>4.740798</td>\n",
              "      <td>1.654584</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.938355</td>\n",
              "      <td>0.139061</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.029400</td>\n",
              "      <td>16.577200</td>\n",
              "      <td>1.531341</td>\n",
              "      <td>151.150000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>230.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>151.150000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>230.200000</td>\n",
              "      <td>0.065863</td>\n",
              "      <td>2.672074</td>\n",
              "      <td>1.557275</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.905127</td>\n",
              "      <td>0.070736</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>-0.043700</td>\n",
              "      <td>15.751403</td>\n",
              "      <td>7.753074</td>\n",
              "      <td>165.550000</td>\n",
              "      <td>105.800000</td>\n",
              "      <td>221.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>165.550000</td>\n",
              "      <td>105.800000</td>\n",
              "      <td>221.000000</td>\n",
              "      <td>0.080013</td>\n",
              "      <td>2.116125</td>\n",
              "      <td>6.685581</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.935278</td>\n",
              "      <td>0.088864</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>16.724705</td>\n",
              "      <td>1.955844</td>\n",
              "      <td>140.800000</td>\n",
              "      <td>108.800000</td>\n",
              "      <td>179.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>140.800000</td>\n",
              "      <td>108.800000</td>\n",
              "      <td>179.600000</td>\n",
              "      <td>0.107116</td>\n",
              "      <td>2.696868</td>\n",
              "      <td>1.645419</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.927837</td>\n",
              "      <td>0.073429</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>16.653461</td>\n",
              "      <td>0.634303</td>\n",
              "      <td>129.150000</td>\n",
              "      <td>101.800000</td>\n",
              "      <td>163.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>129.150000</td>\n",
              "      <td>101.800000</td>\n",
              "      <td>163.400000</td>\n",
              "      <td>0.090769</td>\n",
              "      <td>2.853506</td>\n",
              "      <td>0.426421</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.899955</td>\n",
              "      <td>0.058673</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.022600</td>\n",
              "      <td>15.484253</td>\n",
              "      <td>7.967705</td>\n",
              "      <td>148.650000</td>\n",
              "      <td>104.400000</td>\n",
              "      <td>189.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>148.650000</td>\n",
              "      <td>104.400000</td>\n",
              "      <td>189.400000</td>\n",
              "      <td>0.912429</td>\n",
              "      <td>2.069174</td>\n",
              "      <td>6.992477</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.915079</td>\n",
              "      <td>0.074149</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>19.521911</td>\n",
              "      <td>1.106362</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>122.600000</td>\n",
              "      <td>201.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>122.600000</td>\n",
              "      <td>201.200000</td>\n",
              "      <td>0.072800</td>\n",
              "      <td>5.585987</td>\n",
              "      <td>1.084716</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.935924</td>\n",
              "      <td>0.043109</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.010400</td>\n",
              "      <td>18.474524</td>\n",
              "      <td>1.104541</td>\n",
              "      <td>183.350000</td>\n",
              "      <td>118.200000</td>\n",
              "      <td>284.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>183.350000</td>\n",
              "      <td>118.200000</td>\n",
              "      <td>284.600000</td>\n",
              "      <td>0.071494</td>\n",
              "      <td>4.103789</td>\n",
              "      <td>0.890905</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.970735</td>\n",
              "      <td>0.071883</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.461880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.225100</td>\n",
              "      <td>9.090857</td>\n",
              "      <td>9.141756</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>160.800000</td>\n",
              "      <td>298.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>160.800000</td>\n",
              "      <td>298.600000</td>\n",
              "      <td>0.041315</td>\n",
              "      <td>-4.169397</td>\n",
              "      <td>7.747517</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>0.923760</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.230940</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.060254</td>\n",
              "      <td>0.113918</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>17.294953</td>\n",
              "      <td>2.110026</td>\n",
              "      <td>195.500000</td>\n",
              "      <td>123.800000</td>\n",
              "      <td>272.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.500000</td>\n",
              "      <td>123.800000</td>\n",
              "      <td>272.600000</td>\n",
              "      <td>0.063210</td>\n",
              "      <td>3.862343</td>\n",
              "      <td>1.567536</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.932610</td>\n",
              "      <td>0.120162</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>-0.021700</td>\n",
              "      <td>18.043825</td>\n",
              "      <td>1.405528</td>\n",
              "      <td>189.950000</td>\n",
              "      <td>117.400000</td>\n",
              "      <td>276.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>189.950000</td>\n",
              "      <td>117.400000</td>\n",
              "      <td>276.800000</td>\n",
              "      <td>0.062631</td>\n",
              "      <td>4.066833</td>\n",
              "      <td>1.368302</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.976992</td>\n",
              "      <td>0.094996</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>-0.039300</td>\n",
              "      <td>16.298515</td>\n",
              "      <td>1.898742</td>\n",
              "      <td>164.500000</td>\n",
              "      <td>117.800000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.500000</td>\n",
              "      <td>117.800000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>0.070127</td>\n",
              "      <td>2.318055</td>\n",
              "      <td>1.832079</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.980460</td>\n",
              "      <td>0.108244</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>-0.603800</td>\n",
              "      <td>13.537306</td>\n",
              "      <td>7.993498</td>\n",
              "      <td>181.700000</td>\n",
              "      <td>139.400000</td>\n",
              "      <td>234.600000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>179.333334</td>\n",
              "      <td>139.400000</td>\n",
              "      <td>234.600000</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.891341</td>\n",
              "      <td>5.302808</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.945965</td>\n",
              "      <td>0.121638</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.007200</td>\n",
              "      <td>20.335223</td>\n",
              "      <td>0.678436</td>\n",
              "      <td>164.200000</td>\n",
              "      <td>99.800000</td>\n",
              "      <td>232.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.200000</td>\n",
              "      <td>99.800000</td>\n",
              "      <td>232.600000</td>\n",
              "      <td>0.082091</td>\n",
              "      <td>6.402503</td>\n",
              "      <td>0.683837</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.932720</td>\n",
              "      <td>0.103249</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>-0.240100</td>\n",
              "      <td>9.556888</td>\n",
              "      <td>8.384054</td>\n",
              "      <td>201.150000</td>\n",
              "      <td>154.800000</td>\n",
              "      <td>245.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>201.150000</td>\n",
              "      <td>154.800000</td>\n",
              "      <td>245.600000</td>\n",
              "      <td>0.057816</td>\n",
              "      <td>-3.603139</td>\n",
              "      <td>6.991285</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>0.923760</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.230940</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.960027</td>\n",
              "      <td>0.079368</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>-0.035000</td>\n",
              "      <td>13.247656</td>\n",
              "      <td>7.372366</td>\n",
              "      <td>169.800000</td>\n",
              "      <td>137.200000</td>\n",
              "      <td>223.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>169.800000</td>\n",
              "      <td>137.200000</td>\n",
              "      <td>223.400000</td>\n",
              "      <td>0.063414</td>\n",
              "      <td>-0.280112</td>\n",
              "      <td>6.018277</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.927768</td>\n",
              "      <td>0.088934</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>20.208767</td>\n",
              "      <td>1.323555</td>\n",
              "      <td>246.800000</td>\n",
              "      <td>191.800000</td>\n",
              "      <td>327.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>246.800000</td>\n",
              "      <td>191.800000</td>\n",
              "      <td>327.800000</td>\n",
              "      <td>0.303828</td>\n",
              "      <td>6.039341</td>\n",
              "      <td>1.056006</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.969427</td>\n",
              "      <td>0.071686</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>-0.008200</td>\n",
              "      <td>15.657477</td>\n",
              "      <td>0.564009</td>\n",
              "      <td>164.750000</td>\n",
              "      <td>112.800000</td>\n",
              "      <td>206.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.750000</td>\n",
              "      <td>112.800000</td>\n",
              "      <td>206.600000</td>\n",
              "      <td>0.058481</td>\n",
              "      <td>1.704757</td>\n",
              "      <td>0.521001</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.952720</td>\n",
              "      <td>0.086412</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>-0.075800</td>\n",
              "      <td>15.324706</td>\n",
              "      <td>7.387854</td>\n",
              "      <td>239.850000</td>\n",
              "      <td>161.800000</td>\n",
              "      <td>323.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>239.850000</td>\n",
              "      <td>161.800000</td>\n",
              "      <td>323.600000</td>\n",
              "      <td>0.044327</td>\n",
              "      <td>1.307821</td>\n",
              "      <td>6.021393</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.016885</td>\n",
              "      <td>0.097409</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.861880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.037000</td>\n",
              "      <td>18.268490</td>\n",
              "      <td>1.472056</td>\n",
              "      <td>204.200000</td>\n",
              "      <td>106.600000</td>\n",
              "      <td>326.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>204.200000</td>\n",
              "      <td>106.600000</td>\n",
              "      <td>326.800000</td>\n",
              "      <td>0.065446</td>\n",
              "      <td>4.195972</td>\n",
              "      <td>1.717318</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.922517</td>\n",
              "      <td>0.126072</td>\n",
              "      <td>-0.850000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>19.048675</td>\n",
              "      <td>0.572380</td>\n",
              "      <td>207.450000</td>\n",
              "      <td>167.800000</td>\n",
              "      <td>261.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>207.450000</td>\n",
              "      <td>167.800000</td>\n",
              "      <td>261.800000</td>\n",
              "      <td>0.058441</td>\n",
              "      <td>5.069416</td>\n",
              "      <td>0.519929</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.979258</td>\n",
              "      <td>0.063978</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>-0.019500</td>\n",
              "      <td>17.187373</td>\n",
              "      <td>0.602702</td>\n",
              "      <td>172.450000</td>\n",
              "      <td>102.200000</td>\n",
              "      <td>227.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>172.450000</td>\n",
              "      <td>102.200000</td>\n",
              "      <td>227.800000</td>\n",
              "      <td>0.093507</td>\n",
              "      <td>3.058438</td>\n",
              "      <td>0.283236</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.928935</td>\n",
              "      <td>0.074313</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>18.907932</td>\n",
              "      <td>2.914012</td>\n",
              "      <td>177.500000</td>\n",
              "      <td>121.400000</td>\n",
              "      <td>237.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>177.500000</td>\n",
              "      <td>121.400000</td>\n",
              "      <td>237.800000</td>\n",
              "      <td>0.082712</td>\n",
              "      <td>4.932750</td>\n",
              "      <td>2.941260</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.975182</td>\n",
              "      <td>0.097560</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>-0.013000</td>\n",
              "      <td>16.587556</td>\n",
              "      <td>0.731196</td>\n",
              "      <td>216.550000</td>\n",
              "      <td>115.400000</td>\n",
              "      <td>314.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>216.550000</td>\n",
              "      <td>115.400000</td>\n",
              "      <td>314.600000</td>\n",
              "      <td>0.080515</td>\n",
              "      <td>2.626773</td>\n",
              "      <td>0.678998</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.960783</td>\n",
              "      <td>0.105124</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>19.138744</td>\n",
              "      <td>1.516136</td>\n",
              "      <td>189.250000</td>\n",
              "      <td>132.200000</td>\n",
              "      <td>254.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>189.250000</td>\n",
              "      <td>132.200000</td>\n",
              "      <td>254.400000</td>\n",
              "      <td>0.089832</td>\n",
              "      <td>5.208109</td>\n",
              "      <td>1.517679</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.930635</td>\n",
              "      <td>0.071948</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>-0.016800</td>\n",
              "      <td>17.441614</td>\n",
              "      <td>1.533204</td>\n",
              "      <td>236.450000</td>\n",
              "      <td>189.400000</td>\n",
              "      <td>281.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>236.450000</td>\n",
              "      <td>189.400000</td>\n",
              "      <td>281.800000</td>\n",
              "      <td>0.086507</td>\n",
              "      <td>3.444729</td>\n",
              "      <td>1.553671</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.996885</td>\n",
              "      <td>0.109906</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.097400</td>\n",
              "      <td>17.747633</td>\n",
              "      <td>2.701418</td>\n",
              "      <td>212.300000</td>\n",
              "      <td>139.400000</td>\n",
              "      <td>287.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212.300000</td>\n",
              "      <td>139.400000</td>\n",
              "      <td>287.600000</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>3.770418</td>\n",
              "      <td>2.751542</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.977215</td>\n",
              "      <td>0.101006</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.256200</td>\n",
              "      <td>14.103763</td>\n",
              "      <td>7.157913</td>\n",
              "      <td>221.050000</td>\n",
              "      <td>119.600000</td>\n",
              "      <td>343.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>221.050000</td>\n",
              "      <td>119.600000</td>\n",
              "      <td>343.400000</td>\n",
              "      <td>0.075586</td>\n",
              "      <td>0.665270</td>\n",
              "      <td>6.187134</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.938492</td>\n",
              "      <td>0.126049</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>-0.254000</td>\n",
              "      <td>16.235498</td>\n",
              "      <td>7.741918</td>\n",
              "      <td>180.150000</td>\n",
              "      <td>126.200000</td>\n",
              "      <td>224.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>180.150000</td>\n",
              "      <td>126.200000</td>\n",
              "      <td>224.600000</td>\n",
              "      <td>0.083321</td>\n",
              "      <td>2.806253</td>\n",
              "      <td>6.777444</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.929245</td>\n",
              "      <td>0.070213</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>-0.011500</td>\n",
              "      <td>17.289269</td>\n",
              "      <td>3.412940</td>\n",
              "      <td>240.750000</td>\n",
              "      <td>187.400000</td>\n",
              "      <td>291.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>240.750000</td>\n",
              "      <td>187.400000</td>\n",
              "      <td>291.200000</td>\n",
              "      <td>0.055901</td>\n",
              "      <td>3.504836</td>\n",
              "      <td>3.073262</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.984433</td>\n",
              "      <td>0.101065</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>-0.007600</td>\n",
              "      <td>17.806802</td>\n",
              "      <td>1.391644</td>\n",
              "      <td>232.550000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>309.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>232.550000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>309.200000</td>\n",
              "      <td>0.050479</td>\n",
              "      <td>3.802901</td>\n",
              "      <td>1.344568</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.003901</td>\n",
              "      <td>0.078324</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>15.681318</td>\n",
              "      <td>1.954921</td>\n",
              "      <td>195.450000</td>\n",
              "      <td>131.200000</td>\n",
              "      <td>296.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.450000</td>\n",
              "      <td>131.200000</td>\n",
              "      <td>296.400000</td>\n",
              "      <td>0.169153</td>\n",
              "      <td>1.308111</td>\n",
              "      <td>2.329510</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.973207</td>\n",
              "      <td>0.105482</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.019800</td>\n",
              "      <td>18.131421</td>\n",
              "      <td>2.029571</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>130.200000</td>\n",
              "      <td>187.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>130.200000</td>\n",
              "      <td>187.400000</td>\n",
              "      <td>0.090547</td>\n",
              "      <td>4.281449</td>\n",
              "      <td>1.970463</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.949973</td>\n",
              "      <td>0.072626</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>-0.004300</td>\n",
              "      <td>16.581803</td>\n",
              "      <td>1.229964</td>\n",
              "      <td>146.900000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>183.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.900000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>183.400000</td>\n",
              "      <td>0.075931</td>\n",
              "      <td>2.682249</td>\n",
              "      <td>1.225402</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.899554</td>\n",
              "      <td>0.063261</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>0.010600</td>\n",
              "      <td>19.352509</td>\n",
              "      <td>0.868463</td>\n",
              "      <td>141.700000</td>\n",
              "      <td>119.200000</td>\n",
              "      <td>172.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>141.700000</td>\n",
              "      <td>119.200000</td>\n",
              "      <td>172.400000</td>\n",
              "      <td>0.092879</td>\n",
              "      <td>5.427464</td>\n",
              "      <td>0.884991</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.925045</td>\n",
              "      <td>0.051980</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.041900</td>\n",
              "      <td>15.760010</td>\n",
              "      <td>7.684377</td>\n",
              "      <td>153.500000</td>\n",
              "      <td>114.200000</td>\n",
              "      <td>199.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>153.500000</td>\n",
              "      <td>114.200000</td>\n",
              "      <td>199.200000</td>\n",
              "      <td>0.072394</td>\n",
              "      <td>1.903873</td>\n",
              "      <td>6.407346</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.956137</td>\n",
              "      <td>0.081419</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.461880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>-0.007800</td>\n",
              "      <td>20.120126</td>\n",
              "      <td>1.382614</td>\n",
              "      <td>158.550000</td>\n",
              "      <td>100.600000</td>\n",
              "      <td>225.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>158.550000</td>\n",
              "      <td>100.600000</td>\n",
              "      <td>225.800000</td>\n",
              "      <td>0.110459</td>\n",
              "      <td>6.084020</td>\n",
              "      <td>0.865804</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.936106</td>\n",
              "      <td>0.103082</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>-0.007400</td>\n",
              "      <td>16.877192</td>\n",
              "      <td>0.811442</td>\n",
              "      <td>188.950000</td>\n",
              "      <td>113.400000</td>\n",
              "      <td>254.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.950000</td>\n",
              "      <td>113.400000</td>\n",
              "      <td>254.400000</td>\n",
              "      <td>0.082798</td>\n",
              "      <td>2.910833</td>\n",
              "      <td>0.782057</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.966360</td>\n",
              "      <td>0.106964</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>18.649061</td>\n",
              "      <td>1.575345</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>272.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>272.200000</td>\n",
              "      <td>0.136521</td>\n",
              "      <td>4.715565</td>\n",
              "      <td>1.561461</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.933496</td>\n",
              "      <td>0.066217</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.031500</td>\n",
              "      <td>18.586153</td>\n",
              "      <td>1.456653</td>\n",
              "      <td>183.050000</td>\n",
              "      <td>123.600000</td>\n",
              "      <td>246.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>183.050000</td>\n",
              "      <td>123.600000</td>\n",
              "      <td>246.000000</td>\n",
              "      <td>0.084335</td>\n",
              "      <td>4.628289</td>\n",
              "      <td>1.444780</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.957864</td>\n",
              "      <td>0.078134</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>16.609944</td>\n",
              "      <td>1.109397</td>\n",
              "      <td>211.350000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>211.350000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>293.000000</td>\n",
              "      <td>0.059385</td>\n",
              "      <td>2.609138</td>\n",
              "      <td>1.062624</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>0.095313</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>-0.036200</td>\n",
              "      <td>17.284519</td>\n",
              "      <td>1.834897</td>\n",
              "      <td>198.900000</td>\n",
              "      <td>145.400000</td>\n",
              "      <td>275.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>198.900000</td>\n",
              "      <td>145.400000</td>\n",
              "      <td>275.200000</td>\n",
              "      <td>0.049165</td>\n",
              "      <td>3.276985</td>\n",
              "      <td>1.792548</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.007534</td>\n",
              "      <td>0.084567</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>-0.010200</td>\n",
              "      <td>18.409725</td>\n",
              "      <td>1.360825</td>\n",
              "      <td>198.750000</td>\n",
              "      <td>151.200000</td>\n",
              "      <td>246.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>198.750000</td>\n",
              "      <td>151.200000</td>\n",
              "      <td>246.000000</td>\n",
              "      <td>0.062727</td>\n",
              "      <td>4.429941</td>\n",
              "      <td>1.344111</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.979784</td>\n",
              "      <td>0.084679</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.017000</td>\n",
              "      <td>17.603067</td>\n",
              "      <td>1.748872</td>\n",
              "      <td>197.250000</td>\n",
              "      <td>155.800000</td>\n",
              "      <td>247.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>197.250000</td>\n",
              "      <td>155.800000</td>\n",
              "      <td>247.200000</td>\n",
              "      <td>0.075205</td>\n",
              "      <td>3.603373</td>\n",
              "      <td>1.737154</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.999694</td>\n",
              "      <td>0.068196</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>17.591685</td>\n",
              "      <td>2.326106</td>\n",
              "      <td>162.100000</td>\n",
              "      <td>118.600000</td>\n",
              "      <td>219.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>162.100000</td>\n",
              "      <td>118.600000</td>\n",
              "      <td>219.400000</td>\n",
              "      <td>0.083466</td>\n",
              "      <td>3.637987</td>\n",
              "      <td>2.342187</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.953698</td>\n",
              "      <td>0.074839</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>18.959668</td>\n",
              "      <td>1.211548</td>\n",
              "      <td>206.450000</td>\n",
              "      <td>135.200000</td>\n",
              "      <td>259.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>206.450000</td>\n",
              "      <td>135.200000</td>\n",
              "      <td>259.000000</td>\n",
              "      <td>1.095112</td>\n",
              "      <td>4.987917</td>\n",
              "      <td>1.191198</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.971751</td>\n",
              "      <td>0.094195</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>0.042100</td>\n",
              "      <td>15.888618</td>\n",
              "      <td>6.610380</td>\n",
              "      <td>151.450000</td>\n",
              "      <td>118.600000</td>\n",
              "      <td>191.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>151.450000</td>\n",
              "      <td>118.600000</td>\n",
              "      <td>191.400000</td>\n",
              "      <td>0.080179</td>\n",
              "      <td>2.467357</td>\n",
              "      <td>5.623132</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.921260</td>\n",
              "      <td>0.054198</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>-0.007000</td>\n",
              "      <td>16.316413</td>\n",
              "      <td>2.655575</td>\n",
              "      <td>216.400000</td>\n",
              "      <td>161.400000</td>\n",
              "      <td>290.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>216.400000</td>\n",
              "      <td>161.400000</td>\n",
              "      <td>290.400000</td>\n",
              "      <td>0.044765</td>\n",
              "      <td>2.783199</td>\n",
              "      <td>1.680844</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.033214</td>\n",
              "      <td>0.102432</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>-0.006200</td>\n",
              "      <td>17.622865</td>\n",
              "      <td>0.978008</td>\n",
              "      <td>164.850000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>232.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.850000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>232.800000</td>\n",
              "      <td>0.101142</td>\n",
              "      <td>3.695479</td>\n",
              "      <td>0.966538</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.927387</td>\n",
              "      <td>0.075535</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>12.415554</td>\n",
              "      <td>14.002591</td>\n",
              "      <td>163.150000</td>\n",
              "      <td>125.600000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>163.150000</td>\n",
              "      <td>125.600000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>0.111004</td>\n",
              "      <td>-0.190648</td>\n",
              "      <td>11.378943</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906202</td>\n",
              "      <td>0.085864</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>0.029300</td>\n",
              "      <td>17.550090</td>\n",
              "      <td>2.183794</td>\n",
              "      <td>180.500000</td>\n",
              "      <td>118.600000</td>\n",
              "      <td>262.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>180.500000</td>\n",
              "      <td>118.600000</td>\n",
              "      <td>262.200000</td>\n",
              "      <td>0.097393</td>\n",
              "      <td>3.465060</td>\n",
              "      <td>2.091341</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.935031</td>\n",
              "      <td>0.092757</td>\n",
              "      <td>-0.850000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>18.471793</td>\n",
              "      <td>1.021559</td>\n",
              "      <td>175.800000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>214.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>175.800000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>214.600000</td>\n",
              "      <td>0.072664</td>\n",
              "      <td>4.505573</td>\n",
              "      <td>1.013972</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.966219</td>\n",
              "      <td>0.052846</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>-0.000400</td>\n",
              "      <td>17.837901</td>\n",
              "      <td>1.325137</td>\n",
              "      <td>146.150000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>218.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.150000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>218.400000</td>\n",
              "      <td>0.105457</td>\n",
              "      <td>3.928976</td>\n",
              "      <td>1.310156</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.908925</td>\n",
              "      <td>0.083035</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.019700</td>\n",
              "      <td>19.281787</td>\n",
              "      <td>1.680856</td>\n",
              "      <td>184.250000</td>\n",
              "      <td>122.800000</td>\n",
              "      <td>255.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>184.250000</td>\n",
              "      <td>122.800000</td>\n",
              "      <td>255.800000</td>\n",
              "      <td>0.081247</td>\n",
              "      <td>5.318954</td>\n",
              "      <td>1.672452</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.962833</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>0.047700</td>\n",
              "      <td>16.478535</td>\n",
              "      <td>2.047199</td>\n",
              "      <td>192.050000</td>\n",
              "      <td>136.400000</td>\n",
              "      <td>267.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>192.050000</td>\n",
              "      <td>136.400000</td>\n",
              "      <td>267.400000</td>\n",
              "      <td>0.284834</td>\n",
              "      <td>2.923666</td>\n",
              "      <td>1.368042</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.954869</td>\n",
              "      <td>0.088014</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.010800</td>\n",
              "      <td>17.806412</td>\n",
              "      <td>2.002832</td>\n",
              "      <td>214.150000</td>\n",
              "      <td>150.400000</td>\n",
              "      <td>283.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>214.150000</td>\n",
              "      <td>150.400000</td>\n",
              "      <td>283.600000</td>\n",
              "      <td>0.066786</td>\n",
              "      <td>4.321470</td>\n",
              "      <td>0.995066</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.984942</td>\n",
              "      <td>0.129645</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.021600</td>\n",
              "      <td>21.208996</td>\n",
              "      <td>1.974843</td>\n",
              "      <td>239.700000</td>\n",
              "      <td>178.800000</td>\n",
              "      <td>298.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>239.700000</td>\n",
              "      <td>178.800000</td>\n",
              "      <td>298.800000</td>\n",
              "      <td>0.061890</td>\n",
              "      <td>7.002866</td>\n",
              "      <td>2.210476</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.006130</td>\n",
              "      <td>0.069127</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>18.204581</td>\n",
              "      <td>0.701863</td>\n",
              "      <td>160.750000</td>\n",
              "      <td>86.400000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>160.750000</td>\n",
              "      <td>86.400000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>0.093884</td>\n",
              "      <td>4.291700</td>\n",
              "      <td>0.720431</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.912881</td>\n",
              "      <td>0.101020</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.048500</td>\n",
              "      <td>18.043745</td>\n",
              "      <td>1.233727</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>109.400000</td>\n",
              "      <td>286.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>109.400000</td>\n",
              "      <td>286.600000</td>\n",
              "      <td>0.110427</td>\n",
              "      <td>4.204725</td>\n",
              "      <td>1.247051</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.939021</td>\n",
              "      <td>0.122972</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>19.093704</td>\n",
              "      <td>2.324233</td>\n",
              "      <td>158.950000</td>\n",
              "      <td>120.600000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>158.950000</td>\n",
              "      <td>120.600000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>0.131438</td>\n",
              "      <td>5.145287</td>\n",
              "      <td>2.341597</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.948417</td>\n",
              "      <td>0.083555</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>-0.003900</td>\n",
              "      <td>17.578620</td>\n",
              "      <td>0.686043</td>\n",
              "      <td>138.550000</td>\n",
              "      <td>103.600000</td>\n",
              "      <td>184.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>138.550000</td>\n",
              "      <td>103.600000</td>\n",
              "      <td>184.600000</td>\n",
              "      <td>0.119212</td>\n",
              "      <td>3.681333</td>\n",
              "      <td>0.675163</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.897287</td>\n",
              "      <td>0.070414</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>-0.005200</td>\n",
              "      <td>19.498123</td>\n",
              "      <td>0.757439</td>\n",
              "      <td>168.700000</td>\n",
              "      <td>130.800000</td>\n",
              "      <td>217.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>168.700000</td>\n",
              "      <td>130.800000</td>\n",
              "      <td>217.800000</td>\n",
              "      <td>0.105675</td>\n",
              "      <td>5.539699</td>\n",
              "      <td>0.712236</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.958424</td>\n",
              "      <td>0.070237</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>17.684428</td>\n",
              "      <td>2.876758</td>\n",
              "      <td>236.850000</td>\n",
              "      <td>159.600000</td>\n",
              "      <td>314.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>236.850000</td>\n",
              "      <td>159.600000</td>\n",
              "      <td>314.200000</td>\n",
              "      <td>0.061534</td>\n",
              "      <td>3.691561</td>\n",
              "      <td>2.842538</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.992867</td>\n",
              "      <td>0.085455</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>-0.006400</td>\n",
              "      <td>18.396460</td>\n",
              "      <td>2.189959</td>\n",
              "      <td>209.550000</td>\n",
              "      <td>129.800000</td>\n",
              "      <td>287.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>209.550000</td>\n",
              "      <td>129.800000</td>\n",
              "      <td>287.800000</td>\n",
              "      <td>0.066109</td>\n",
              "      <td>4.227291</td>\n",
              "      <td>1.845627</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.969169</td>\n",
              "      <td>0.069104</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "[Step 100] Semantic Similarity Debug\n",
            "Prompt:\n",
            "Sites & types of teratomas (mature teratoma & immature teratoma)\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Teratomas, also known as成熟的畸胎瘤, are complex tumors that can contain a mixture of tissue from two or more germ layers that developed during embryonic life. They typically consist of living tissues that can be derived from all three germ layers: ectoderm, mesoderm, and endoderm.\n",
            "\n",
            "There are two main categories of teratomas:\n",
            "\n",
            "1. Mature Teratomas:\n",
            "   Mature teratomas consist mostly of developed tissue that resembles typical adult structures. These tumors usually contain mature cell organizations like skin, hair, teeth, bone, cartilage, and often neural tissue. Due to their development into recognizable adult structures, the prognosis for mature teratomas is typically positive, and they can often be successfully removed surgically.\n",
            "\n",
            "2. Immature Teratomas:\n",
            "   Immature teratomas, on the other hand, contain less differentiated tissues and may include embryonic structures that are not found in normal adult organisms. This can include cells from all three germ layers that have not fully developed, such as neural crest cells, stem cells, or undifferentiated cells. This diversity of non-adult or primitive tissue types makes immature teratomas more difficult to manage and typically more dangerous. In some cases, immature teratomas can give rise to more aggressive cancers, making them a serious medical concern.</reasoning>\n",
            "\n",
            "<answer>\n",
            "A mature teratoma is predominantly composed of adult-like tissue culminating in a positive prognosis with surgical removal.\n",
            "\n",
            "An immature teratoma comprises less developed tissues and potentially primitive cells leading to a higher medical risk.</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "A mature teratoma is predominantly composed of adult-like tissue culminating in a positive prognosis with surgical removal.\n",
            "\n",
            "An immature teratoma comprises less developed tissues and potentially primitive cells leading to a higher medical risk.\n",
            "------------------------------\n",
            "Prompt:\n",
            "Sites & types of teratomas (mature teratoma & immature teratoma)\n",
            "Model Output:\n",
            "<reasoning>Teratomas, or teratomas, are a type of germ cell tumor that usually develop in the ovary (ovarian teratoma) or testis (testicular teratoma). There are two main types:\n",
            "\n",
            "1. **Mature Teratoma (Cystadenoma)**: This type is typically benign and consists of mature cells that resemble cells from an embryo's yolk sac, placenta, or somatic tissues (like hair follicles, teeth, and bone). It often presents as a solid cyst or a fluid-filled cyst.\n",
            "\n",
            "2. **Immature Teratoma**: Also known as malignant teratoma or dysgerminoma/malignant teratoma in the context of ovarian tumors, this type is less common and is more aggressive. It contains a mix of undifferentiated cells, stem cells, and differentiated cells from various tissues, including immature to mature tissues like bone, cartilage, and fat.\n",
            "\n",
            "It's important to note that teratomas can have a wide range of tissue types, making it possible for them to contain nearly all tissues and organs, which is why they are named teratomas or \"monsters\" in ancient Greek, referring to their potential heterogeneity.</reasoning>\n",
            "\n",
            "<answer>\n",
            "Mature Teratoma: Consists mostly of mature tissues like cells resembling the yolk sac, placenta, or somatic tissues.\n",
            "\n",
            "Immature Teratoma: Contains a mix of undifferentiated cells to immature tissues, including bone, cartilage, and fat.\n",
            "</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "Mature Teratoma: Consists mostly of mature tissues like cells resembling the yolk sac, placenta, or somatic tissues.\n",
            "\n",
            "Immature Teratoma: Contains a mix of undifferentiated cells to immature tissues, including bone, cartilage, and fat.\n",
            "------------------------------\n",
            "Prompt:\n",
            "Sites & types of teratomas (mature teratoma & immature teratoma)\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Teratomas are abnormal tumors that develop from different types of tissues. There are two main types of teratomas: mature teratomas and immature teratomas.\n",
            "\n",
            "A mature teratoma, also known as a dermoid cyst, contains all layers of the ectoderm, endoderm, and mesoderm. These tumors are benign and typically form during the first few years of life, with a peak incidence during the puberty to early 20s. Dermoid cysts are also quite common in the female genital tract (ovaries), testes, and sebaceous areas of the skin. \n",
            "\n",
            "On the other hand, an immature teratoma represents an incomplete transformation of primordial germ cells into a mature teratoma. These tumors have cells that are still in the dedifferentiation process and are capable of being multi-systemic, particularly in the case of ovarian immature teratoma. They can also give rise to choriocarcinoma, a form of cancer.\n",
            "</reasoning>\n",
            "\n",
            "<answer>\n",
            "Mature teratomas contain all layers of the ectoderm, endoderm, and mesoderm and are found in various sites such as ovaries, testes, and skin, typically being benign. Immature teratomas are incomplete transformations of primordial germ cells, potentially capable of forming choriocarcinoma and having multi-system involvement.\n",
            "\n",
            "Q&amp;A: GM: mature teratomas; IM: immature teratomas\n",
            "A1: GM includes all layers of the three germ layers.\n",
            "A2: IM is characterized by incomplete cell differentiation and potential multi-system involvement.\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "\n",
            "------------------------------\n",
            "Prompt:\n",
            "Sites & types of teratomas (mature teratoma & immature teratoma)\n",
            "Model Output:\n",
            "<reasoning>Teratomas, often benign developmental anomalies, are comprised of multiple tissue types and can originate from any germ cell. There are two main types: mature teratomas and immature teratomas.\n",
            "\n",
            "1. Mature teratomas: These are characterized by their fully developed tissue structures belonging to three primary germ layers (ectoderm, mesoderm, and endoderm). Components can include hair, teeth, bone, cartilage, and various other tissues. They are usually benign.\n",
            "\n",
            "2. Immature teratomas: These are less common and feature tissues in various stages of development, often not fully formed into the typical structures found in mature teratomas. They can include tissues from several different areas across the three germ layers and may require immediate medical attention.\n",
            "\n",
            "Both types require a multidisciplinary approach for management and treatment, including imaging, and may necessitate surgery.</reasoning>\n",
            "\n",
            "<answer>\n",
            "Mature teratomas display fully developed structures belonging to three primary germ layers, whereas Immature teratomas feature tissues in various stages of development and may include tissues from multiple areas across the three germ layers.\n",
            "</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "Mature teratomas display fully developed structures belonging to three primary germ layers, whereas Immature teratomas feature tissues in various stages of development and may include tissues from multiple areas across the three germ layers.\n",
            "------------------------------\n",
            "========================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "[Step 200] Semantic Similarity Debug\n",
            "Prompt:\n",
            "Examples of: Gene amplification\n",
            "Model Output:\n",
            "<reasoning>Gene amplification refers to the process by which a particular gene or a set of genes is duplicated within the genome. This process increases the number of gene copies within a cell. Genetic amplification typically occurs in two main contexts:\n",
            "1. During DNA replication, errors can lead to the duplication of specific gene segments.\n",
            "2. In cancer cells, gene amplification can occur as a mechanism to enhance the expression of genes that promote cell growth, survival, or metabolism.\n",
            "\n",
            "Gene amplification is often studied in the field of oncology, particularly in understanding cancer mechanisms and developing targeted therapies.</reasoning>\n",
            "<answer>Gene amplification</answer>\n",
            "</answer>\n",
            "<em>Safety Warning</em> Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "Gene amplification\n",
            "------------------------------\n",
            "Prompt:\n",
            "Examples of: Gene amplification\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Gene amplification is a type of genetic event where multiple copies of a specific gene are created within a cell. This process often occurs as a part of cancer progression and development. In this context, the excessive copies of a gene can lead to an overproduction of proteins encoded by that gene, potentially contributing to the cancerous cell's growth and survival advantages over normal cells. The mechanism behind gene amplification involves the duplication of DNA segments followed by their incorporation into the cell's nuclear genome. </reasoning>\n",
            "<answer>\n",
            "Gene amplification is: a: the process of creating multiple copies of a specific gene within a cell. This often leads to increased production of proteins encoded by that gene, and can play a key role in cancer development. </answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "Gene amplification is: a: the process of creating multiple copies of a specific gene within a cell. This often leads to increased production of proteins encoded by that gene, and can play a key role in cancer development.\n",
            "------------------------------\n",
            "Prompt:\n",
            "Examples of: Gene amplification\n",
            "Model Output:\n",
            "<reasoning>Gene amplification refers to the increase in the number of copies of a particular gene within a cell or tissue. This process can play a critical role in several biological and pathological conditions. It typically involves mechanisms such as unequal crossing over, transposition, or copy number variation. Amplification can lead to overexpression of the gene product, which may result in changes in cellular function, growth, and possibly malignancy.</reasoning>\n",
            "<answer>\n",
            "A: This is the explanation of gene amplification.\n",
            "</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "A: This is the explanation of gene amplification.\n",
            "------------------------------\n",
            "Prompt:\n",
            "Examples of: Gene amplification\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Gene amplification refers to the process where a specific gene in the genome is duplicated many times. This increase in gene copy number can happen either through genetic recombination during cell division or through errors during DNA replication. gene amplification often has significant effects on cellular function and is commonly associated with cancer biology, where excessive genes might lead to overexpression of proteins critical to cell proliferation.\n",
            "\n",
            "</reasoning>\n",
            "<answer>\n",
            "Gene amplification involves the duplication of specific genes within the genome.\n",
            "</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "Gene amplification involves the duplication of specific genes within the genome.\n",
            "------------------------------\n",
            "========================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "[Step 300] Semantic Similarity Debug\n",
            "Prompt:\n",
            "Centro acinar cells , all true except: a. Beginning of pancreatic duct system. b. Secrete bicarbonate ion ( with intercalated ducts) c. Its secretion is controlled by secretin hormone d. Beginning of biliary duct system\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Centro acinar cells are specialized cells found in the pancreas, specifically in the acinar units. They are involved in the secretion of digestive enzymes. Let's evaluate each statement:\n",
            "\n",
            "a. Conditional acinar cells indeed constitute a part of the pancreatic secretion system, but the entire duct system is initiated by ductal cells, not centro acinar cells. This statement is incorrect.\n",
            "\n",
            "b. Centro acinar cells do secrete bicarbonate ions, alongside ductal cells, which forms part of their function to neutralize acidic food in the stomach before it enters the intestine. This statement is correct.\n",
            "\n",
            "c. The control of secretion by the centro acinar cells is indeed regulated by the hormone secretin, along with other factors. This hormone is known to stimulate the release of bicarbonate-rich fluid and digestive enzymes. This statement is correct.\n",
            "\n",
            "d. Centro acinar cells are exclusively part of the pancreatic secretory system and do not participate in forming the biliary duct system. This statement is correct as centro acinar cells do not contribute to the biliary duct system. \n",
            "\n",
            "In summary, statement **a** is the exception as it is not true that centro acinar cells begin the pancreatic duct system.</reasoning>\n",
            "<answer>\n",
            "a</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "a\n",
            "------------------------------\n",
            "Prompt:\n",
            "Centro acinar cells , all true except: a. Beginning of pancreatic duct system. b. Secrete bicarbonate ion ( with intercalated ducts) c. Its secretion is controlled by secretin hormone d. Beginning of biliary duct system\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Center acinar cells are part of the exocrine pancreas and are not directly involved in the biliary duct system, which is managed by the liver and bile ducts. Therefore, the statement that 'Centro acinar cells begin the biliary duct system' is false, making option d incorrect. Centroacinar cells begin the pancreatic duct system (option a), they secrete bicarbonate ions (option b), and their secretion is indeed regulated by secretin hormone (option c).</reasoning>\n",
            "<answer>\n",
            "d: Beginning of biliary duct system</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "d: Beginning of biliary duct system\n",
            "------------------------------\n",
            "Prompt:\n",
            "Centro acinar cells , all true except: a. Beginning of pancreatic duct system. b. Secrete bicarbonate ion ( with intercalated ducts) c. Its secretion is controlled by secretin hormone d. Beginning of biliary duct system\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Centro acinar cells are specialized cells located at the center of the acini. These cells play significant roles in the secretory function of the pancreas and are involved in the secretion of bicarbonate ions. They are controlled by secretin, which is released by the small intestine to stimulate further secretion. Centro acinar cells are indeed the beginnings of the pancreatic duct system, not the biliary duct system. Therefore, the false statement is:\n",
            "\n",
            "d. Beginning of biliary duct system</reasoning>\n",
            "<answer>\n",
            "D: Beginning of biliary duct system</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "D: Beginning of biliary duct system\n",
            "------------------------------\n",
            "Prompt:\n",
            "Centro acinar cells , all true except: a. Beginning of pancreatic duct system. b. Secrete bicarbonate ion ( with intercalated ducts) c. Its secretion is controlled by secretin hormone d. Beginning of biliary duct system\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Centro acinar cells are found in the acini of the exocrine pancreas. They produce and secrete digestive enzymes into the small intestine. From the given options, option d) \"Beginning of biliary duct system\" is not true. Centro acinar cells form part of the acinar system and are not directly involved in the beginning of the biliary duct system. The biliary system and pancreatic system are separate in the digestive system, with the exocrine pancreas producing digestive enzymes and the liver producing bile which is secreted through different pathways.\n",
            "</reasoning>\n",
            "<answer>\n",
            "d: Beginning of biliary duct system</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "d: Beginning of biliary duct system\n",
            "------------------------------\n",
            "========================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "[Step 400] Semantic Similarity Debug\n",
            "Prompt:\n",
            "Nerve that runs between trachea & oesophagus in superior mediastinum (A) Rt phrenic (B) Lt vagus (C) Rt recurrent laryngeal (D) Lt recurrent laryngeal\n",
            "Model Output:\n",
            "<reasoning>\n",
            "In the superior mediastinum, between the trachea and oesophagus, the Lt vagus nerve (C) is the correct answer. The Lt vagus nerve enters the neck above the manubrium sterni and passes behind the trachea and oesophagus before dividing into two parts: the external and internal laryngeal nerves. The external laryngeal nerve travels down from the ventral surface of the neck, while the internal laryngeal nerve runs anterolaterally to the trachea and oesophagus.</reasoning>\n",
            "<answer>\n",
            "(C) Lt recurrent laryngeal</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "(C) Lt recurrent laryngeal\n",
            "------------------------------\n",
            "Prompt:\n",
            "Nerve that runs between trachea & oesophagus in superior mediastinum (A) Rt phrenic (B) Lt vagus (C) Rt recurrent laryngeal (D) Lt recurrent laryngeal\n",
            "Model Output:\n",
            "<reasoning>\n",
            "The nerve that runs between trachea and oesophagus in the superior mediastinum is the left recurrent laryngeal nerve (Lrt. Recurrent laryngeal, option D). This nerve winds around the inferior thyroid artery and is located in the anatomical location described, which is the superior mediastinum.</reasoning>\n",
            "<answer>\n",
            "D: Lt recurrent laryngeal</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "D: Lt recurrent laryngeal\n",
            "------------------------------\n",
            "Prompt:\n",
            "Nerve that runs between trachea & oesophagus in superior mediastinum (A) Rt phrenic (B) Lt vagus (C) Rt recurrent laryngeal (D) Lt recurrent laryngeal\n",
            "Model Output:\n",
            "<reasoning>\n",
            "The nerve that runs between the trachea and the oesophagus in the superior mediastinum is the Left recurrent laryngeal nerve (Branch of Lt vagus). It travels behind the left and anterior portion of the trachea and passes through the gap between the trachea and the oesophagus as the trachea ascends just above the level of the cricoid cartilage. Therefore, the correct answer is (B) Lt vagus.</reasoning>\n",
            "<answer>\n",
            "B: Lt vagus</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "B: Lt vagus\n",
            "------------------------------\n",
            "Prompt:\n",
            "Nerve that runs between trachea & oesophagus in superior mediastinum (A) Rt phrenic (B) Lt vagus (C) Rt recurrent laryngeal (D) Lt recurrent laryngeal\n",
            "Model Output:\n",
            "<reasoning>\n",
            "Understanding the structure of the neck and thorax, the nerve that runs between the trachea and the oesophagus in the superior mediastinum is usually the left recurrent laryngeal nerve. This is because the left recurrent laryngeal nerve has a more anterior and medial path superiorly, before passing around the left side and subsequent descent as the laryngeal portion of the vagus nerve.\n",
            "\n",
            "</reasoning>\n",
            "<answer>\n",
            "(D) Lt recurrent laryngeal</answer>\n",
            "\n",
            "Always consult a qualified healthcare professional for medical advice.\n",
            "Extracted Answer:\n",
            "(D) Lt recurrent laryngeal\n",
            "------------------------------\n",
            "========================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=-0.03930371666606516, metrics={'train_runtime': 6505.6981, 'train_samples_per_second': 0.307, 'train_steps_per_second': 0.077, 'total_flos': 0.0, 'train_loss': -0.03930371666606516})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RnJcFzcxU6Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUbluAAhD0Lg"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "# Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "3b51ec55624a40edb7952acfe9ed7254",
            "d2fe911e4631445088fdaf14cb77c913",
            "f9b0865fab2944a4bf466c7f48e91ad6",
            "2f68ee61065f413597919af2277e1678",
            "3555cee82a38472bae08d08aa8261795",
            "27e0ebce71bc46b98d91bfb40758b47d",
            "d4bd4cb2f9f547a58d792feb048c9281",
            "c7389460eb85491292103f4eb2955f85",
            "25565496f63444b286f89d3970df9105",
            "3691956757794847a3e354a2eb07a77c",
            "df0832ea0e464bf1a6360e876bc3c75d"
          ]
        },
        "id": "IqzsdZzeDM_m",
        "outputId": "e1e36cf8-028e-4c78-9f0b-a85ba75c1218"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b51ec55624a40edb7952acfe9ed7254"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<reasoning> Cardiac output is the product of heart rate and stroke volume. Hormones affect cardiac output by increasing heart rate, stroke volume, or both. \\n\\nA. Epinephrine increases both heart rate and contractility, thus increasing cardiac output.\\nB. Thyroid hormones also increase heart rate and contractility, thus increasing cardiac output.\\nC. Glucagon primarily affects the liver, stimulating glycogenolysis, but has direct effects on heart muscle cells, thus it increases cardiac output indirectly.\\nD. Acetylcholine, on the other hand, acts as a parasympathetic neurotransmitter, which generally decreases heart rate and, when considering its systemic effects, might lead to a slight decrease in cardiac output.\\n\\nTherefore, acetylcholine does NOT increase cardiac output directly. </reasoning>\\n<answer> D: Acetyl choline decreases cardiac output because it acts as a parasympathetic neurotransmitter, leading to decreased heart rate and, consequently, reduced cardiac output. </answer>\\nAlways consult a qualified healthcare professional for medical advice.\\n<|end_of_turn|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "prompt = \"\"\"Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\"\"\"\n",
        "\n",
        "prompt2 = \"\"\"\n",
        "You are a MediLearn, knowledgeable medical tutor AI.\n",
        "\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...your full explanation goes here...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...your final answer goes here...\n",
        "</answer>\n",
        "\n",
        "Follow these rules strictly:\n",
        "\n",
        "1. **Always Include Reasoning:** For every question (whether multiple-choice or not), first think through the problem carefully. Place this full explanation inside the `<reasoning>` tag.\n",
        "2. **Final Answer in Tag:** After reasoning, give your final answer clearly inside the `<answer>` tag. Be direct and specific. If the question is multiple choice, begin the answer with the correct letter followed by a colon.\n",
        "For example:\n",
        "<reasoning> Option A refers to... Option B is correct because... etc. </reasoning> <answer> B: This is the correct answer because it inhibits the correct enzyme involved. </answer> ```\n",
        "3. Stay On Topic: If a question is not related to human anatomy or medicine, refuse it politely. You must begin such responses with the exact phrase: \"{specific_refusal_phrase}\" — and still include the <reasoning> and <answer> tags.\n",
        "4. Safety First: End every response with this exact sentence: \"Always consult a qualified healthcare professional for medical advice.\"\n",
        "5. After the safety disclaimer, finish your reply with this special token: \"<|end_of_turn|>\"\n",
        "6. Never omit any part of this structure. Even refusals must include all required tags and formatting.\n",
        "\"\"\"\n",
        "\n",
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : prompt2},\n",
        "    {\"role\" : \"user\", \"content\" : \"Which of the following hormones does NOT increase cardiac output? A. epinephrine B. thyroid hormones C. glucagon D. acetyl choline\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 5000,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our reasoning model is much better. It's not always correct, since we only trained it for an hour or so it'll be better if we extend the sequence length and train for longer!"
      ],
      "metadata": {
        "id": "ZMR0Omv8eG0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving"
      ],
      "metadata": {
        "id": "WhWTz9mrm2b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge to 16bit\n",
        "if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if True: model.push_to_hub_merged(\"noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave\", tokenizer, save_method = \"merged_16bit\", token = \"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\")\n",
        "\n",
        "# # Merge to 4bit\n",
        "# if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "# if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# # Just LoRA adapters\n",
        "# if False:\n",
        "#     model.save_pretrained(\"model\")\n",
        "#     tokenizer.save_pretrained(\"model\")\n",
        "# if False:\n",
        "#     model.push_to_hub(\"hf/model\", token = \"\")\n",
        "#     tokenizer.push_to_hub(\"hf/model\", token = \"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972,
          "referenced_widgets": [
            "ce2681385e2e48ff93dadbb842908c13",
            "69bf8beac1314101b251ea4a97b9b300",
            "6b47292b6714443c931e77c81738f967",
            "f5fea625d27a43578002a6b2a52016fe",
            "1f64bafc2bf046caaea12a3e985be44f",
            "70eb010fb65442fe937589a9c4bd26fb",
            "6fa6da3ecf044447894794e38aaa7ceb",
            "c0b5742eb56c4165b6f542c13e7bdd54",
            "6d7a1dc757c04b0d804a16ab8f41c389",
            "e37c96512dbb4bf9a93fbde1e3f511a4",
            "7a4e19a815244b1d93038960534e8a98",
            "6ea3fd8df8194facb3f3726e84d02031",
            "7104cba797894ae5a6c01ed4aa3a045c",
            "c612607de350484e9f29a0f4811ca3a0",
            "afb191bbcf6a4c04b18d0c567e893dc8",
            "b858bd327f174d48890ab8ed37c5c213",
            "6341520993be4bf894fcddaf1765e913",
            "d93e11d3dc0f4f018ae83e46858a81eb",
            "50ddb7a646c740afb29d308896adf5e3",
            "dd30cc8b92274a2ba28ff4fcfe95b53b",
            "d3329005dc0d4ed9af7934b1bb3dfb7a",
            "b21fd5ed2302467c8e960575397422da",
            "163bac95c3b24c6a9f1e4d968e831124",
            "b4a7cbf95f484173aed03feb558b4c92",
            "b8bc5e64f1034acaaad80419ef47d5d5",
            "e0a3422c675f40a0afac5d271acbfa44",
            "c320ac3f7052487ba025399bbf597aa3",
            "0cdb2d7dfda44138a98eef73b0f25ddf",
            "568ac04327df4809a3f9fed5a1bc2944",
            "2ce4b0d0f79a4e19b86531eb473ebfe6",
            "c178a188b0b24cc6a64d12b468580aaa",
            "8d18dab913e14fa58b9aad5fd9e35e21",
            "6570b95264e34a90b0a5f959a0411c48",
            "fe9327ac42464ff6a6c99a66c0af440e",
            "aa929e9711d04103aa42003fc65b22ef",
            "88a52c19d13e4217b3d222b70b8bb196",
            "10d5ebaf9aa149aa87d8a0a47eb9bd03",
            "b4fc2ddf7203405f80bb7f8d70ebc026",
            "edf9de6d19044944a1a91c808786014f",
            "fb4107000a4648eca417298d78986766",
            "8f1ec34de6a04b13ac8949463d0357f3",
            "45e27542adbf481f89533c9ee6e59e8f",
            "38fc480b71674c75a211d49f89fb00ee",
            "74ea65af77e243dd95606b67752ebd3f",
            "12d1464395f74f88a3430c513bd33b97",
            "f9eb689e7f3a4c65abcca86d0c3cfa8f",
            "b8965da9fff74f30a740637109a27846",
            "a3c79f7d62bc4a6cb20c72db720aae7d",
            "7b59ab7963684e99a21bd3e2c906aac4",
            "f227afbebf664116be5256a8dd7630c8",
            "bdaf8b06b31c487b92b58853736f811e",
            "91438f652f05435aa5a3d33ac7a4f669",
            "991a4753a68445b5bac27d22853dc8e9",
            "01d20cac9e4f499ca5b04639510de9a5",
            "dcf49bc981b742c79abdc7c6f3db58c8",
            "37b0cf86c4c94a4d9f038703888657d4",
            "ba90ac98dee04175959714a7ab3fd32d",
            "9a66ac76fd3543fa988bbd603a2d92bf",
            "3b6b4197e2a04d78b34d16c68dd0a175",
            "0ea14708c7474e17bc1a7c5839234908",
            "d8572b44245441d5825f9123becdc766",
            "89d34fc7ca244e46b140ca0dfb0deaa4",
            "629946bf923445fa9ae35498efbbdf24",
            "4d73be752eb5412b8eb52084961bcafd",
            "51c1afc6cec84c959ff984bef18dbafa",
            "575d2a7416e341a1bae13a18680c88c8",
            "5c0093d6dd6e4887a1b511881e071847",
            "4a9fc955b290493181af2f19d7763d95",
            "6170966f3b074623be7c2c33855a51a5",
            "05cf2762af314b03a10d33bb8fa6fb0c",
            "932385f7712c47328838397d303262a8",
            "5b628e48ea6549b2ba2123b470a47b9f",
            "4300e66d94e741808d6a772e81f843ef",
            "7b31ede9093a4cbfbb9a51d25d21661d",
            "aa2ece61f1e0454395a2bd3d67ddfc10",
            "8f6db425efc9421b8d029c65278c4e9c",
            "e10192fc7f0a40b69d7b5253fae139b4",
            "111a1af55d9b468b95c50c058a45ab14",
            "510c8ab0e7934619aa2fa01fd12cb64e",
            "9a7a2a1aa9244dbead9cd109603bf988",
            "44cc12fc3fb245d0af53a504023ce9c3",
            "83048f60b69144e889a5e8fe44d1776a",
            "9f7bb8b62a854177bfa9b6e9e5e3d447",
            "add44c63990b4349943239e6a1eddc5b",
            "98cba6f726c54ca19c7b4f1025ab34f7",
            "f3b8f782d6fd407c9380e44d6124bdaa",
            "cb1563e8464f4b9e98baa8ae0216a485",
            "d4d8da6fe19a4c90ae1970fbf6495fda",
            "d024192aff934df688d6410bb66cbfa4",
            "aa4548b27d3a44849a441105613106ca",
            "cad54dd1bd444c2bbafd974fe31cb4cb",
            "933f2297ccb74202852f72d3d71edb84",
            "ed4f03a154c24782b6b5904bbfbb0e70",
            "567e605ca88645eaacb366fbd3857704",
            "60a50327bc8f4cf08c09ec179c03b117",
            "56d5941a81e34bcb92dc20f926328cfd",
            "c23aaeb265bc4753a1ea935ddb3de91e",
            "a68e3e4937f84847850e5628a1655170",
            "622a374deceb4b72b1c6cdac3a9e8c2f",
            "cb45353d1e2d42bd9f524e39966a0bec",
            "ac24e3fcb69c4ad896efc08a340a1610",
            "a8dc1c294e484fcc9211c829fcb82a99",
            "761f6dbb9ad0473eb6ff3e46b9d8c110",
            "360e2e25d58141b9902d1e5b03b5ede7",
            "1d1e9dbf34c14594a8a2bef6d3e1e3b8",
            "f6950a7498fe461e8390b87b653744ca",
            "dfc9bc3614f1482dbd663fc9d2a7d6b3",
            "a849613464164b509e63a0f14c137e17",
            "ffe1977633ec40aa9ca30e436ca1df51",
            "10c06aa378b24c2fb298cc032ac1a1ce",
            "7f75910021514743a283223ba0e47093",
            "d628b25ead10431b9d6a9a76b1aa048d",
            "4a88c667a9b14793adbb55c85e21b3bc",
            "09d1a4cc149f407a9d0dcf43004a3bac",
            "7dc33af7427943c799d9a08685112f6c",
            "f7ae333b266846f7957eb9278648e680",
            "a2f20d2ad3894448b14a6868169aaaa5",
            "35964f054bec4831b8e7bb46252c01d0",
            "176be8890a1c4c5f815b28cc76308f1c",
            "7274ead1ae9240ceb11a1ed5a3267420",
            "5a98ad5f93564876b9d9ed64c6ce2238",
            "2ce085f33828492aab27ca3f18b14087",
            "8fee59561306407f95bf32d293db3fce",
            "207c7589d3184c6a9dcb8bd956e22ad4",
            "c56cf013b9ec4922b4b8b194abec42a0",
            "37664cf9bc7042e98dd6a1a2a7858f4d",
            "0d456168b7014e18a0b4bb87aeafea24",
            "715f6d3787184c06b69712bea70cc8e1",
            "5fd4ef7c3fb44429aadbb3c5edac4566",
            "8817112969484228b5ae1e1465b365b8",
            "f502e6361cb24fc081f0fbedc91d0a85",
            "3e46dbe0f5f64e2d872491546a520928",
            "77de0aff09b3476e93895238be2f5a2b",
            "4570123bf5144e19aa02a77a0b4594c4",
            "257ef2296d6743ccbc233e1c347a6944",
            "9fcef8035fbb483e95aaab91d6f77921",
            "1629b29ee1004dcbb747de286bb83e23",
            "574f1444a578475ea2c5d256f5c1a93b",
            "44440373e8f04bd195192b7e920071e8",
            "1b4df87fcaa94b1aa3f42d39d97737cd",
            "6dacb73e95bc4abaa562e53a54dc881e",
            "a975bd59dd94456ca34693075c6b1b5a",
            "49a84fdb0478402d897babd92bbf388d",
            "88ee9d2112fe45f9b112057892e33741",
            "cf1c7afb2d12464abbedc9815c356268",
            "4426aaff304d47fba19dc573d1f627eb",
            "d401f8f1026e48109026147f1481205c",
            "21a45fa3707442c39c1ff620f40c6cc8",
            "48001cf3129c45a6b3d6c44d8b70b553",
            "8ddb2e55899d42beaa107e6c635b6c99",
            "aec621dba12b4febb035fb1f2f1dc2bc",
            "7cca89d228fc4f63a21c412a8b207fb9",
            "39aa474e2e1947e6afd62396cc65fc4c",
            "e3561402d92d40f395ac15aa58622f84",
            "dd5319d95a6e429aa910083ea113d54b",
            "32076a514d2c471893815e7195864a79",
            "69e5a56b13bf415c8335efb22073c465",
            "7a654bea9e2f4012be4bfb9d2686c7d0",
            "746b4c2dd9084fc3b61d7ef934f2715a",
            "35c2757ad484465fa66a3c07481c20dc",
            "5f146ffa23934e2c88d8a965c12393f3",
            "afcdce6b080d4e5aaccb376fee9b9fb5",
            "4261ae1d636d419aa81759e934fc0833",
            "7574d31382e248a6bff2d3af0c00a731",
            "befc5e043445459fbf95aeefdac517c7",
            "565cab7840e341eb92b926680b931213",
            "1a53b1ea5a08493e9d0ec8480ebbf59f",
            "2ddefedfced04eae93c4b80c1435bc54",
            "8b849755592e4c52b95123c55771c37f",
            "047aebdbeb704477bb08552802114039",
            "fb6c3ce6b71644ccb0d58317a93b9c4a",
            "dda31399d0454b5797c19329c22561a7",
            "cac4086aecac499ab5ea2fabe2f825b4",
            "b22086d9d73b44348f4500b4a7e18fa7",
            "1cf32d64965940738b6e9e301e4a09e0",
            "72c273b77a5f4966b108eccdb861916a",
            "d804f9aa2749470f8009a0776d0a24b2",
            "63429090a8db477cb87db69b638a40ad",
            "547f795f81c944eca988bd5b5bde9334",
            "c5a79c4a121c4dd7b058e2050a4f44f9",
            "4cc60d13bfe945d3804b858a6ae536e2",
            "d910f7982b2f4f06bea68cd89b59a09e",
            "078f39612148493cb198f281560fe33e",
            "e81c79ea1b904c8aaa8f697e6bca98f2",
            "0b88b97e28a249ce87067f034260f8c0",
            "5cad68e6ac6c423d96627240c58b09ed",
            "56e92d71c9db4ffdb1e6899901be565d",
            "a89db533f79849aea49aba9bbf752098",
            "eb039c39c08e439e83ffb9402178d000",
            "39de3b5729904e8e9c000d4c0c8948eb",
            "67d0a54dee1749e0b5e58e695dc97e9d",
            "ccf8f3e90c894c9f8530cf9eca7b89d8",
            "106d589a0fe047e3941d9b702b0d0aea",
            "94f61634bf8f44a38cedf488a8dd9cba",
            "c5c185c02786415d9c92399ba6b9820d",
            "bd2218dd8d8849af96252370e4afe1ee",
            "93af3729512a4a4a8d34d67ac008f153",
            "e3078312364840e8ba16b13313788acc",
            "ca1f68c61dd648cd92b88d82cd36c7a7",
            "69fe730e18f440b09885fce480049297",
            "214c695c780049c5b2e652ff63bd5820",
            "5be1bc33d88f4dfea768d1baf210affb",
            "17db9c9b8b9a417e81d9fee28401cea9",
            "0e07d6478e4944fe9958b95ee95d1685",
            "7660ed01d60b4428990d8ba96fde5abb",
            "e30675ec135743fa9b5a49350a51e859",
            "01c412f2a6af4a62b3821c4ff724739d",
            "9fd17ed7179d4bfbaa529fe9d3301c49",
            "852248290bd44bb3bb19d1b188a92800"
          ]
        },
        "id": "oO5XMU6ZeF1G",
        "outputId": "8265bf16-44e5-49fe-ecc1-eeb20f1a82d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
            "Checking cache directory for required files...\n",
            "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
            "Not all required files found in cache. Will proceed with downloading.\n",
            "Downloading safetensors index for unsloth/qwen2-7b-instruct...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce2681385e2e48ff93dadbb842908c13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:  25%|██▌       | 1/4 [00:32<01:38, 32.92s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ea3fd8df8194facb3f3726e84d02031"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:  50%|█████     | 2/4 [01:12<01:13, 36.58s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "163bac95c3b24c6a9f1e4d968e831124"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:  75%|███████▌  | 3/4 [01:34<00:29, 29.93s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe9327ac42464ff6a6c99a66c0af440e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Merging weights into 16bit: 100%|██████████| 4/4 [01:54<00:00, 28.56s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12d1464395f74f88a3430c513bd33b97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37b0cf86c4c94a4d9f038703888657d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
            "Checking cache directory for required files...\n",
            "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
            "Not all required files found in cache. Will proceed with downloading.\n",
            "Downloading safetensors index for unsloth/qwen2-7b-instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c0093d6dd6e4887a1b511881e071847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "111a1af55d9b468b95c50c058a45ab14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d024192aff934df688d6410bb66cbfa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb45353d1e2d42bd9f524e39966a0bec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:  25%|██▌       | 1/4 [01:13<03:41, 73.72s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f75910021514743a283223ba0e47093"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce085f33828492aab27ca3f18b14087"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77de0aff09b3476e93895238be2f5a2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:  50%|█████     | 2/4 [02:27<02:27, 73.53s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ee9d2112fe45f9b112057892e33741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd5319d95a6e429aa910083ea113d54b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "565cab7840e341eb92b926680b931213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Merging weights into 16bit:  75%|███████▌  | 3/4 [03:37<01:12, 72.07s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d804f9aa2749470f8009a0776d0a24b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a89db533f79849aea49aba9bbf752098"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca1f68c61dd648cd92b88d82cd36c7a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Merging weights into 16bit: 100%|██████████| 4/4 [04:42<00:00, 70.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDUGPiL3Fkkq"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGo4dbWvFk4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bdb2dc48357942efb9e8f232880a6d10",
            "ce8577ae8c464366a5c7d6aa9ab0fd84",
            "d3365c906e1d4c379d8a1312518727bb",
            "4c3033c5997745138885fefd9bd6e697",
            "7c861757862841a1a662cd01c3b9e8d7",
            "7fe4c9e23d454d1ab9596fb2e8dff63d",
            "1159116e22b746fb98f98a1663734d7a",
            "1ce4bb1e4b3a4b20bcaddf467af1e290",
            "d4428fe4ea9048a0ac41fe0bb03f36df",
            "079e221a1447412fbc7ca5b05dd2ff9c",
            "6db44e8afcd146eeb898ab8b526e8f04",
            "0d1cdde4e1f246f8828cd860979785a7",
            "abbf08203158425e950ab937064efd04",
            "834ec320909e4461aa749eb90dac047a",
            "290dbd8e730b4e5d8c43e9759602f04d",
            "42f3f541baaf4dca81c49983b68db2b0",
            "fd44085f8dd1497792b20e18c9e3af6b",
            "0b4b4004d0254dfa84acf5fe4e3f7782",
            "da24c4a950f34808a81b0df6e254615b",
            "3174b8e369e24812be48bedbb82bd8f4",
            "c4282d7edbb14fae9a9e760a44707af1",
            "b8c569fb4b594cb5a4727679b64acf8c"
          ]
        },
        "outputId": "e446fda0-2a48-417c-fd99-958504b0b84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 48.66 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28/28 [00:24<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['f16'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF into f16 GGUF format.\n",
            "The output location will be /content/noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: MediLearn-Qwen2-7B-GRPO-500Steps-GGUF\n",
            "INFO:hf-to-gguf:Model architecture: Qwen2ForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.bfloat16 --> F16, shape = {3584, 152064}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,             torch.bfloat16 --> F16, shape = {3584, 152064}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 32768\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3584\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 18944\n",
            "INFO:hf-to-gguf:gguf: head count = 28\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 4\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
            "INFO:gguf.vocab:Adding 151387 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type eos to 151645\n",
            "INFO:gguf.vocab:Setting special token type pad to 151643\n",
            "INFO:gguf.vocab:Setting special token type bos to 151643\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
            "' + message['content'] + '<|im_end|>' + '\n",
            "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
            "' }}{% endif %}\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF/unsloth.F16.gguf: n_tensors = 339, total_size = 15.2G\n",
            "Writing: 100%|██████████| 15.2G/15.2G [01:38<00:00, 155Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF/unsloth.F16.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdb2dc48357942efb9e8f232880a6d10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.F16.gguf:   0%|          | 0.00/15.2G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d1cdde4e1f246f8828cd860979785a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF\n"
          ]
        }
      ],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "# if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if True: model.push_to_hub_gguf(\"noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-GGUF\", tokenizer, quantization_method = \"f16\", token = \"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\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "# Delete all model references\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n"
      ],
      "metadata": {
        "id": "jdePbhUHrJy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Save locally\n",
        "model.save_pretrained(\"MediLearn-Qwen2-7B-transformers\")\n",
        "tokenizer.save_pretrained(\"MediLearn-Qwen2-7B-transformers\")\n",
        "\n",
        "# Step 2: Push to Hugging Face Hub\n",
        "from huggingface_hub import HfApi\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load the saved model and tokenizer again (optional, but safe to ensure everything is clean)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"MediLearn-Qwen2-7B-transformers\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"MediLearn-Qwen2-7B-transformers\")\n",
        "\n",
        "# Push to Hub\n",
        "model.push_to_hub(\"noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-TransformersSave\", token=\"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\")\n",
        "tokenizer.push_to_hub(\"noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-TransformersSave\", token=\"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\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3MrQRyEaqRij",
        "outputId": "c0bcb252-d651-48e8-ed20-c6fee0255f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-103-1542738961.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1: Save locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MediLearn-Qwen2-7B-transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MediLearn-Qwen2-7B-transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 2: Push to Hugging Face Hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation On 0.1% (270) Validation Set"
      ],
      "metadata": {
        "id": "HzbtNiBHg0kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install bert_score\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "kgys8Pv4g8_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67f62e5-6006-465c-bab9-00ff4ab08fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.4\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.53.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.33.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.6.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=decd9a191a5138e5c50ece59f91bdacbcc018a0b5cff7c5a2aa4b54bb7568e2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "IW4wDpsahESj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c036f74-363c-4882-dc3c-4b2213f39af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=name --format=csv,noheader"
      ],
      "metadata": {
        "id": "16jO6OgfhGP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16421c04-eb8d-40bd-a33c-904aa32e33d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token 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"
      ],
      "metadata": {
        "id": "iZC186nMhHGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95d6883-59b7-4448-feda-bca02189d35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `AnatomyLLM` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AnatomyLLM`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from huggingface_hub import hf_hub_download\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "from evaluate import load\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    AutoProcessor,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        "    AutoModelForImageTextToText, # For MedGemma\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "transformers.utils.logging.set_verbosity_error()\n",
        "\n",
        "print(f\"Transformers version installed: {transformers.__version__}\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "DATASET_REPO_ID = \"Anatomy-Tutor/Anatomy-and-Medical-Dataset\"\n",
        "DATASET_FILENAME = \"processed_medical_and_anatomy.json\"\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading dataset from Hugging Face Hub...\")\n",
        "try:\n",
        "    hf_data_path = hf_hub_download(\n",
        "        repo_id=DATASET_REPO_ID,\n",
        "        filename=DATASET_FILENAME,\n",
        "        repo_type=\"dataset\"\n",
        "    )\n",
        "    with open(hf_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        splits = json.load(f)\n",
        "    ds = DatasetDict({\n",
        "        \"train\": Dataset.from_list(splits[\"train\"]),\n",
        "        \"validation\": Dataset.from_list(splits[\"validation\"]),\n",
        "        \"test\": Dataset.from_list(splits[\"test\"]),\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load or process dataset. Error: {e}\")\n",
        "    ds = None # Changed DEV_SET to ds to match variable in try block\n",
        "\n",
        "# A specific refusal phrase for the model to use.\n",
        "specific_refusal_phrase = \"I am sorry, but I can only answer questions related to human anatomy and medicine.\"\n",
        "safety_warning = \"Always consult a qualified healthcare professional for medical advice.\"\n",
        "end_of_turn_token = \"<|end_of_turn|>\" # Define this token explicitly\n",
        "\n",
        "MEDICAL_CHATBOT_SYSTEM_PROMPT = f\"\"\"You are \"Medilearn,\" an expert AI anatomy tutor for a VR application. Your goal is to provide clear, accurate, and educational explanations.\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...your full explanation goes here...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...your final answer goes here...\n",
        "</answer>\n",
        "\n",
        "*Rules:**\n",
        "1. **Always Include Reasoning:** For every question (whether multiple-choice or not), first think through the problem carefully. Place this full explanation inside the `<reasoning>` tag.\n",
        "2. **Stay On Topic:** Politely refuse any question not related to human anatomy or medicine. When you refuse a question, you MUST begin your response with the exact phrase: \"{specific_refusal_phrase}\"\n",
        "3. **Final Answer in Tag:** After reasoning, give your final answer clearly inside the `<answer>` tag. Be direct and specific. If the question is multiple choice, begin the answer with the correct letter followed by a colon.\n",
        "   For example: <reasoning> Option A refers to... Option B is correct because... etc. </reasoning> <answer> B: This is the correct answer because it inhibits the correct enzyme involved. </answer>\n",
        "4. **End Your Turn:** After providing the complete answer and the mandatory safety warning, you MUST output the special token `{end_of_turn_token}`.\n",
        "5. **Safety First:** Your final sentence before the end-of-turn token must be: \"{safety_warning}\"\n",
        "\"\"\"\n",
        "\n",
        "# Additional instruction for reasoning models\n",
        "REASONING_FORMAT_INSTRUCTION = \"Please provide your concise reasoning within <think> tags and your final answer within <Answer> tags.\"\n",
        "\n",
        "REASONING_MODELS = [\n",
        "    \"Intelligent-Internet/II-Medical-8B\",\n",
        "    \"ContactDoctor/Bio-Medical-Llama-3-8B-CoT-012025\"\n",
        "]\n",
        "\n",
        "# Non-medical \"bait\" questions to test refusal\n",
        "BAIT_QUESTIONS = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"Can you tell me a joke??\",\n",
        "    \"Who is the current president of the United States?\",\n",
        "    \"What's 5 multiplied by 7?\",\n",
        "    \"Name a popular song from 2023.\",\n",
        "    \"How do you make scrambled eggs?\",\n",
        "    \"What is the tallest mountain in the world?\",\n",
        "    \"Give me a fun fact about space.\",\n",
        "    \"What's the meaning of life?\",\n",
        "    \"Can you recommend a good book to read?\",\n",
        "]\n",
        "\n",
        "def _parse_and_structure_item(prompt_text, reference_answer):\n",
        "    \"\"\"\n",
        "    Helper function to auto-detect and structure MCQs from raw text.\n",
        "    This version includes the more robust logic from the analyzer script.\n",
        "    \"\"\"\n",
        "    option_marker_pattern = re.compile(r'\\b[A-Da-d1-4][\\.\\)-:]')\n",
        "    splitter_pattern = re.compile(r'\\s+(?=[A-Da-d1-4][\\.\\)-:]|\\([A-Da-d1-4]\\))')\n",
        "    parts = splitter_pattern.split(prompt_text)\n",
        "\n",
        "    if len(parts) >= 3:\n",
        "        base_prompt = parts[0]\n",
        "        option_parts = parts[1:]\n",
        "        options_dict = {}\n",
        "        for part in option_parts:\n",
        "            match = re.match(r'\\(?([A-Da-d1-4])\\)?[.\\s:-]\\s*(.*)', part.strip())\n",
        "            if match:\n",
        "                key, text = match.groups()\n",
        "                options_dict[key.upper()] = text.strip()\n",
        "\n",
        "        if len(options_dict) >= 2:\n",
        "            structured_item = {\n",
        "                \"is_mcq\": True,\n",
        "                \"prompt\": base_prompt.strip(),\n",
        "                \"options\": options_dict\n",
        "            }\n",
        "            key_pattern = re.compile(\n",
        "                r\"^\\s*\\(?([A-D1-4])\\)?[.\\s:-]|(?:the correct answer is|the answer is|completion:)\\s*\\(?([A-D1-4])\\)?\",\n",
        "                re.IGNORECASE\n",
        "            )\n",
        "            match = key_pattern.search(reference_answer)\n",
        "            if match:\n",
        "                found_key = (match.group(1) or match.group(2))\n",
        "                if found_key:\n",
        "                    structured_item[\"correct_answer_key\"] = found_key.upper()\n",
        "                    return structured_item\n",
        "\n",
        "    options_found = option_marker_pattern.findall(prompt_text)\n",
        "    is_short_answer = len(reference_answer.strip()) < 100 and not reference_answer.strip().endswith('.')\n",
        "\n",
        "    if len(set(options_found)) >= 2 or is_short_answer:\n",
        "        pass # Let it fall through to the non-MCQ return\n",
        "\n",
        "    return {\"is_mcq\": False, \"prompt\": prompt_text}\n",
        "\n",
        "def prepare_evaluation_set(full_dataset, max_samples: int):\n",
        "    \"\"\"\n",
        "    Prepares the evaluation set from the full dataset.\n",
        "    \"\"\"\n",
        "    print(\"Preparing evaluation set from full dataset...\")\n",
        "    dev_set = []\n",
        "    if full_dataset and 'validation' in full_dataset:\n",
        "        validation_split = full_dataset[\"validation\"]\n",
        "        num_medical_samples = max_samples - len(BAIT_QUESTIONS)\n",
        "        if num_medical_samples < 0: num_medical_samples = 0\n",
        "\n",
        "        num_medical_samples = min(num_medical_samples, len(validation_split))\n",
        "\n",
        "        indices = list(range(len(validation_split)))\n",
        "        random.shuffle(indices)\n",
        "        sampled_indices = indices[:num_medical_samples]\n",
        "        print(f\"Sampling {len(sampled_indices)} medical questions for processing...\")\n",
        "\n",
        "        for i in sampled_indices:\n",
        "            item = validation_split[i]\n",
        "            user_prompt, reference_answer = None, None\n",
        "\n",
        "            messages = item.get('messages', item.get('conversations', []))\n",
        "\n",
        "            for message in messages:\n",
        "                if message.get('role') == 'user': user_prompt = message.get('content')\n",
        "                elif message.get('role') == 'assistant': reference_answer = message.get('content')\n",
        "\n",
        "            if not user_prompt: user_prompt = item.get('prompt')\n",
        "            if not reference_answer: reference_answer = item.get('completion')\n",
        "\n",
        "            if user_prompt and reference_answer:\n",
        "                structured_info = _parse_and_structure_item(user_prompt, reference_answer)\n",
        "                eval_item = {\n",
        "                    \"id\": f\"Med-{i}\", \"prompt\": structured_info[\"prompt\"],\n",
        "                    \"reference_answer\": reference_answer, \"is_bait\": False,\n",
        "                    \"is_mcq\": structured_info[\"is_mcq\"], \"expected_tags\": item.get(\"expected_tags\", []),\n",
        "                }\n",
        "                if structured_info[\"is_mcq\"]:\n",
        "                    eval_item[\"options\"] = structured_info.get(\"options\", {})\n",
        "                    eval_item[\"correct_answer_key\"] = structured_info.get(\"correct_answer_key\", \"\")\n",
        "                dev_set.append(eval_item)\n",
        "    else:\n",
        "        print(\"Medical dataset not available or invalid. Proceeding with bait questions only.\")\n",
        "\n",
        "    for i, question in enumerate(BAIT_QUESTIONS):\n",
        "        dev_set.append({\"id\": f\"Bait-{i}\", \"prompt\": question, \"reference_answer\": \"\", \"is_bait\": True, \"is_mcq\": False, \"expected_tags\": []})\n",
        "\n",
        "    random.shuffle(dev_set)\n",
        "    print(f\"Prepared a final set of {len(dev_set)} mixed samples for evaluation.\")\n",
        "    return dev_set\n",
        "\n",
        "def extract_answer_from_model_output(generated_text: str, is_mcq: bool) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the answer part from the model's generated text based on the defined format.\n",
        "    Prioritizes text within <answer> tags.\n",
        "    \"\"\"\n",
        "    # Define common ending patterns for generated text\n",
        "    ending_patterns = [\n",
        "        end_of_turn_token,\n",
        "        safety_warning,\n",
        "        specific_refusal_phrase,\n",
        "        r'System:\\s*.*', # Catches accidental regeneration of system prompt\n",
        "        r'User:\\s*.*', # Catches accidental regeneration of user prompt\n",
        "    ]\n",
        "\n",
        "    # Remove safety warning and end-of-turn token first\n",
        "    cleaned_temp = generated_text.replace(safety_warning, \"\").replace(end_of_turn_token, \"\").strip()\n",
        "\n",
        "    # 1. Try to find content within <answer>...</answer> tags\n",
        "    answer_match = re.search(r'<answer>(.*?)</answer>', cleaned_temp, re.DOTALL | re.IGNORECASE)\n",
        "    if answer_match:\n",
        "        extracted_answer = answer_match.group(1).strip()\n",
        "        return extracted_answer\n",
        "\n",
        "    # 2. If no full <answer> tag, try to find an opening <answer> tag and take everything after it\n",
        "    open_answer_tag_match = re.search(r'<answer>(.*)', cleaned_temp, re.DOTALL | re.IGNORECASE)\n",
        "    if open_answer_tag_match:\n",
        "        extracted_answer = open_answer_tag_match.group(1).strip()\n",
        "        # Clean any remaining ending patterns from this fallback\n",
        "        for pattern in ending_patterns:\n",
        "            extracted_answer = re.sub(pattern, '', extracted_answer, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "        return extracted_answer\n",
        "\n",
        "    # 3. If no <answer> tag at all, try to find text after </reasoning>\n",
        "    reasoning_end_match = re.search(r'</reasoning>(.*)', cleaned_temp, re.DOTALL | re.IGNORECASE)\n",
        "    if reasoning_end_match:\n",
        "        # Take everything after </reasoning>\n",
        "        post_reasoning_text = reasoning_end_match.group(1).strip()\n",
        "        # Clean any remaining ending patterns from this fallback\n",
        "        for pattern in ending_patterns:\n",
        "            post_reasoning_text = re.sub(pattern, '', post_reasoning_text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "        return post_reasoning_text\n",
        "\n",
        "    # 4. As a last resort, if no structure is found, take the whole generated text\n",
        "    # and try to remove common unwanted phrases/patterns.\n",
        "    final_cleaned_text = generated_text.strip()\n",
        "    for pattern in ending_patterns:\n",
        "        final_cleaned_text = re.sub(pattern, '', final_cleaned_text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "\n",
        "    # Also remove system prompt content if it got accidentally regenerated at the start\n",
        "    final_cleaned_text = re.sub(r'^System:\\s*.*', '', final_cleaned_text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "\n",
        "    return final_cleaned_text\n",
        "\n",
        "\n",
        "MAX_SAMPLES_TO_EVALUATE = 280 # A limit to keep evaluation time reasonable. 270 from the eval and 10 from bait\n",
        "\n",
        "DEV_SET = [] # Initialize DEV_SET to an empty list\n",
        "if ds: # Check if dataset was loaded successfully\n",
        "    DEV_SET = prepare_evaluation_set(full_dataset=ds, max_samples=MAX_SAMPLES_TO_EVALUATE)\n",
        "\n",
        "    # --- ADDED: Analyze and Print Final Counts ---\n",
        "    if DEV_SET:\n",
        "        mcq_count = sum(1 for item in DEV_SET if item.get('is_mcq') and not item.get('is_bait'))\n",
        "        open_ended_count = sum(1 for item in DEV_SET if not item.get('is_mcq') and not item.get('is_bait'))\n",
        "\n",
        "        print(\"\\n--- Dataset Content Analysis ---\")\n",
        "        print(f\"Total Multiple-Choice Questions (MCQs) detected: {mcq_count}\")\n",
        "        print(f\"Total Open-Ended Questions detected: {open_ended_count}\")\n",
        "        print(f\"Total Bait Questions added: {len(BAIT_QUESTIONS)}\")\n",
        "        print(\"--------------------------------\\n\")\n",
        "\n",
        "        # --- ADDED: Save the generated DEV_SET to a file ---\n",
        "        output_filename = \"evaluation_set_280_samples.json\"\n",
        "        print(f\"Saving the prepared evaluation set to '{output_filename}'...\")\n",
        "        try:\n",
        "            with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(DEV_SET, f, indent=4)\n",
        "            print(f\"File '{output_filename}' saved successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving file: {e}\")\n",
        "else:\n",
        "    print(\"Dataset not loaded, DEV_SET is empty. Evaluation will only run on bait questions if any are defined.\")\n",
        "\n",
        "\n",
        "def evaluate_model(models_to_evaluate, dev_set, log_every_n_samples, batch_size, use_4bit_quantization):\n",
        "    \"\"\"\n",
        "    Main function to load models, run evaluation, and report metrics.\n",
        "    \"\"\"\n",
        "    if not dev_set:\n",
        "        print(\"Evaluation cannot proceed without a development set.\")\n",
        "        return\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"ERROR: This script requires a CUDA-enabled GPU.\")\n",
        "        return\n",
        "\n",
        "    bertscore = load(\"bertscore\")\n",
        "    rouge = load(\"rouge\")\n",
        "    all_results_data = []\n",
        "\n",
        "    refusal_keywords = [\n",
        "        \"sorry\", \"cannot\", \"unable\", \"not medical\", \"not anatomy\", \"only answer\",\n",
        "        \"not equipped\", \"outside my scope\", \"my purpose is\", \"my knowledge is limited to\",\n",
        "        specific_refusal_phrase.lower() # Use the exact phrase for checking\n",
        "    ]\n",
        "\n",
        "    current_system_prompt = MEDICAL_CHATBOT_SYSTEM_PROMPT\n",
        "\n",
        "    # Define a custom max_seq_length for Unsloth models\n",
        "    UNSLOTH_MAX_SEQ_LENGTH = 1500\n",
        "\n",
        "    for model_info in models_to_evaluate:\n",
        "        model_name, model_id = model_info[\"name\"], model_info[\"model_id\"]\n",
        "        print(f\"\\n{'='*20}\\nEvaluating Model: {model_name} ({model_id})\\n{'='*20}\")\n",
        "\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "        model, processor_or_tokenizer = None, None\n",
        "        current_model_results = []\n",
        "\n",
        "        try:\n",
        "            print(\"Loading model and tokenizer/processor...\")\n",
        "\n",
        "            # Determine if it's your specific Unsloth model\n",
        "            is_unsloth_finetuned_qwen = \"medilearn-qwen2-7b-grpo-500steps\" in model_name.lower()\n",
        "            is_gemma_model = \"gemma\" in model_id.lower()\n",
        "            is_jsl_model = \"johnsnowlabs\" in model_id.lower()\n",
        "\n",
        "            # Define common quantization config if 4-bit quantization is used\n",
        "            q_config = None\n",
        "            if use_4bit_quantization:\n",
        "                print(\"    > NOTE: Loading with 4-bit quantization.\")\n",
        "                q_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                    bnb_4bit_use_double_quant=True,\n",
        "                )\n",
        "            else:\n",
        "                print(\"    > NOTE: Loading in native precision.\")\n",
        "\n",
        "            if is_unsloth_finetuned_qwen:\n",
        "                print(f\"    > Loading Unsloth fine-tuned model: {model_id}\")\n",
        "                # Import FastLanguageModel here to avoid error if not used\n",
        "                try:\n",
        "                    from unsloth import FastLanguageModel\n",
        "                except ImportError:\n",
        "                    raise ImportError(\"Please install unsloth to use FastLanguageModel: pip install unsloth\")\n",
        "\n",
        "                model, processor_or_tokenizer = FastLanguageModel.from_pretrained(\n",
        "                    model_name = model_id, # This is the Hugging Face repo ID\n",
        "                    max_seq_length = UNSLOTH_MAX_SEQ_LENGTH,\n",
        "                    load_in_4bit = use_4bit_quantization,\n",
        "                    fast_inference = True,\n",
        "                )\n",
        "                actual_tokenizer = processor_or_tokenizer # For Unsloth, processor_or_tokenizer IS the tokenizer\n",
        "            elif is_gemma_model:\n",
        "                processor_or_tokenizer = AutoProcessor.from_pretrained(model_id)\n",
        "                model = AutoModelForImageTextToText.from_pretrained(\n",
        "                    model_id,\n",
        "                    device_map=\"auto\",\n",
        "                    trust_remote_code=True,\n",
        "                    quantization_config=q_config,\n",
        "                    torch_dtype=torch.bfloat16 if not use_4bit_quantization else None\n",
        "                )\n",
        "                actual_tokenizer = processor_or_tokenizer.tokenizer if hasattr(processor_or_tokenizer, 'tokenizer') else processor_or_tokenizer\n",
        "            else: # Generic AutoModel loading for all other models\n",
        "                processor_or_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    model_id,\n",
        "                    device_map=\"auto\",\n",
        "                    trust_remote_code=True,\n",
        "                    quantization_config=q_config,\n",
        "                    torch_dtype=torch.bfloat16 if not use_4bit_quantization else None\n",
        "                )\n",
        "                actual_tokenizer = processor_or_tokenizer.tokenizer if hasattr(processor_or_tokenizer, 'tokenizer') else processor_or_tokenizer\n",
        "\n",
        "            if actual_tokenizer.pad_token is None:\n",
        "                actual_tokenizer.pad_token = actual_tokenizer.eos_token\n",
        "\n",
        "            if not hasattr(processor_or_tokenizer, 'pad_token_id') or processor_or_tokenizer.pad_token_id is None:\n",
        "                processor_or_tokenizer.pad_token_id = actual_tokenizer.pad_token_id\n",
        "\n",
        "            print(\"Model loaded successfully.\")\n",
        "            peak_vram_gb = torch.cuda.max_memory_allocated() / (1024**3)\n",
        "\n",
        "            for i in tqdm(range(0, len(dev_set), batch_size), desc=f\"Evaluating {model_name}\"):\n",
        "                batch = dev_set[i:i + batch_size]\n",
        "\n",
        "                batch_prompts = []\n",
        "                for item in batch:\n",
        "                    user_prompt = item[\"prompt\"]\n",
        "                    if item.get(\"is_mcq\", False):\n",
        "                        options_str = \"\\n\".join([f\"{key}: {value}\" for key, value in item[\"options\"].items()])\n",
        "                        user_prompt = f\"{user_prompt}\\n\\n{options_str}\"\n",
        "                    batch_prompts.append(user_prompt)\n",
        "\n",
        "                batch_inputs_text = []\n",
        "                for prompt_text in batch_prompts:\n",
        "                    if is_jsl_model:\n",
        "                        formatted_prompt = f\"###Question: {prompt_text} ###Answer:\"\n",
        "                        batch_inputs_text.append(formatted_prompt)\n",
        "                    else:\n",
        "                        full_system_prompt_content = current_system_prompt\n",
        "                        if model_name in REASONING_MODELS:\n",
        "                            full_system_prompt_content += \"\\n\" + REASONING_FORMAT_INSTRUCTION\n",
        "\n",
        "                        if is_gemma_model:\n",
        "                            messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt_text}]}]\n",
        "                        else:\n",
        "                            messages = [\n",
        "                                {\"role\": \"system\", \"content\": full_system_prompt_content},\n",
        "                                {\"role\": \"user\", \"content\": prompt_text},\n",
        "                            ]\n",
        "                        formatted_prompt = processor_or_tokenizer.apply_chat_template(\n",
        "                            messages, tokenize=False, add_generation_prompt=True\n",
        "                        )\n",
        "                        batch_inputs_text.append(formatted_prompt)\n",
        "\n",
        "                inputs = processor_or_tokenizer(\n",
        "                    batch_inputs_text, return_tensors=\"pt\", padding=True, truncation=True\n",
        "                ).to(model.device)\n",
        "\n",
        "                start_time = time.perf_counter()\n",
        "\n",
        "                output_ids = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=1000,\n",
        "                    num_return_sequences=1,\n",
        "                    do_sample=False,\n",
        "                    pad_token_id=processor_or_tokenizer.pad_token_id,\n",
        "                )\n",
        "\n",
        "                end_time = time.perf_counter()\n",
        "                total_time = end_time - start_time\n",
        "\n",
        "                input_lengths = inputs.input_ids.shape[1]\n",
        "                newly_generated_ids = output_ids[:, input_lengths:]\n",
        "                raw_generated_texts = processor_or_tokenizer.batch_decode(newly_generated_ids, skip_special_tokens=True)\n",
        "\n",
        "                for j, item in enumerate(batch):\n",
        "                    raw_generated_text = raw_generated_texts[j].strip()\n",
        "\n",
        "                    # === EXTRACT ANSWER USING THE NEW FUNCTION ===\n",
        "                    cleaned_text = extract_answer_from_model_output(raw_generated_text, item.get(\"is_mcq\", False))\n",
        "                    # ============================================\n",
        "\n",
        "                    num_new_tokens = newly_generated_ids[j].shape[0]\n",
        "                    tokens_per_second = num_new_tokens / total_time if total_time > 0 else 0\n",
        "\n",
        "                    if i == 0 and j == 0:\n",
        "                        print(f\"\\n--- First Output for Model: {model_name} (Prompt ID: {item['id']}) ---\")\n",
        "                        print(f\"Question:\\n{batch_prompts[j]}\\n\")\n",
        "                        print(f\"Reference Answer:\\n{item['reference_answer']}\\n\")\n",
        "                        print(\"Raw Generated Text (for debugging format issues):\")\n",
        "                        print(raw_generated_text)\n",
        "                        print(\"\\nCleaned Extracted Answer:\")\n",
        "                        print(cleaned_text)\n",
        "                        print(\"-\" * 50)\n",
        "\n",
        "                    metrics = {\"Model\": model_name, \"Prompt ID\": item[\"id\"], \"Is MCQ\": item.get(\"is_mcq\", False), \"Is Bait\": item[\"is_bait\"], \"Tokens/Sec\": tokens_per_second, \"Peak VRAM (GB)\": peak_vram_gb, \"BERTScore_F1\": 0, \"ROUGE_L\": 0, \"Refusal_Acc\": 0, \"MCQ_Acc\": 0}\n",
        "\n",
        "                    # Refusal check - cleaned for safety warning and end token\n",
        "                    refusal_check_text_raw = raw_generated_text.lower()\n",
        "                    for pattern in [safety_warning.lower(), end_of_turn_token.lower()]:\n",
        "                        refusal_check_text_raw = refusal_check_text_raw.replace(pattern, \"\")\n",
        "\n",
        "                    # Now check if the specific refusal phrase is present in the raw output\n",
        "                    if item[\"is_bait\"]:\n",
        "                        if specific_refusal_phrase.lower() in refusal_check_text_raw:\n",
        "                            metrics[\"Refusal_Acc\"] = 1\n",
        "                        else:\n",
        "                            print(f\"\\n[Refusal Check Fail] Prompt ID: {item['id']}\")\n",
        "                            print(f\"Raw Generated Text: {raw_generated_text[:200]}...\") # Print beginning of output\n",
        "                            print(f\"Expected Refusal: '{specific_refusal_phrase}'\")\n",
        "                    elif item.get(\"is_mcq\", False):\n",
        "                        correct_key = item[\"correct_answer_key\"]\n",
        "\n",
        "                        # Look for answers in the extracted cleaned_text\n",
        "                        # This pattern is more flexible for \"A: text\", \"A. text\", \"(A) text\", \"A text\"\n",
        "                        found_keys_in_cleaned = re.findall(r\"(?:^|\\b)(?:option|answer|choice)?\\s*([A-D1-4])\\s*[:\\)\\.\\-\\s]\", cleaned_text, re.IGNORECASE)\n",
        "                        found_keys_in_cleaned = [k.upper() for k in found_keys_in_cleaned]\n",
        "\n",
        "                        # Also check the raw generated text for robustness if needed, but primarily rely on cleaned\n",
        "                        found_keys_in_raw = re.findall(r\"(?:^|\\b)(?:option|answer|choice)?\\s*([A-D1-4])\\s*[:\\)\\.\\-\\s]\", raw_generated_text, re.IGNORECASE)\n",
        "                        found_keys_in_raw = [k.upper() for k in found_keys_in_raw]\n",
        "\n",
        "                        # Combine found keys and prioritize those from cleaned_text\n",
        "                        all_found_keys = list(set(found_keys_in_cleaned + found_keys_in_raw))\n",
        "\n",
        "                        # Refine chosen_answers based on explicit negation (if model explicitly says \"X is not correct\")\n",
        "                        negated_keys = re.findall(r\"([A-D1-4])\\s*(?:is not correct|is incorrect|is wrong)\", raw_generated_text, re.IGNORECASE)\n",
        "                        negated_keys = [k.upper() for k in negated_keys]\n",
        "\n",
        "                        chosen_answers = [k for k in all_found_keys if k not in negated_keys]\n",
        "\n",
        "                        # If multiple keys are found and one matches the correct key, count as correct if it's the *only* one.\n",
        "                        # If a single, unambiguous correct key is identified, and it matches the reference, it's correct.\n",
        "                        # This logic needs to be careful: if it says \"A is wrong, B is correct\", and B is indeed correct.\n",
        "                        # The simple `chosen_answers` list works if the model explicitly selects one.\n",
        "\n",
        "                        # Simpler MCQ matching: If the correct key is found among the chosen_answers and it's unambiguous\n",
        "                        if correct_key and correct_key in chosen_answers and len(chosen_answers) == 1:\n",
        "                            metrics[\"MCQ_Acc\"] = 1\n",
        "                        # Edge case: If the correct key is mentioned *first* and no other key is chosen,\n",
        "                        # or if it's the only one clearly stated as \"correct\".\n",
        "                        elif correct_key and re.search(r'(?:^|\\b)' + re.escape(correct_key) + r'\\s*[:\\)\\.\\-]', cleaned_text, re.IGNORECASE):\n",
        "                            # This catches \"C: SGLT-2 inhibitors\" where 'C' is the correct key\n",
        "                            metrics[\"MCQ_Acc\"] = 1\n",
        "                        else:\n",
        "                            metrics[\"MCQ_Acc\"] = 0\n",
        "                            # Optional: Log specific MCQ failures for manual review\n",
        "                            # print(f\"\\n[MCQ Fail] Prompt ID: {item['id']}\")\n",
        "                            # print(f\"Reference Answer: {item['reference_answer']}\")\n",
        "                            # print(f\"Raw Generated Text: {raw_generated_text}\")\n",
        "                            # print(f\"Extracted Cleaned Text: {cleaned_text}\")\n",
        "                            # print(f\"Correct Key: {correct_key}, Found Keys: {all_found_keys}, Chosen: {chosen_answers}\")\n",
        "\n",
        "                    else: # Open-ended questions\n",
        "                        if cleaned_text and item[\"reference_answer\"]: # Ensure both are non-empty for BERTScore/ROUGE\n",
        "                            try:\n",
        "                                bert_results = bertscore.compute(predictions=[cleaned_text], references=[item[\"reference_answer\"]], lang=\"en\")\n",
        "                                rouge_results = rouge.compute(predictions=[cleaned_text], references=[item[\"reference_answer\"]])\n",
        "                                metrics[\"BERTScore_F1\"] = bert_results['f1'][0]\n",
        "                                metrics[\"ROUGE_L\"] = rouge_results['rougeL']\n",
        "\n",
        "                                # Log low BERTScore for open-ended questions for debugging\n",
        "                                if metrics[\"BERTScore_F1\"] < 0.5: # Arbitrary threshold for logging\n",
        "                                     print(f\"\\n[Low BERTScore] Prompt ID: {item['id']}\")\n",
        "                                     print(f\"Reference Answer: {item['reference_answer']}\")\n",
        "                                     print(f\"Cleaned Extracted Answer: {cleaned_text}\")\n",
        "                                     print(f\"BERTScore_F1: {metrics['BERTScore_F1']:.2f}\")\n",
        "\n",
        "                            except Exception as bert_rouge_e:\n",
        "                                print(f\"Error computing BERTScore/ROUGE for Prompt ID {item['id']}: {bert_rouge_e}\")\n",
        "                                print(f\"Cleaned text: {cleaned_text}\")\n",
        "                                print(f\"Reference answer: {item['reference_answer']}\")\n",
        "                        else:\n",
        "                            print(f\"Skipping BERTScore/ROUGE for Prompt ID {item['id']} due to empty prediction or reference.\")\n",
        "\n",
        "\n",
        "                    current_model_results.append(metrics)\n",
        "                    all_results_data.append(metrics)\n",
        "\n",
        "                samples_processed = i + batch_size\n",
        "                if log_every_n_samples > 0 and samples_processed % log_every_n_samples == 0 and samples_processed > 0 and samples_processed < len(dev_set):\n",
        "                    print(f\"\\n    [Log at sample {samples_processed}/{len(dev_set)}] Model: {model_name}\")\n",
        "\n",
        "                    # Ensure enough results are available for the log slice\n",
        "                    num_results_to_log = min(log_every_n_samples, len(current_model_results))\n",
        "                    log_slice = current_model_results[-num_results_to_log:]\n",
        "\n",
        "                    if log_slice:\n",
        "                        df_log = pd.DataFrame(log_slice)\n",
        "\n",
        "                        slice_mcq_count = df_log['Is MCQ'].sum()\n",
        "                        slice_bait_count = df_log['Is Bait'].sum()\n",
        "                        slice_open_ended_count = len(df_log) - slice_mcq_count - slice_bait_count\n",
        "\n",
        "                        print(f\"      > Current Slice Counts: MCQs={slice_mcq_count}, Open-Ended={slice_open_ended_count}, Bait={slice_bait_count}\")\n",
        "\n",
        "                        # Calculate means only if there are relevant samples\n",
        "                        avg_mcq = df_log[df_log['Is MCQ']]['MCQ_Acc'].mean() if slice_mcq_count > 0 else np.nan\n",
        "                        avg_bert = df_log[~df_log['Is MCQ'] & ~df_log['Is Bait']]['BERTScore_F1'].mean() if slice_open_ended_count > 0 else np.nan\n",
        "                        avg_rouge = df_log[~df_log['Is MCQ'] & ~df_log['Is Bait']]['ROUGE_L'].mean() if slice_open_ended_count > 0 else np.nan\n",
        "                        avg_refusal = df_log[df_log['Is Bait']]['Refusal_Acc'].mean() if slice_bait_count > 0 else np.nan\n",
        "\n",
        "                        print(f\"      > Last {len(log_slice)} samples | Avg MCQ Acc: {avg_mcq:.2f} | Avg BERT_F1: {avg_bert:.2f} | Avg ROUGE_L: {avg_rouge:.2f} | Avg Refusal: {avg_refusal:.2f}\")\n",
        "\n",
        "\n",
        "            print(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR: Failed to evaluate model {model_name}. Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        finally:\n",
        "            print(f\"Clearing memory after evaluating {model_name}...\")\n",
        "            if 'model' in locals() and model is not None: del model\n",
        "            if 'processor_or_tokenizer' in locals() and processor_or_tokenizer is not None: del processor_or_tokenizer\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if current_model_results:\n",
        "            df_current = pd.DataFrame(current_model_results)\n",
        "            # Use 'first' for Peak_VRAM_GB as it's constant for the model run\n",
        "            summary = df_current.groupby(\"Model\").agg(\n",
        "                Avg_Tokens_Sec=(\"Tokens/Sec\", \"mean\"),\n",
        "                Peak_VRAM_GB=(\"Peak VRAM (GB)\", \"first\"),\n",
        "                Avg_MCQ_Acc=(\"MCQ_Acc\", lambda x: x[df_current.loc[x.index, 'Is MCQ']].mean() if df_current.loc[x.index, 'Is MCQ'].any() else np.nan),\n",
        "                Avg_OpenEnded_BERT_F1=(\"BERTScore_F1\", lambda x: x[~df_current.loc[x.index, 'Is Bait'] & ~df_current.loc[x.index, 'Is MCQ']].mean() if (~df_current.loc[x.index, 'Is Bait'] & ~df_current.loc[x.index, 'Is MCQ']).any() else np.nan),\n",
        "                Avg_OpenEnded_ROUGE_L=(\"ROUGE_L\", lambda x: x[~df_current.loc[x.index, 'Is Bait'] & ~df_current.loc[x.index, 'Is MCQ']].mean() if (~df_current.loc[x.index, 'Is Bait'] & ~df_current.loc[x.index, 'Is MCQ']).any() else np.nan),\n",
        "                Avg_Refusal_Acc=(\"Refusal_Acc\", lambda x: x[df_current.loc[x.index, 'Is Bait']].mean() if df_current.loc[x.index, 'Is Bait'].any() else np.nan)\n",
        "            ).reset_index().fillna(0) # Fill NaN from empty groups with 0 for display\n",
        "            print(f\"\\n--- METRIC SUMMARY for {model_name} ---\")\n",
        "            print(summary.round(3).to_string(index=False))\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    if not all_results_data:\n",
        "        print(\"\\nNo overall results to display.\")\n",
        "        return\n",
        "\n",
        "    pd.set_option('display.max_colwidth', 80)\n",
        "    pd.set_option('display.width', 120)\n",
        "    df_detailed = pd.DataFrame(all_results_data)\n",
        "\n",
        "    df_summary_overall = df_detailed.groupby(\"Model\").agg(\n",
        "        Avg_Tokens_Sec=(\"Tokens/Sec\", \"mean\"),\n",
        "        Peak_VRAM_GB=(\"Peak VRAM (GB)\", \"first\"),\n",
        "        Avg_MCQ_Acc=(\"MCQ_Acc\", lambda x: x[df_detailed.loc[x.index, 'Is MCQ']].mean() if df_detailed.loc[x.index, 'Is MCQ'].any() else np.nan),\n",
        "        Avg_OpenEnded_BERT_F1=(\"BERTScore_F1\", lambda x: x[~df_detailed.loc[x.index, 'Is Bait'] & ~df_detailed.loc[x.index, 'Is MCQ']].mean() if (~df_detailed.loc[x.index, 'Is Bait'] & ~df_detailed.loc[x.index, 'Is MCQ']).any() else np.nan),\n",
        "        Avg_OpenEnded_ROUGE_L=(\"ROUGE_L\", lambda x: x[~df_detailed.loc[x.index, 'Is Bait'] & ~df_detailed.loc[x.index, 'Is MCQ']].mean() if (~df_detailed.loc[x.index, 'Is Bait'] & ~df_detailed.loc[x.index, 'Is MCQ']).any() else np.nan),\n",
        "        Avg_Refusal_Acc=(\"Refusal_Acc\", lambda x: x[df_detailed.loc[x.index, 'Is Bait']].mean() if df_detailed.loc[x.index, 'Is Bait'].any() else np.nan)\n",
        "    ).reset_index().fillna(0)\n",
        "\n",
        "    print(\"\\n\\n--- FINAL METRIC SUMMARY (All Models Combined) ---\")\n",
        "    print(df_summary_overall.round(3).to_string(index=False))\n",
        "\n",
        "    df_detailed.to_csv(\"detailed_results.csv\", index=False)\n",
        "    df_summary_overall.to_csv(\"summary_results.csv\", index=False)\n",
        "    print(\"\\nResults saved to detailed_results.csv and summary_results.csv\")\n",
        "    print(\"\\nEvaluation complete.\")\n",
        "\n",
        "MODELS_TO_EVALUATE = [\n",
        "    {\"name\": \"MediLearn-Qwen2-7B-GRPO-500Steps\", \"model_id\": \"noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave\"},\n",
        "    # You can add more models here as needed for comparison\n",
        "]\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "USE_4BIT_QUANTIZATION = True\n",
        "LOG_EVERY_N_SAMPLES = 8 # Changed to 8 to log every batch\n",
        "\n",
        "evaluate_model(\n",
        "    models_to_evaluate=MODELS_TO_EVALUATE,\n",
        "    dev_set=DEV_SET,\n",
        "    log_every_n_samples=LOG_EVERY_N_SAMPLES,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    use_4bit_quantization=USE_4BIT_QUANTIZATION\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "db2be62e264146e8a71fbb2010aaafa2",
            "fd792f7c049845848475e0e64ca4d9b3",
            "79ad595c73764d158cf4dcab03c7aa4e",
            "a6299769590543f28aafeb4bd7190227",
            "ec8466c48b834d9a834970a64e855ee5",
            "3d4f3776591c4b6399fa09d7d7a24040",
            "18385cee8a9d4115a3e820973162e6b6",
            "c14d8bf326994f34aa0a4809ef2de0d5",
            "6c536be78db845dd8bf6406c6294d7c4",
            "f9de86f98e0f4b3eb74a225fd5c59e00",
            "c93953fca6aa4072998b37e9f1e9de88",
            "d579453fbd1042f09621130ba45729d0",
            "6a4ee2a2ab2745959811d98072c763ee",
            "55c333aeda4e49828ccd0d8ced4dbfb0",
            "e2a371a45ffe4bed93f7a62ee81c5909",
            "19724ec0e9fc4e1f951da61b06ac0ecd",
            "fe64d344dc7e41f6baf276bb91e6af9e",
            "f506023d6c65434385ca8bd0d6086d07",
            "2870057d82214798b6856aa15e6c9226",
            "3bfc4419728a455d8ee34595b23085fe",
            "f0025ebe3fb94a07b795285c56843e54",
            "0b0ab2ccebcf434abf31129b5e8a917b"
          ]
        },
        "id": "xh3iDbJGsOlm",
        "outputId": "980532f0-da57-4c39-be84-bf2aba7a4dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version installed: 4.53.0\n",
            "Loading dataset from Hugging Face Hub...\n",
            "Preparing evaluation set from full dataset...\n",
            "Sampling 270 medical questions for processing...\n",
            "Prepared a final set of 280 mixed samples for evaluation.\n",
            "\n",
            "--- Dataset Content Analysis ---\n",
            "Total Multiple-Choice Questions (MCQs) detected: 160\n",
            "Total Open-Ended Questions detected: 110\n",
            "Total Bait Questions added: 10\n",
            "--------------------------------\n",
            "\n",
            "Saving the prepared evaluation set to 'evaluation_set_280_samples.json'...\n",
            "File 'evaluation_set_280_samples.json' saved successfully.\n",
            "\n",
            "====================\n",
            "Evaluating Model: MediLearn-Qwen2-7B-GRPO-500Steps (noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave)\n",
            "====================\n",
            "Loading model and tokenizer/processor...\n",
            "    > NOTE: Loading with 4-bit quantization.\n",
            "    > Loading Unsloth fine-tuned model: noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave\n",
            "==((====))==  Unsloth 2025.6.12: Fast Qwen2 patching. Transformers: 4.53.0. vLLM: 0.8.5.post1.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave with actual GPU utilization = 49.43%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1500. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 5.07 GB. Also swap space = 6 GB.\n",
            "INFO 07-05 09:22:53 [config.py:717] This model supports multiple tasks: {'classify', 'embed', 'score', 'reward', 'generate'}. Defaulting to 'generate'.\n",
            "INFO 07-05 09:22:53 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=1500.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'fp4', 'bnb_4bit_use_double_quant': False, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': [], 'llm_int8_threshold': 6.0}\n",
            "INFO 07-05 09:22:54 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave', speculative_config=None, tokenizer='noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1500, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"backend\":\"inductor\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"debug\":false,\"dce\":true,\"coordinate_descent_tuning\":true,\"trace.enabled\":false,\"trace.graph_diagram\":false,\"triton.cudagraphs\":true,\"compile_threads\":48,\"max_autotune\":false,\"disable_progress\":false,\"verbose_progress\":true,\"enable_auto_functionalized_v2\":false},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
            "WARNING 07-05 09:22:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e01753babd0>\n",
            "INFO 07-05 09:22:54 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
            "INFO 07-05 09:22:54 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
            "WARNING 07-05 09:22:54 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "INFO 07-05 09:22:55 [gpu_model_runner.py:1329] Starting to load model noureldinayman/MediLearn-Qwen2-7B-GRPO-500Steps-vLLM-MergedSave...\n",
            "INFO 07-05 09:22:55 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 07-05 09:22:55 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db2be62e264146e8a71fbb2010aaafa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 07-05 09:23:00 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 07-05 09:23:00 [gpu_model_runner.py:1347] Model loading took 5.5142 GiB and 5.195378 seconds\n",
            "INFO 07-05 09:23:17 [backends.py:420] Using cache directory: /root/.cache/vllm/torch_compile_cache/70f353c6e1/rank_0_0 for vLLM's torch.compile\n",
            "INFO 07-05 09:23:17 [backends.py:430] Dynamo bytecode transform time: 16.41 s\n",
            "INFO 07-05 09:23:27 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 7.372 s\n",
            "INFO 07-05 09:23:31 [monitor.py:33] torch.compile takes 16.41 s in total\n",
            "INFO 07-05 09:23:32 [kv_cache_utils.py:634] GPU KV cache size: 232,432 tokens\n",
            "INFO 07-05 09:23:32 [kv_cache_utils.py:637] Maximum concurrency for 1,500 tokens per request: 154.95x\n",
            "INFO 07-05 09:24:43 [gpu_model_runner.py:1686] Graph capturing finished in 72 secs, took 1.33 GiB\n",
            "INFO 07-05 09:24:43 [core.py:159] init engine (profile, create kv cache, warmup model) took 103.11 seconds\n",
            "Unsloth: Just some info: will skip parsing ['k_norm', 'q_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['k_norm', 'q_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm']\n",
            "Model loaded successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating MediLearn-Qwen2-7B-GRPO-500Steps:   0%|          | 0/35 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d579453fbd1042f09621130ba45729d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- First Output for Model: MediLearn-Qwen2-7B-GRPO-500Steps (Prompt ID: Med-2692) ---\n",
            "Question:\n",
            "For patients with PAD and type 2 diabetes, the\n",
            "\n",
            "A: Sulfonylureas\n",
            "B: DPP-4 inhibitors\n",
            "C: SGLT-2 inhibitors\n",
            "D: Meglitinides\n",
            "\n",
            "Reference Answer:\n",
            "c- SGLT-2 inhibitors\n",
            "\n",
            "Raw Generated Text (for debugging format issues):\n",
            "<reasoning> Option A (Sulfonylureas) is not typically recommended for patients with PAD (Peripheral Artery Disease) and type 2 diabetes because they can cause hypoglycemia, which can worsen PAD symptoms. Option B (DPP-4 inhibitors) are not specifically designed to address PAD but can help manage type 2 diabetes. Option C (SGLT-2 inhibitors) are effective in managing type 2 diabetes and have shown benefits in reducing cardiovascular risk, which can be beneficial for patients with PAD. Option D (Meglitinides) are insulin secretagogues that can cause hypoglycemia, which is not ideal for patients with PAD. </reasoning> <answer> C: SGLT-2 inhibitors: These are effective in managing type 2 diabetes and have shown benefits in reducing cardiovascular risk, which can be beneficial for patients with PAD. </answer> Always consult a qualified healthcare professional for medical advice.\n",
            "\n",
            "Cleaned Extracted Answer:\n",
            "C: SGLT-2 inhibitors: These are effective in managing type 2 diabetes and have shown benefits in reducing cardiovascular risk, which can be beneficial for patients with PAD.\n",
            "--------------------------------------------------\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-7\n",
            "Raw Generated Text: <reasoning> A fun fact about space is that the International Space Station (ISS) has its own internet system, allowing astronauts to send and receive emails and access the internet. This system is cru...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 8/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=2, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.80 | Avg BERT_F1: 0.86 | Avg ROUGE_L: 0.15 | Avg Refusal: 0.00\n",
            "\n",
            "    [Log at sample 16/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=3, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.20 | Avg BERT_F1: 0.76 | Avg ROUGE_L: 0.01 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 24/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=6, Open-Ended=2, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.67 | Avg BERT_F1: 0.85 | Avg ROUGE_L: 0.05 | Avg Refusal: nan\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-4\n",
            "Raw Generated Text: 2023: A popular song from 2023 is \"drivers license\" by Olivia Rodrigo. This song became a sensation on social media platforms, particularly TikTok, where it was used in numerous videos and became a vi...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-2635 due to empty prediction or reference.\n",
            "\n",
            "    [Log at sample 32/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=2, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.40 | Avg BERT_F1: 0.40 | Avg ROUGE_L: 0.01 | Avg Refusal: 0.00\n",
            "\n",
            "    [Log at sample 40/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=3, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.60 | Avg BERT_F1: 0.83 | Avg ROUGE_L: 0.16 | Avg Refusal: nan\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-1\n",
            "Raw Generated Text: < reason> I'm sorry, but I can only answer questions related to human anatomy and medicine....\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 48/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=2, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.40 | Avg BERT_F1: 0.80 | Avg ROUGE_L: 0.03 | Avg Refusal: 0.00\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-6\n",
            "Raw Generated Text: I know the tallest mountain in the world is Mount Everest, which is located in the Himalayas, straddling the border between Nepal and Tibet, China. It has a height of 8,848 meters (29,029 feet) above ...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 56/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=4, Open-Ended=3, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.50 | Avg BERT_F1: 0.80 | Avg ROUGE_L: 0.14 | Avg Refusal: 0.00\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-2\n",
            "Raw Generated Text: : the president of the United States is currently Joe Biden....\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 64/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=6, Open-Ended=1, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 1.00 | Avg BERT_F1: 0.69 | Avg ROUGE_L: 0.02 | Avg Refusal: 0.00\n",
            "\n",
            "    [Log at sample 72/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=4, Open-Ended=4, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.00 | Avg BERT_F1: 0.82 | Avg ROUGE_L: 0.05 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 80/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=6, Open-Ended=2, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.33 | Avg BERT_F1: 0.85 | Avg ROUGE_L: 0.14 | Avg Refusal: nan\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-792 due to empty prediction or reference.\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-713 due to empty prediction or reference.\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-3 due to empty prediction or reference.\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-2319 due to empty prediction or reference.\n",
            "\n",
            "    [Log at sample 88/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.00 | Avg BERT_F1: 0.18 | Avg ROUGE_L: 0.07 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 96/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=2, Open-Ended=6, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.50 | Avg BERT_F1: 0.83 | Avg ROUGE_L: 0.11 | Avg Refusal: nan\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-121 due to empty prediction or reference.\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-267 due to empty prediction or reference.\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-1792 due to empty prediction or reference.\n",
            "\n",
            "    [Log at sample 104/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.33 | Avg BERT_F1: 0.30 | Avg ROUGE_L: 0.00 | Avg Refusal: nan\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-8\n",
            "Raw Generated Text: : \n",
            "\n",
            " 1. \n",
            "\n",
            " 2. \n",
            "\n",
            " 3. \n",
            "\n",
            " 4. \n",
            "\n",
            " 5. \n",
            "\n",
            " 6. \n",
            "\n",
            " 7. \n",
            "\n",
            " 8. \n",
            "\n",
            " 9. \n",
            "\n",
            " 10. \n",
            "\n",
            " 11. \n",
            "\n",
            " 12. \n",
            "\n",
            " 13. \n",
            "\n",
            " 14. \n",
            "\n",
            " 15. \n",
            "\n",
            " 16. \n",
            "\n",
            " 17. \n",
            "\n",
            " 18. \n",
            "\n",
            " 19. \n",
            "\n",
            " 20. \n",
            "\n",
            " 21. \n",
            "\n",
            " 22. \n",
            "\n",
            " 23. \n",
            "\n",
            " 24. \n",
            "\n",
            " 25. \n",
            "\n",
            " 26. \n",
            "\n",
            " 27. \n",
            "\n",
            " 28. \n",
            "\n",
            " 29. \n",
            "\n",
            " 3...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 112/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=2, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.40 | Avg BERT_F1: 0.82 | Avg ROUGE_L: 0.21 | Avg Refusal: 0.00\n",
            "\n",
            "    [Log at sample 120/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=3, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.40 | Avg BERT_F1: 0.84 | Avg ROUGE_L: 0.08 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 128/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 1.00 | Avg BERT_F1: 0.81 | Avg ROUGE_L: 0.04 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 136/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=2, Open-Ended=6, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.50 | Avg BERT_F1: 0.79 | Avg ROUGE_L: 0.21 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 144/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=3, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.40 | Avg BERT_F1: 0.81 | Avg ROUGE_L: 0.09 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 152/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=3, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.20 | Avg BERT_F1: 0.82 | Avg ROUGE_L: 0.01 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 160/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=6, Open-Ended=2, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.50 | Avg BERT_F1: 0.84 | Avg ROUGE_L: 0.14 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 168/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=6, Open-Ended=2, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.33 | Avg BERT_F1: 0.91 | Avg ROUGE_L: 0.57 | Avg Refusal: nan\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-9\n",
            "Raw Generated Text: book is not related to human anatomy or medicine. It seems like you're asking for a recommendation for a book on a different topic, such as literature, history, or a specific subject. If you're lookin...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 176/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=6, Open-Ended=1, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.33 | Avg BERT_F1: 0.82 | Avg ROUGE_L: 0.00 | Avg Refusal: 0.00\n",
            "\n",
            "    [Log at sample 184/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=5, Open-Ended=3, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.40 | Avg BERT_F1: 0.80 | Avg ROUGE_L: 0.01 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 192/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.33 | Avg BERT_F1: 0.82 | Avg ROUGE_L: 0.04 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 200/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.67 | Avg BERT_F1: 0.84 | Avg ROUGE_L: 0.14 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 208/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.67 | Avg BERT_F1: 0.85 | Avg ROUGE_L: 0.23 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 216/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=7, Open-Ended=1, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.43 | Avg BERT_F1: 0.83 | Avg ROUGE_L: 0.15 | Avg Refusal: nan\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-1426 due to empty prediction or reference.\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-400 due to empty prediction or reference.\n",
            "\n",
            "    [Log at sample 224/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=1, Open-Ended=7, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.00 | Avg BERT_F1: 0.57 | Avg ROUGE_L: 0.05 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 232/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=7, Open-Ended=1, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.57 | Avg BERT_F1: 0.80 | Avg ROUGE_L: 0.12 | Avg Refusal: nan\n",
            "\n",
            "    [Log at sample 240/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=7, Open-Ended=1, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.57 | Avg BERT_F1: 0.85 | Avg ROUGE_L: 0.09 | Avg Refusal: nan\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-5\n",
            "Raw Generated Text: to be laid out on a plate, and then be folded into a soft, fluffy shape. The eggs should be whisked with a fork to break the yolks and whites into separate streams. The whites should be beaten until t...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 248/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=4, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 1.00 | Avg BERT_F1: 0.77 | Avg ROUGE_L: 0.04 | Avg Refusal: 0.00\n",
            "Skipping BERTScore/ROUGE for Prompt ID Med-1184 due to empty prediction or reference.\n",
            "\n",
            "    [Log at sample 256/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=3, Open-Ended=5, Bait=0\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.67 | Avg BERT_F1: 0.66 | Avg ROUGE_L: 0.08 | Avg Refusal: nan\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-3\n",
            "Raw Generated Text: : 7\n",
            " answer...\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 264/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=7, Open-Ended=0, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.57 | Avg BERT_F1: nan | Avg ROUGE_L: nan | Avg Refusal: 0.00\n",
            "\n",
            "[Refusal Check Fail] Prompt ID: Bait-0\n",
            "Raw Generated Text: the capital of France is Paris....\n",
            "Expected Refusal: 'I am sorry, but I can only answer questions related to human anatomy and medicine.'\n",
            "\n",
            "    [Log at sample 272/280] Model: MediLearn-Qwen2-7B-GRPO-500Steps\n",
            "      > Current Slice Counts: MCQs=4, Open-Ended=3, Bait=1\n",
            "      > Last 8 samples | Avg MCQ Acc: 0.50 | Avg BERT_F1: 0.80 | Avg ROUGE_L: 0.01 | Avg Refusal: 0.00\n",
            "\n",
            "\n",
            "Clearing memory after evaluating MediLearn-Qwen2-7B-GRPO-500Steps...\n",
            "\n",
            "--- METRIC SUMMARY for MediLearn-Qwen2-7B-GRPO-500Steps ---\n",
            "                           Model  Avg_Tokens_Sec  Peak_VRAM_GB  Avg_MCQ_Acc  Avg_OpenEnded_BERT_F1  Avg_OpenEnded_ROUGE_L  Avg_Refusal_Acc\n",
            "MediLearn-Qwen2-7B-GRPO-500Steps          19.048        19.056          0.5                  0.735                  0.094              0.0\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--- FINAL METRIC SUMMARY (All Models Combined) ---\n",
            "                           Model  Avg_Tokens_Sec  Peak_VRAM_GB  Avg_MCQ_Acc  Avg_OpenEnded_BERT_F1  Avg_OpenEnded_ROUGE_L  Avg_Refusal_Acc\n",
            "MediLearn-Qwen2-7B-GRPO-500Steps          19.048        19.056          0.5                  0.735                  0.094              0.0\n",
            "\n",
            "Results saved to detailed_results.csv and summary_results.csv\n",
            "\n",
            "Evaluation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "- Avg_Tokens_Sec: 19.048\n",
        "- Peak_VRAM_GB: 19.056          \n",
        "- Avg_MCQ_Acc: 0.5                  \n",
        "- Avg_OpenEnded_BERT_F1: 0.735                  \n",
        "- Avg_OpenEnded_ROUGE_L: 0.094              \n",
        "- Avg_Refusal_Acc: 0.0"
      ],
      "metadata": {
        "id": "Yz_d5oDpliai"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTx5HMuohu_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}